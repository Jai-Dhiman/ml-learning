{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stage 3: Constitutional AI Training\n",
        "\n",
        "Critique-Revision data generation + DPO training.\n",
        "\n",
        "**Requires**: Stage 2 adapters (load from Drive or retrain)\n",
        "\n",
        "**Expected time**: ~4-5 hours on T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Clone Repository\n",
        "import os\n",
        "\n",
        "os.chdir('/content')\n",
        "\n",
        "# Remove existing directory and clone fresh\n",
        "!rm -rf ml-learning\n",
        "!git clone https://github.com/Jai-Dhiman/ml-learning.git\n",
        "os.chdir('/content/ml-learning')\n",
        "\n",
        "print(f\"\u2705 Repository cloned to: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Install uv Package Manager\n",
        "!pip -q install -U uv\n",
        "\n",
        "import shutil\n",
        "print(f\"\u2705 uv installed at: {shutil.which('uv')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: HuggingFace Authentication\n",
        "import os\n",
        "from huggingface_hub import login, HfApi\n",
        "\n",
        "# Clear any existing tokens\n",
        "os.environ.pop('HF_TOKEN', None)\n",
        "os.environ.pop('HUGGINGFACEHUB_API_TOKEN', None)\n",
        "\n",
        "try:\n",
        "    import getpass as gp\n",
        "    raw = gp.getpass(\"Paste your Hugging Face token (input hidden): \")\n",
        "    token = raw.decode() if isinstance(raw, (bytes, bytearray)) else raw\n",
        "    if not isinstance(token, str):\n",
        "        raise TypeError(f\"Unexpected token type: {type(token).__name__}\")\n",
        "    token = token.strip()\n",
        "    if not token:\n",
        "        raise ValueError(\"Empty token provided\")\n",
        "    \n",
        "    # Login and set environment variable\n",
        "    login(token=token, add_to_git_credential=False)\n",
        "    os.environ['HF_TOKEN'] = token\n",
        "    \n",
        "    who = HfApi().whoami(token=token)\n",
        "    print(f\"\u2705 Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
        "    print('HF_TOKEN environment variable set for bash cells.')\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"[HF Login] getpass flow failed: {e}\")\n",
        "    print(\"Falling back to interactive login widget...\")\n",
        "    login()\n",
        "    \n",
        "    # Try to get token from saved credentials\n",
        "    try:\n",
        "        from huggingface_hub import HfFolder\n",
        "        token = HfFolder.get_token()\n",
        "        if token:\n",
        "            os.environ['HF_TOKEN'] = token\n",
        "            print('HF_TOKEN environment variable set from saved credentials.')\n",
        "        who = HfApi().whoami()\n",
        "        print(f\"\u2705 Logged in as: {who.get('name') or who.get('email') or 'OK'}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"[HF Login] Could not set HF_TOKEN env var: {e2}\")\n",
        "        print(\"You may need to run 'huggingface-cli login' in a bash cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Install Dependencies with uv\n",
        "%%bash\n",
        "set -e\n",
        "cd /content/ml-learning\n",
        "\n",
        "# Create virtual environment\n",
        "echo 'Creating uv virtual environment...'\n",
        "uv venv\n",
        "\n",
        "echo 'Installing dependencies...'\n",
        "\n",
        "# Install PyTorch with CUDA support first\n",
        "uv pip install --python .venv/bin/python torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 || \\\n",
        "  uv pip install --python .venv/bin/python torch torchvision torchaudio\n",
        "\n",
        "# Install remaining dependencies with exact versions\n",
        "uv pip install --python .venv/bin/python \\\n",
        "  \"transformers>=4.43.0\" \\\n",
        "  \"trl>=0.9.6\" \\\n",
        "  \"peft>=0.13.0\" \\\n",
        "  \"datasets>=2.19.0\" \\\n",
        "  \"accelerate>=0.28.0\" \\\n",
        "  sentencepiece \\\n",
        "  safetensors \\\n",
        "  einops \\\n",
        "  evaluate \\\n",
        "  \"protobuf<5\"\n",
        "\n",
        "# Verify installation\n",
        "echo 'Verifying torch installation...'\n",
        ".venv/bin/python -c \"import torch; print(f'PyTorch {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}')\"\n",
        "echo '\u2705 Dependencies installed successfully!'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Download Stage 2 Artifacts from Google Drive\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"DOWNLOADING STAGE 2 ARTIFACTS FROM GOOGLE DRIVE\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"\\n1. Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to Stage 2 artifacts in Google Drive\n",
        "print(\"\\n2. Looking for Stage 2 artifacts in Google Drive...\")\n",
        "drive_artifacts_path = '/content/drive/MyDrive/artifacts/stage2_finetuning_artifacts'\n",
        "\n",
        "print(f\"   Expected location: {drive_artifacts_path}\")\n",
        "print(\"   (If your path is different, update the 'drive_artifacts_path' variable above)\")\n",
        "print()\n",
        "\n",
        "drive_path = Path(drive_artifacts_path)\n",
        "\n",
        "if not drive_path.exists():\n",
        "    print(f\"\u274c ERROR: Path not found: {drive_path}\")\n",
        "    print(\"\\nExpected directory structure in Google Drive:\")\n",
        "    print(\"  MyDrive/\")\n",
        "    print(\"  \u2514\u2500\u2500 artifacts/\")\n",
        "    print(\"      \u2514\u2500\u2500 stage2_finetuning_artifacts/\")\n",
        "    print(\"          \u2514\u2500\u2500 lora_adapters/\")\n",
        "    print(\"\\nPlease:\")\n",
        "    print(\"  1. Upload your local artifacts/stage2_finetuning_artifacts/ folder\")\n",
        "    print(\"     to Google Drive at: MyDrive/artifacts/\")\n",
        "    print(\"  2. Or update the 'drive_artifacts_path' variable above with your actual path\")\n",
        "    print(\"  3. Re-run this cell\")\n",
        "    raise FileNotFoundError(f\"Stage 2 artifacts not found at: {drive_path}\")\n",
        "\n",
        "# Copy artifacts to working directory\n",
        "print(f\"\\n3. Copying artifacts from Drive to Colab workspace...\")\n",
        "target_dir = Path('/content/ml-learning/artifacts/stage2_finetuning_artifacts')\n",
        "target_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Copy the entire directory\n",
        "import shutil\n",
        "if target_dir.exists():\n",
        "    shutil.rmtree(target_dir)\n",
        "shutil.copytree(drive_path, target_dir)\n",
        "\n",
        "# Verify lora_adapters exists\n",
        "lora_dir = target_dir / 'lora_adapters'\n",
        "if lora_dir.exists() and (lora_dir / 'adapter_config.json').exists():\n",
        "    print(f\"\\n\u2705 Stage 2 artifacts successfully copied!\")\n",
        "    print(f\"   Source: {drive_path}\")\n",
        "    print(f\"   Destination: {target_dir}\")\n",
        "    print(f\"   LoRA adapters: {lora_dir}\")\n",
        "    files_list = list(lora_dir.glob('*'))\n",
        "    print(f\"   Files ({len(files_list)}): {[f.name for f in files_list[:5]]}\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"lora_adapters not found or incomplete at: {lora_dir}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"\u2705 ARTIFACTS READY\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: PREFLIGHT TEST (1 pair)\n",
        "%%bash\n",
        "set -e\n",
        "cd /content/ml-learning\n",
        "export WANDB_DISABLED=true\n",
        "\n",
        "echo \"======================================================================\"\n",
        "echo \"PREFLIGHT: Testing with 1 sample\"\n",
        "echo \"======================================================================\"\n",
        "\n",
        "# Test critique-revision\n",
        "echo \"\"\n",
        "echo \"[1/2] Testing critique-revision generation...\"\n",
        "uv run python critique-revision-system/src/critique_revision.py \\\n",
        "  --num-examples 1 \\\n",
        "  --split 'test[:1]' \\\n",
        "  --output /tmp/preflight_pairs.jsonl \\\n",
        "  --adapter-path artifacts/stage2_finetuning_artifacts/lora_adapters \\\n",
        "  --seed 42\n",
        "\n",
        "# Test DPO\n",
        "echo \"\"\n",
        "echo \"[2/2] Testing DPO training...\"\n",
        "uv run python critique-revision-system/src/training/train_dpo_stage3.py \\\n",
        "  --repo-root /content/ml-learning \\\n",
        "  --pairs-path /tmp/preflight_pairs.jsonl \\\n",
        "  --base-model-id google/gemma-2b-it \\\n",
        "  --stage2-adapter-path artifacts/stage2_finetuning_artifacts/lora_adapters \\\n",
        "  --output-dir /tmp/preflight_stage3 \\\n",
        "  --per-device-train-batch-size 1 \\\n",
        "  --gradient-accumulation-steps 1 \\\n",
        "  --learning-rate 5e-5 \\\n",
        "  --num-train-epochs 1 \\\n",
        "  --max-steps 1 \\\n",
        "  --beta 0.1 \\\n",
        "  --seed 42 \\\n",
        "  --cpu-ref-model\n",
        "\n",
        "echo \"\"\n",
        "echo \"======================================================================\"\n",
        "echo \"\u2705 PREFLIGHT PASSED - Ready for full training\"\n",
        "echo \"======================================================================\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Generate Critique-Revision Pairs (2500 pairs)\n",
        "%%bash\n",
        "set -e\n",
        "cd /content/ml-learning\n",
        "mkdir -p artifacts/stage3_constitutional/pairs\n",
        "\n",
        "echo \"======================================================================\"\n",
        "echo \"STAGE 3 - PART 1: CRITIQUE-REVISION GENERATION\"\n",
        "echo \"======================================================================\"\n",
        "\n",
        "uv run python critique-revision-system/src/critique_revision.py \\\n",
        "  --num-examples 2500 \\\n",
        "  --split 'test[:1000]+train[:1500]' \\\n",
        "  --output artifacts/stage3_constitutional/pairs/pairs.jsonl \\\n",
        "  --adapter-path artifacts/stage2_finetuning_artifacts/lora_adapters \\\n",
        "  --seed 42\n",
        "\n",
        "echo \"\"\n",
        "echo \"\u2705 Pairs generated\"\n",
        "ls -lh artifacts/stage3_constitutional/pairs/pairs.jsonl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Validate Pairs Quality\n",
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "pairs_path = '/content/ml-learning/artifacts/stage3_constitutional/pairs/pairs.jsonl'\n",
        "\n",
        "with open(pairs_path) as f:\n",
        "    pairs = [json.loads(line) for line in f]\n",
        "\n",
        "print(f\"Total pairs: {len(pairs)}\")\n",
        "\n",
        "# Check malformed\n",
        "malformed = 0\n",
        "for p in pairs:\n",
        "    revised = p.get('revised_response', '')\n",
        "    if len(revised) < 30 or any(ind in revised.lower()[:100] for ind in ['accurate, but', 'could be improved']):\n",
        "        malformed += 1\n",
        "\n",
        "malformed_rate = malformed / len(pairs) * 100\n",
        "print(f\"\\nQuality: {len(pairs)-malformed} valid ({100-malformed_rate:.1f}%)\")\n",
        "print(f\"Malformed: {malformed} ({malformed_rate:.1f}%)\")\n",
        "\n",
        "if malformed_rate < 5:\n",
        "    print(\"\u2705 Quality GOOD\")\n",
        "else:\n",
        "    print(\"\u26a0\ufe0f  Quality needs improvement\")\n",
        "\n",
        "# Top principles\n",
        "principle_counts = Counter()\n",
        "for p in pairs:\n",
        "    for pid in p.get('principle_ids', []):\n",
        "        principle_counts[pid] += 1\n",
        "\n",
        "print(f\"\\nTop Principles:\")\n",
        "for pid, count in principle_counts.most_common(5):\n",
        "    print(f\"  {pid}: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: DPO Training\n",
        "%%bash\n",
        "set -e\n",
        "cd /content/ml-learning\n",
        "\n",
        "echo \"======================================================================\"\n",
        "echo \"STAGE 3 - PART 2: DPO TRAINING\"\n",
        "echo \"======================================================================\"\n",
        "\n",
        "uv run python critique-revision-system/src/training/train_dpo_stage3.py \\\n",
        "  --repo-root /content/ml-learning \\\n",
        "  --pairs-path artifacts/stage3_constitutional/pairs/pairs.jsonl \\\n",
        "  --base-model-id google/gemma-2b-it \\\n",
        "  --stage2-adapter-path artifacts/stage2_finetuning_artifacts/lora_adapters \\\n",
        "  --output-dir artifacts/stage3_constitutional \\\n",
        "  --per-device-train-batch-size 1 \\\n",
        "  --gradient-accumulation-steps 8 \\\n",
        "  --learning-rate 5e-5 \\\n",
        "  --num-train-epochs 1.0 \\\n",
        "  --beta 0.1 \\\n",
        "  --seed 42 \\\n",
        "  --save-steps 200 \\\n",
        "  --logging-steps 10 \\\n",
        "  --cpu-ref-model\n",
        "\n",
        "echo \"\"\n",
        "echo \"\u2705 Stage 3 DPO training complete!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Download Stage 3 Artifacts\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "from google.colab import files\n",
        "\n",
        "print('=' * 70)\n",
        "print('DOWNLOADING STAGE 3 ARTIFACTS')\n",
        "print('=' * 70)\n",
        "\n",
        "# Define paths\n",
        "artifacts_dir = Path('/content/ml-learning/artifacts/stage3_constitutional')\n",
        "zip_name = 'stage3_constitutional_artifacts'\n",
        "zip_path = f'/content/{zip_name}'\n",
        "\n",
        "# Check if artifacts exist\n",
        "if not artifacts_dir.exists():\n",
        "    print(f'ERROR: Artifacts directory not found at {artifacts_dir}')\n",
        "    print('Please ensure Stage 3 training completed successfully.')\n",
        "else:\n",
        "    print(f'Found artifacts directory: {artifacts_dir}')\n",
        "    print(f'\\nCreating zip archive...')\n",
        "    \n",
        "    # Create zip archive\n",
        "    with zipfile.ZipFile(f'{zip_path}.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, file_list in os.walk(artifacts_dir):\n",
        "            for file in file_list:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, artifacts_dir.parent)\n",
        "                zipf.write(file_path, arcname)\n",
        "    \n",
        "    zip_file = f'{zip_path}.zip'\n",
        "    zip_size_mb = Path(zip_file).stat().st_size / (1024 * 1024)\n",
        "    \n",
        "    print(f'Zip archive created: {zip_file}')\n",
        "    print(f'Archive size: {zip_size_mb:.2f} MB')\n",
        "    print(f'\\nContents:')\n",
        "    print(f'  - pairs/pairs.jsonl (critique/revision training pairs)')\n",
        "    print(f'  - models/lora_adapters/ (DPO-trained Stage 3 model)')\n",
        "    print(f'  - dpo_dataset/train.jsonl (preprocessed DPO training data)')\n",
        "    print(f'  - metrics.json (training metrics)')\n",
        "    print(f'  - checkpoints/ (training checkpoints)')\n",
        "    print(f'  - logs/ (training logs)')\n",
        "    print(f'\\nInitiating download...')\n",
        "    \n",
        "    # Download the zip file\n",
        "    files.download(zip_file)\n",
        "    \n",
        "    print(f'\\n' + '=' * 70)\n",
        "    print('EXTRACTION INSTRUCTIONS FOR LOCAL MACHINE')\n",
        "    print('=' * 70)\n",
        "    print(f'\\n1. Locate downloaded file: {zip_name}.zip')\n",
        "    print(f'\\n2. Extract to your ml-learning artifacts directory:')\n",
        "    print(f'   cd ~/Documents/ml-learning/artifacts')\n",
        "    print(f'   unzip ~/Downloads/{zip_name}.zip')\n",
        "    print(f'\\n3. Verify extraction:')\n",
        "    print(f'   ls -lh ~/Documents/ml-learning/artifacts/stage3_constitutional/')\n",
        "    print(f'\\n4. Stage 3 artifacts will be at:')\n",
        "    print(f'   ~/Documents/ml-learning/artifacts/stage3_constitutional/')\n",
        "    print(f'\\n' + '=' * 70)\n",
        "    print('\u2705 STAGE 3 COMPLETE - Artifacts downloaded!')\n",
        "    print('=' * 70)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}