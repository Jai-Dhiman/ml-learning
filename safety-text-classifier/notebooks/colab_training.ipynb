{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ğŸ›¡ï¸ Safety Text Classifier Training - Google Colab\n",
    "\n",
    "**Constitutional AI Research Project - Stage 1**\n",
    "\n",
    "This notebook trains a transformer-based safety text classifier using JAX/Flax on Google Colab GPU.\n",
    "\n",
    "## ğŸ“‹ Prerequisites\n",
    "- GPU runtime enabled in Colab\n",
    "- Weights & Biases account for experiment tracking\n",
    "- Project files uploaded or cloned\n",
    "\n",
    "## ğŸ¯ Expected Results\n",
    "- Training time: ~2-3 hours on GPU\n",
    "- Target accuracy: 85%+ on safety classification\n",
    "- Model size: ~50MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## 1. ğŸš€ Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory on Drive\n",
    "import os\n",
    "checkpoint_dir = '/content/drive/MyDrive/safety-classifier-checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(f\"âœ… Checkpoint directory ready: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1.5 ğŸš€ Setup with uv \n\nThis step installs dependencies using uv (10-100x faster than pip) with proper compatibility and resolved dependency conflicts."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install uv package manager\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "# Add uv to PATH\n",
    "import os\n",
    "uv_path = os.path.expanduser('~/.cargo/bin')\n",
    "os.environ['PATH'] = f\"{uv_path}:{os.environ['PATH']}\"\n",
    "\n",
    "# Test uv\n",
    "!uv --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('ml-learning/safety-text-classifier')\n",
    "print(f\"Changed directory to: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 ğŸ“ Navigate to Project Directory\n",
    "\n",
    "This cell helps you navigate to the correct directory if you've uploaded the full ml-learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Navigation Helper - Run this if you have path issues\nimport os\nfrom pathlib import Path\n\ndef find_and_navigate_to_project():\n    current_dir = Path.cwd()\n    print(f\"ğŸ“ Current directory: {current_dir}\")\n    \n    # Check if we're already in the right place\n    if current_dir.name == \"safety-text-classifier\":\n        if (current_dir / \"src\").exists() and (current_dir / \"configs\").exists():\n            print(\"âœ… Already in safety-text-classifier directory!\")\n            return str(current_dir)\n    \n    # Look for safety-text-classifier in current directory\n    safety_path = current_dir / \"safety-text-classifier\"\n    if safety_path.exists() and safety_path.is_dir():\n        print(f\"âœ… Found safety-text-classifier at: {safety_path}\")\n        os.chdir(safety_path)\n        print(f\"ğŸ“‚ Changed to: {Path.cwd()}\")\n        return str(safety_path)\n    \n    # Look for ml-learning directory\n    ml_learning_path = current_dir / \"ml-learning\"\n    if ml_learning_path.exists():\n        safety_in_ml = ml_learning_path / \"safety-text-classifier\"\n        if safety_in_ml.exists():\n            print(f\"âœ… Found project at: {safety_in_ml}\")\n            os.chdir(safety_in_ml)\n            print(f\"ğŸ“‚ Changed to: {Path.cwd()}\")\n            return str(safety_in_ml)\n    \n    print(\"âŒ Could not find safety-text-classifier directory!\")\n    print(\"ğŸ“‹ Available directories:\")\n    for item in current_dir.iterdir():\n        if item.is_dir():\n            print(f\"  ğŸ“ {item.name}\")\n    return None\n\n# Run navigation\nproject_path = find_and_navigate_to_project()\n\n# Verify structure\nif project_path:\n    print(\"\\nğŸ” Verifying project structure...\")\n    required_items = ['src', 'configs', 'pyproject.toml']\n    all_good = True\n    for item in required_items:\n        if Path(item).exists():\n            print(f\"âœ… {item}\")\n        else:\n            print(f\"âŒ {item}\")\n            all_good = False\n    \n    if all_good:\n        print(\"\\nğŸ‰ Project structure looks good!\")\n    else:\n        print(\"\\nâš ï¸  Some required files are missing.\")\n\nprint(f\"\\nğŸ“ Final directory: {Path.cwd()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training-section"
   },
   "source": [
    "## 2. ğŸ‹ï¸ Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-modules"
   },
   "outputs": [],
   "source": "# Project Setup - Run this cell first\nimport os\nimport sys\nfrom pathlib import Path\n\ndef setup_project():\n    \"\"\"Find project directory and set up Python path.\"\"\"\n    current_dir = Path.cwd()\n    print(f\"ğŸ“ Starting from: {current_dir}\")\n    \n    # Check if we're already in the right place\n    if current_dir.name == \"safety-text-classifier\" and (current_dir / \"src\").exists():\n        print(\"âœ… Already in safety-text-classifier directory!\")\n        project_path = current_dir\n    else:\n        # Look for project in common locations\n        search_paths = [\n            current_dir / \"safety-text-classifier\",\n            current_dir / \"ml-learning\" / \"safety-text-classifier\"\n        ]\n        \n        project_path = None\n        for path in search_paths:\n            if path.exists() and (path / \"src\").exists():\n                print(f\"âœ… Found project at: {path}\")\n                os.chdir(path)\n                project_path = path\n                break\n        \n        if not project_path:\n            print(\"âŒ Could not find safety-text-classifier directory!\")\n            print(\"ğŸ“‹ Available directories:\")\n            for item in current_dir.iterdir():\n                if item.is_dir():\n                    print(f\"  ğŸ“ {item.name}\")\n            return False\n    \n    # Add src to Python path for imports\n    src_path = str(project_path / \"src\")\n    if src_path not in sys.path:\n        sys.path.insert(0, src_path)\n        print(f\"âœ… Added to Python path: {src_path}\")\n    \n    # Verify structure\n    required_items = ['src', 'configs', 'pyproject.toml']\n    missing = [item for item in required_items if not (project_path / item).exists()]\n    \n    if not missing:\n        print(\"ğŸ‰ Project structure verified!\")\n        print(f\"ğŸ“ Working directory: {project_path}\")\n        return True\n    else:\n        print(f\"âŒ Missing: {missing}\")\n        return False\n\n# Run setup\nif setup_project():\n    print(\"âœ… Setup complete!\")\nelse:\n    print(\"âš ï¸ Please upload the safety-text-classifier folder to Colab\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "setup-wandb"
   },
   "outputs": [],
   "source": "# Test imports - Run this after project setup\nimport os\nimport sys\n\n# Debug path information\nprint(f\"Current working directory: {os.getcwd()}\")\nprint(f\"Contents of src/: {os.listdir('src') if os.path.exists('src') else 'src not found'}\")\n\n# Try different import approaches\ntry:\n    # Method 1: Direct import from current directory\n    sys.path.insert(0, os.getcwd())  # Add current directory to path\n    from src.data.dataset_loader import create_data_loaders, SafetyDatasetLoader\n    from src.training.trainer import SafetyTrainer\n    print(\"âœ… Method 1 successful: Direct src import\")\n    \nexcept ImportError as e:\n    print(f\"âŒ Method 1 failed: {e}\")\n    try:\n        # Method 2: Import with src in path (should work from setup cell)\n        from data.dataset_loader import create_data_loaders, SafetyDatasetLoader\n        from training.trainer import SafetyTrainer\n        print(\"âœ… Method 2 successful: Import from src path\")\n        \n    except ImportError as e2:\n        print(f\"âŒ Method 2 failed: {e2}\")\n        print(\"Available modules in src/:\")\n        for item in os.listdir('src'):\n            if os.path.isdir(f'src/{item}'):\n                print(f\"  ğŸ“ {item}/: {os.listdir(f'src/{item}')}\")\n\n# Test other imports\ntry:\n    import jax\n    import numpy as np\n    print(f\"âœ… JAX {jax.__version__} and NumPy {np.__version__} imported\")\n    print(f\"JAX devices: {jax.devices()}\")\n    \n    # Check for GPU\n    gpu_devices = [d for d in jax.devices() if 'gpu' in str(d).lower()]\n    if gpu_devices:\n        print(f\"ğŸ¯ GPU ready: {gpu_devices}\")\n    else:\n        print(\"âš ï¸ CPU only - training will be slower\")\n        \nexcept Exception as e:\n    print(f\"âŒ JAX/NumPy error: {e}\")\n\nprint(\"\\\\nğŸ¯ If imports are successful, you're ready for training!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "start-training",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start training with Colab-optimized config\n",
    "print(\"ğŸš€ Starting training with Colab configuration...\")\n",
    "print(\"ğŸ“Š Monitor progress in W&B dashboard\")\n",
    "print(\"â±ï¸  Expected training time: 2-3 hours\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Initialize trainer with Colab config\n",
    "    trainer = SafetyTrainer(config_path=\"configs/colab_config.yaml\")\n",
    "    \n",
    "    # Start training\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"\\nğŸ‰ Training completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    # Clean up W&B\n",
    "    if 'wandb' in globals() and wandb.run:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evaluate-model"
   },
   "outputs": [],
   "source": [
    "# Evaluate the trained model\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from training.trainer import SafetyTrainer\n",
    "from data.dataset_loader import create_data_loaders\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“Š Loading model for evaluation...\")\n",
    "\n",
    "# Load config\n",
    "with open('configs/colab_config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Load trainer (will load best checkpoint)\n",
    "trainer = SafetyTrainer('configs/colab_config.yaml')\n",
    "\n",
    "# Load test data\n",
    "_, _, test_dataset = create_data_loaders('configs/colab_config.yaml')\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = trainer.evaluate(test_dataset, 0, \"test/\")\n",
    "\n",
    "print(\"\\nğŸ¯ Final Test Results:\")\n",
    "print(f\"Test Accuracy: {test_metrics['accuracy']:.1%}\")\n",
    "print(f\"Test Loss: {test_metrics['loss']:.4f}\")\n",
    "\n",
    "# Per-class accuracy\n",
    "if 'per_class_accuracy' in test_metrics:\n",
    "    categories = ['Hate Speech', 'Self Harm', 'Dangerous Advice', 'Harassment']\n",
    "    per_class_acc = test_metrics['per_class_accuracy']\n",
    "    print(\"\\nğŸ“‹ Per-Category Accuracy:\")\n",
    "    for cat, acc in zip(categories, per_class_acc):\n",
    "        print(f\"  {cat}: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-demo"
   },
   "source": "# Setup Weights & Biases and start training\nimport wandb\n\n# Login to W&B\nwandb.login()\n\nprint(\"ğŸš€ Starting training...\")\nprint(\"ğŸ“Š Monitor progress in W&B dashboard\")\nprint(\"â±ï¸ Expected time: 2-3 hours on GPU\")\nprint(\"=\" * 50)\n\ntry:\n    # Initialize trainer with Colab config\n    trainer = SafetyTrainer(config_path=\"configs/colab_config.yaml\")\n    \n    # Start training\n    trainer.train()\n    \n    print(\"\\nğŸ‰ Training completed successfully!\")\n    \nexcept Exception as e:\n    print(f\"âŒ Training failed: {e}\")\n    import traceback\n    traceback.print_exc()\n\nfinally:\n    # Clean up W&B\n    if 'wandb' in globals() and wandb.run:\n        wandb.finish()"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save-model"
   },
   "source": [
    "## 5. ğŸ’¾ Save Model for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-to-drive"
   },
   "outputs": [],
   "source": "# Evaluate the trained model\nimport yaml\n\nprint(\"ğŸ“Š Evaluating trained model...\")\n\ntry:\n    # Use the imports that worked in the test cell above\n    from src.training.trainer import SafetyTrainer\n    from src.data.dataset_loader import create_data_loaders\nexcept ImportError:\n    # Fallback to path-based imports\n    from training.trainer import SafetyTrainer\n    from data.dataset_loader import create_data_loaders\n\n# Load trainer (will automatically load best checkpoint)\ntrainer = SafetyTrainer('configs/colab_config.yaml')\n\n# Load test data\n_, _, test_dataset = create_data_loaders('configs/colab_config.yaml')\n\n# Evaluate on test set\ntest_metrics = trainer.evaluate(test_dataset, 0, \"test/\")\n\nprint(\"\\\\nğŸ¯ Final Test Results:\")\nprint(f\"Test Accuracy: {test_metrics['accuracy']:.1%}\")\nprint(f\"Test Loss: {test_metrics['loss']:.4f}\")\n\n# Per-class accuracy\nif 'per_class_accuracy' in test_metrics:\n    categories = ['Hate Speech', 'Self Harm', 'Dangerous Advice', 'Harassment']\n    per_class_acc = test_metrics['per_class_accuracy']\n    print(\"\\\\nğŸ“‹ Per-Category Accuracy:\")\n    for cat, acc in zip(categories, per_class_acc):\n        print(f\"  {cat}: {acc:.1%}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next-steps"
   },
   "source": "# Evaluate the trained model\nfrom training.trainer import SafetyTrainer\nfrom data.dataset_loader import create_data_loaders\nimport yaml\n\nprint(\"ğŸ“Š Evaluating trained model...\")\n\n# Load trainer (will automatically load best checkpoint)\ntrainer = SafetyTrainer('configs/colab_config.yaml')\n\n# Load test data\n_, _, test_dataset = create_data_loaders('configs/colab_config.yaml')\n\n# Evaluate on test set\ntest_metrics = trainer.evaluate(test_dataset, 0, \"test/\")\n\nprint(\"\\nğŸ¯ Final Test Results:\")\nprint(f\"Test Accuracy: {test_metrics['accuracy']:.1%}\")\nprint(f\"Test Loss: {test_metrics['loss']:.4f}\")\n\n# Per-class accuracy\nif 'per_class_accuracy' in test_metrics:\n    categories = ['Hate Speech', 'Self Harm', 'Dangerous Advice', 'Harassment']\n    per_class_acc = test_metrics['per_class_accuracy']\n    print(\"\\nğŸ“‹ Per-Category Accuracy:\")\n    for cat, acc in zip(categories, per_class_acc):\n        print(f\"  {cat}: {acc:.1%}\")"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}