{
  "training_metrics": [
    {
      "step": 1,
      "loss": 0.835487961769104,
      "accuracy": 0.0,
      "grad_norm": 12.942760467529297
    },
    {
      "step": 2,
      "loss": 0.7434655427932739,
      "accuracy": 0.0625,
      "grad_norm": 10.985095024108887
    },
    {
      "step": 3,
      "loss": 0.8738044500350952,
      "accuracy": 0.0,
      "grad_norm": 13.78806209564209
    },
    {
      "step": 4,
      "loss": 0.7917342185974121,
      "accuracy": 0.0,
      "grad_norm": 11.414875984191895
    },
    {
      "step": 5,
      "loss": 0.7816250324249268,
      "accuracy": 0.0,
      "grad_norm": 13.591668128967285
    },
    {
      "step": 6,
      "loss": 0.8822637796401978,
      "accuracy": 0.0,
      "grad_norm": 14.152442932128906
    },
    {
      "step": 7,
      "loss": 0.8336787819862366,
      "accuracy": 0.0,
      "grad_norm": 12.770407676696777
    },
    {
      "step": 8,
      "loss": 0.6803960800170898,
      "accuracy": 0.0625,
      "grad_norm": 10.747759819030762
    },
    {
      "step": 9,
      "loss": 0.7149505019187927,
      "accuracy": 0.0625,
      "grad_norm": 11.106557846069336
    },
    {
      "step": 10,
      "loss": 0.6867899298667908,
      "accuracy": 0.0,
      "grad_norm": 11.782425880432129
    },
    {
      "step": 11,
      "loss": 0.6897145509719849,
      "accuracy": 0.0,
      "grad_norm": 11.260357856750488
    },
    {
      "step": 12,
      "loss": 0.5777320861816406,
      "accuracy": 0.0625,
      "grad_norm": 9.874933242797852
    },
    {
      "step": 13,
      "loss": 0.6532580852508545,
      "accuracy": 0.0625,
      "grad_norm": 9.278462409973145
    },
    {
      "step": 14,
      "loss": 0.6614603400230408,
      "accuracy": 0.1875,
      "grad_norm": 9.929859161376953
    },
    {
      "step": 15,
      "loss": 0.5672241449356079,
      "accuracy": 0.25,
      "grad_norm": 8.134607315063477
    },
    {
      "step": 16,
      "loss": 0.48186901211738586,
      "accuracy": 0.3125,
      "grad_norm": 6.730350971221924
    },
    {
      "step": 17,
      "loss": 0.5308144092559814,
      "accuracy": 0.1875,
      "grad_norm": 4.755552291870117
    },
    {
      "step": 18,
      "loss": 0.5112797021865845,
      "accuracy": 0.3125,
      "grad_norm": 4.895055294036865
    },
    {
      "step": 19,
      "loss": 0.44525572657585144,
      "accuracy": 0.3125,
      "grad_norm": 4.217610836029053
    },
    {
      "step": 20,
      "loss": 0.4137915372848511,
      "accuracy": 0.5,
      "grad_norm": 4.900006294250488
    },
    {
      "step": 21,
      "loss": 0.47084617614746094,
      "accuracy": 0.125,
      "grad_norm": 4.570019721984863
    },
    {
      "step": 22,
      "loss": 0.3739379048347473,
      "accuracy": 0.5,
      "grad_norm": 3.086054563522339
    },
    {
      "step": 23,
      "loss": 0.4425447881221771,
      "accuracy": 0.4375,
      "grad_norm": 4.116444110870361
    },
    {
      "step": 24,
      "loss": 0.3924483060836792,
      "accuracy": 0.4375,
      "grad_norm": 2.9882614612579346
    },
    {
      "step": 25,
      "loss": 0.45642703771591187,
      "accuracy": 0.3125,
      "grad_norm": 3.0340776443481445
    },
    {
      "step": 26,
      "loss": 0.3787787854671478,
      "accuracy": 0.375,
      "grad_norm": 1.9842147827148438
    },
    {
      "step": 27,
      "loss": 0.4451902508735657,
      "accuracy": 0.375,
      "grad_norm": 2.9082634449005127
    },
    {
      "step": 28,
      "loss": 0.3873242437839508,
      "accuracy": 0.4375,
      "grad_norm": 2.2044379711151123
    },
    {
      "step": 29,
      "loss": 0.3313750624656677,
      "accuracy": 0.625,
      "grad_norm": 2.0046558380126953
    },
    {
      "step": 30,
      "loss": 0.3637521266937256,
      "accuracy": 0.5,
      "grad_norm": 2.573962688446045
    },
    {
      "step": 31,
      "loss": 0.35934606194496155,
      "accuracy": 0.5625,
      "grad_norm": 2.3604049682617188
    },
    {
      "step": 32,
      "loss": 0.5289124846458435,
      "accuracy": 0.25,
      "grad_norm": 4.600325584411621
    },
    {
      "step": 33,
      "loss": 0.5323648452758789,
      "accuracy": 0.25,
      "grad_norm": 3.2290539741516113
    },
    {
      "step": 34,
      "loss": 0.37489864230155945,
      "accuracy": 0.5,
      "grad_norm": 2.0651557445526123
    },
    {
      "step": 35,
      "loss": 0.4090403616428375,
      "accuracy": 0.4375,
      "grad_norm": 2.747143507003784
    },
    {
      "step": 36,
      "loss": 0.46882641315460205,
      "accuracy": 0.375,
      "grad_norm": 3.375058650970459
    },
    {
      "step": 37,
      "loss": 0.25268393754959106,
      "accuracy": 0.6875,
      "grad_norm": 1.4975757598876953
    },
    {
      "step": 38,
      "loss": 0.4063696265220642,
      "accuracy": 0.4375,
      "grad_norm": 2.2090017795562744
    },
    {
      "step": 39,
      "loss": 0.3910142183303833,
      "accuracy": 0.375,
      "grad_norm": 2.09666109085083
    },
    {
      "step": 40,
      "loss": 0.3968697786331177,
      "accuracy": 0.5,
      "grad_norm": 2.246734380722046
    },
    {
      "step": 41,
      "loss": 0.3594413995742798,
      "accuracy": 0.5,
      "grad_norm": 1.8725472688674927
    },
    {
      "step": 42,
      "loss": 0.4063282608985901,
      "accuracy": 0.4375,
      "grad_norm": 2.607480525970459
    },
    {
      "step": 43,
      "loss": 0.46078068017959595,
      "accuracy": 0.25,
      "grad_norm": 2.701925754547119
    },
    {
      "step": 44,
      "loss": 0.42365193367004395,
      "accuracy": 0.375,
      "grad_norm": 2.987058639526367
    },
    {
      "step": 45,
      "loss": 0.3924803137779236,
      "accuracy": 0.375,
      "grad_norm": 2.365042209625244
    },
    {
      "step": 46,
      "loss": 0.35518890619277954,
      "accuracy": 0.4375,
      "grad_norm": 3.326639175415039
    },
    {
      "step": 47,
      "loss": 0.374914288520813,
      "accuracy": 0.4375,
      "grad_norm": 2.654714345932007
    },
    {
      "step": 48,
      "loss": 0.32220813632011414,
      "accuracy": 0.625,
      "grad_norm": 2.9179630279541016
    },
    {
      "step": 49,
      "loss": 0.4720572829246521,
      "accuracy": 0.3125,
      "grad_norm": 2.944789171218872
    },
    {
      "step": 50,
      "loss": 0.46214061975479126,
      "accuracy": 0.3125,
      "grad_norm": 1.9162187576293945
    },
    {
      "step": 51,
      "loss": 0.3676469027996063,
      "accuracy": 0.5,
      "grad_norm": 2.4285495281219482
    },
    {
      "step": 52,
      "loss": 0.32764703035354614,
      "accuracy": 0.375,
      "grad_norm": 1.986609935760498
    },
    {
      "step": 53,
      "loss": 0.4471377432346344,
      "accuracy": 0.25,
      "grad_norm": 4.7884602546691895
    },
    {
      "step": 54,
      "loss": 0.3645930886268616,
      "accuracy": 0.4375,
      "grad_norm": 4.0124831199646
    },
    {
      "step": 55,
      "loss": 0.4257885217666626,
      "accuracy": 0.3125,
      "grad_norm": 2.475409746170044
    },
    {
      "step": 56,
      "loss": 0.3745223879814148,
      "accuracy": 0.3125,
      "grad_norm": 2.943476676940918
    },
    {
      "step": 57,
      "loss": 0.33106327056884766,
      "accuracy": 0.375,
      "grad_norm": 2.3626627922058105
    },
    {
      "step": 58,
      "loss": 0.40970420837402344,
      "accuracy": 0.5,
      "grad_norm": 3.295952796936035
    },
    {
      "step": 59,
      "loss": 0.35670769214630127,
      "accuracy": 0.375,
      "grad_norm": 2.012540817260742
    },
    {
      "step": 60,
      "loss": 0.4229888916015625,
      "accuracy": 0.25,
      "grad_norm": 2.3741705417633057
    },
    {
      "step": 61,
      "loss": 0.4825947880744934,
      "accuracy": 0.1875,
      "grad_norm": 2.9901912212371826
    },
    {
      "step": 62,
      "loss": 0.30865347385406494,
      "accuracy": 0.625,
      "grad_norm": 2.2174384593963623
    },
    {
      "step": 63,
      "loss": 0.3955082297325134,
      "accuracy": 0.375,
      "grad_norm": 4.535532474517822
    },
    {
      "step": 64,
      "loss": 0.3960126042366028,
      "accuracy": 0.375,
      "grad_norm": 2.179549217224121
    },
    {
      "step": 65,
      "loss": 0.3470710515975952,
      "accuracy": 0.375,
      "grad_norm": 2.160425901412964
    },
    {
      "step": 66,
      "loss": 0.35596615076065063,
      "accuracy": 0.3125,
      "grad_norm": 2.380300998687744
    },
    {
      "step": 67,
      "loss": 0.35279613733291626,
      "accuracy": 0.375,
      "grad_norm": 2.3390495777130127
    },
    {
      "step": 68,
      "loss": 0.2969703674316406,
      "accuracy": 0.4375,
      "grad_norm": 2.5918233394622803
    },
    {
      "step": 69,
      "loss": 0.40519261360168457,
      "accuracy": 0.3125,
      "grad_norm": 3.4374899864196777
    },
    {
      "step": 70,
      "loss": 0.3646771311759949,
      "accuracy": 0.375,
      "grad_norm": 2.182748556137085
    },
    {
      "step": 71,
      "loss": 0.3722612261772156,
      "accuracy": 0.4375,
      "grad_norm": 2.8079991340637207
    },
    {
      "step": 72,
      "loss": 0.3959927260875702,
      "accuracy": 0.25,
      "grad_norm": 4.803654193878174
    },
    {
      "step": 73,
      "loss": 0.32324811816215515,
      "accuracy": 0.5,
      "grad_norm": 2.1150825023651123
    },
    {
      "step": 74,
      "loss": 0.38128525018692017,
      "accuracy": 0.4375,
      "grad_norm": 2.9552948474884033
    },
    {
      "step": 75,
      "loss": 0.3268473148345947,
      "accuracy": 0.375,
      "grad_norm": 1.94423508644104
    },
    {
      "step": 76,
      "loss": 0.3619932234287262,
      "accuracy": 0.3125,
      "grad_norm": 3.2664434909820557
    },
    {
      "step": 77,
      "loss": 0.3550332486629486,
      "accuracy": 0.5625,
      "grad_norm": 2.5450942516326904
    },
    {
      "step": 78,
      "loss": 0.4117201268672943,
      "accuracy": 0.375,
      "grad_norm": 3.1775927543640137
    },
    {
      "step": 79,
      "loss": 0.3286593556404114,
      "accuracy": 0.3125,
      "grad_norm": 3.2294375896453857
    },
    {
      "step": 80,
      "loss": 0.343114972114563,
      "accuracy": 0.375,
      "grad_norm": 3.008114814758301
    },
    {
      "step": 81,
      "loss": 0.29698100686073303,
      "accuracy": 0.5,
      "grad_norm": 1.794939637184143
    },
    {
      "step": 82,
      "loss": 0.3922750949859619,
      "accuracy": 0.375,
      "grad_norm": 4.321345806121826
    },
    {
      "step": 83,
      "loss": 0.3819410800933838,
      "accuracy": 0.625,
      "grad_norm": 4.6452107429504395
    },
    {
      "step": 84,
      "loss": 0.2939392924308777,
      "accuracy": 0.625,
      "grad_norm": 4.055639743804932
    },
    {
      "step": 85,
      "loss": 0.30764859914779663,
      "accuracy": 0.5,
      "grad_norm": 2.980271816253662
    },
    {
      "step": 86,
      "loss": 0.3288944363594055,
      "accuracy": 0.4375,
      "grad_norm": 3.4033877849578857
    },
    {
      "step": 87,
      "loss": 0.368228554725647,
      "accuracy": 0.375,
      "grad_norm": 2.7960855960845947
    },
    {
      "step": 88,
      "loss": 0.333964467048645,
      "accuracy": 0.5,
      "grad_norm": 3.5179057121276855
    },
    {
      "step": 89,
      "loss": 0.39359551668167114,
      "accuracy": 0.25,
      "grad_norm": 1.957063913345337
    },
    {
      "step": 90,
      "loss": 0.2664315104484558,
      "accuracy": 0.5625,
      "grad_norm": 2.1246113777160645
    },
    {
      "step": 91,
      "loss": 0.3553658425807953,
      "accuracy": 0.4375,
      "grad_norm": 2.6919169425964355
    },
    {
      "step": 92,
      "loss": 0.3332803547382355,
      "accuracy": 0.4375,
      "grad_norm": 3.0110740661621094
    },
    {
      "step": 93,
      "loss": 0.22993385791778564,
      "accuracy": 0.625,
      "grad_norm": 1.630307912826538
    },
    {
      "step": 94,
      "loss": 0.3462809920310974,
      "accuracy": 0.5,
      "grad_norm": 4.683339595794678
    },
    {
      "step": 95,
      "loss": 0.4192696213722229,
      "accuracy": 0.375,
      "grad_norm": 4.633235454559326
    },
    {
      "step": 96,
      "loss": 0.26481401920318604,
      "accuracy": 0.5625,
      "grad_norm": 1.9677928686141968
    },
    {
      "step": 97,
      "loss": 0.37387967109680176,
      "accuracy": 0.375,
      "grad_norm": 4.816346168518066
    },
    {
      "step": 98,
      "loss": 0.342069149017334,
      "accuracy": 0.375,
      "grad_norm": 5.296156883239746
    },
    {
      "step": 99,
      "loss": 0.3118915557861328,
      "accuracy": 0.375,
      "grad_norm": 2.54592227935791
    },
    {
      "step": 100,
      "loss": 0.39943888783454895,
      "accuracy": 0.3125,
      "grad_norm": 5.408413887023926
    },
    {
      "step": 101,
      "loss": 0.30378639698028564,
      "accuracy": 0.5625,
      "grad_norm": 1.8985086679458618
    },
    {
      "step": 102,
      "loss": 0.27662986516952515,
      "accuracy": 0.75,
      "grad_norm": 3.612004280090332
    },
    {
      "step": 103,
      "loss": 0.4424198567867279,
      "accuracy": 0.4375,
      "grad_norm": 4.661970138549805
    },
    {
      "step": 104,
      "loss": 0.23470093309879303,
      "accuracy": 0.5625,
      "grad_norm": 2.873141050338745
    },
    {
      "step": 105,
      "loss": 0.3936997950077057,
      "accuracy": 0.5,
      "grad_norm": 2.57281231880188
    },
    {
      "step": 106,
      "loss": 0.2279021441936493,
      "accuracy": 0.5625,
      "grad_norm": 4.335754871368408
    },
    {
      "step": 107,
      "loss": 0.3335988521575928,
      "accuracy": 0.625,
      "grad_norm": 4.470832347869873
    },
    {
      "step": 108,
      "loss": 0.347548246383667,
      "accuracy": 0.3125,
      "grad_norm": 2.8491415977478027
    },
    {
      "step": 109,
      "loss": 0.31375086307525635,
      "accuracy": 0.3125,
      "grad_norm": 3.7518725395202637
    },
    {
      "step": 110,
      "loss": 0.30487674474716187,
      "accuracy": 0.5625,
      "grad_norm": 2.6178364753723145
    },
    {
      "step": 111,
      "loss": 0.2880224585533142,
      "accuracy": 0.375,
      "grad_norm": 2.580764055252075
    },
    {
      "step": 112,
      "loss": 0.3441048264503479,
      "accuracy": 0.4375,
      "grad_norm": 3.2513346672058105
    },
    {
      "step": 113,
      "loss": 0.27432599663734436,
      "accuracy": 0.4375,
      "grad_norm": 4.303135871887207
    },
    {
      "step": 114,
      "loss": 0.3397113084793091,
      "accuracy": 0.25,
      "grad_norm": 5.987730026245117
    },
    {
      "step": 115,
      "loss": 0.3046596050262451,
      "accuracy": 0.375,
      "grad_norm": 4.729400634765625
    },
    {
      "step": 116,
      "loss": 0.2569054663181305,
      "accuracy": 0.6875,
      "grad_norm": 3.011622667312622
    },
    {
      "step": 117,
      "loss": 0.24722757935523987,
      "accuracy": 0.625,
      "grad_norm": 2.426645040512085
    },
    {
      "step": 118,
      "loss": 0.3313879668712616,
      "accuracy": 0.4375,
      "grad_norm": 3.805513858795166
    },
    {
      "step": 119,
      "loss": 0.3092272877693176,
      "accuracy": 0.5,
      "grad_norm": 2.956968069076538
    },
    {
      "step": 120,
      "loss": 0.28871893882751465,
      "accuracy": 0.4375,
      "grad_norm": 5.1243414878845215
    },
    {
      "step": 121,
      "loss": 0.39535412192344666,
      "accuracy": 0.4375,
      "grad_norm": 5.512287616729736
    },
    {
      "step": 122,
      "loss": 0.2767881155014038,
      "accuracy": 0.5625,
      "grad_norm": 4.03872537612915
    },
    {
      "step": 123,
      "loss": 0.246265709400177,
      "accuracy": 0.625,
      "grad_norm": 1.8073145151138306
    },
    {
      "step": 124,
      "loss": 0.22024264931678772,
      "accuracy": 0.5625,
      "grad_norm": 2.9178218841552734
    },
    {
      "step": 125,
      "loss": 0.3375374674797058,
      "accuracy": 0.375,
      "grad_norm": 6.0035529136657715
    },
    {
      "step": 126,
      "loss": 0.291542649269104,
      "accuracy": 0.5625,
      "grad_norm": 3.1244823932647705
    },
    {
      "step": 127,
      "loss": 0.2841530740261078,
      "accuracy": 0.4375,
      "grad_norm": 3.943956136703491
    },
    {
      "step": 128,
      "loss": 0.37617459893226624,
      "accuracy": 0.5,
      "grad_norm": 3.2875564098358154
    },
    {
      "step": 129,
      "loss": 0.23183754086494446,
      "accuracy": 0.6875,
      "grad_norm": 3.1421420574188232
    },
    {
      "step": 130,
      "loss": 0.2690078020095825,
      "accuracy": 0.625,
      "grad_norm": 2.172236680984497
    },
    {
      "step": 131,
      "loss": 0.3702274560928345,
      "accuracy": 0.625,
      "grad_norm": 4.3672871589660645
    },
    {
      "step": 132,
      "loss": 0.34746241569519043,
      "accuracy": 0.4375,
      "grad_norm": 6.704164981842041
    },
    {
      "step": 133,
      "loss": 0.42645594477653503,
      "accuracy": 0.375,
      "grad_norm": 7.411233425140381
    },
    {
      "step": 134,
      "loss": 0.2996973991394043,
      "accuracy": 0.5,
      "grad_norm": 4.0590901374816895
    },
    {
      "step": 135,
      "loss": 0.29368990659713745,
      "accuracy": 0.4375,
      "grad_norm": 4.724409580230713
    },
    {
      "step": 136,
      "loss": 0.32345086336135864,
      "accuracy": 0.375,
      "grad_norm": 3.153040647506714
    },
    {
      "step": 137,
      "loss": 0.2868388295173645,
      "accuracy": 0.6875,
      "grad_norm": 2.7023439407348633
    },
    {
      "step": 138,
      "loss": 0.40661805868148804,
      "accuracy": 0.3125,
      "grad_norm": 3.84387469291687
    },
    {
      "step": 139,
      "loss": 0.26699239015579224,
      "accuracy": 0.5,
      "grad_norm": 4.057785987854004
    },
    {
      "step": 140,
      "loss": 0.26314669847488403,
      "accuracy": 0.625,
      "grad_norm": 2.206054449081421
    },
    {
      "step": 141,
      "loss": 0.259967565536499,
      "accuracy": 0.75,
      "grad_norm": 3.3411054611206055
    },
    {
      "step": 142,
      "loss": 0.32370808720588684,
      "accuracy": 0.5,
      "grad_norm": 3.6239993572235107
    },
    {
      "step": 143,
      "loss": 0.26969364285469055,
      "accuracy": 0.5625,
      "grad_norm": 2.4979305267333984
    },
    {
      "step": 144,
      "loss": 0.28202366828918457,
      "accuracy": 0.625,
      "grad_norm": 3.3847577571868896
    },
    {
      "step": 145,
      "loss": 0.25201621651649475,
      "accuracy": 0.625,
      "grad_norm": 3.477491617202759
    },
    {
      "step": 146,
      "loss": 0.23821315169334412,
      "accuracy": 0.625,
      "grad_norm": 2.9706358909606934
    },
    {
      "step": 147,
      "loss": 0.238008514046669,
      "accuracy": 0.6875,
      "grad_norm": 2.7410402297973633
    },
    {
      "step": 148,
      "loss": 0.1718825101852417,
      "accuracy": 0.75,
      "grad_norm": 1.4172474145889282
    },
    {
      "step": 149,
      "loss": 0.3656628131866455,
      "accuracy": 0.5,
      "grad_norm": 3.069338798522949
    },
    {
      "step": 150,
      "loss": 0.3841342031955719,
      "accuracy": 0.5625,
      "grad_norm": 5.45265531539917
    },
    {
      "step": 151,
      "loss": 0.27660343050956726,
      "accuracy": 0.5,
      "grad_norm": 3.10372257232666
    },
    {
      "step": 152,
      "loss": 0.30429917573928833,
      "accuracy": 0.5,
      "grad_norm": 4.1334147453308105
    },
    {
      "step": 153,
      "loss": 0.32354825735092163,
      "accuracy": 0.4375,
      "grad_norm": 3.813908576965332
    },
    {
      "step": 154,
      "loss": 0.24782373011112213,
      "accuracy": 0.625,
      "grad_norm": 3.492002487182617
    },
    {
      "step": 155,
      "loss": 0.2495507001876831,
      "accuracy": 0.5625,
      "grad_norm": 1.8238885402679443
    },
    {
      "step": 156,
      "loss": 0.23323291540145874,
      "accuracy": 0.6875,
      "grad_norm": 3.32261061668396
    },
    {
      "step": 157,
      "loss": 0.238906592130661,
      "accuracy": 0.5625,
      "grad_norm": 3.1056087017059326
    },
    {
      "step": 158,
      "loss": 0.31793782114982605,
      "accuracy": 0.5,
      "grad_norm": 2.5997304916381836
    },
    {
      "step": 159,
      "loss": 0.35122036933898926,
      "accuracy": 0.375,
      "grad_norm": 4.499612331390381
    },
    {
      "step": 160,
      "loss": 0.24174368381500244,
      "accuracy": 0.5,
      "grad_norm": 4.45612907409668
    },
    {
      "step": 161,
      "loss": 0.29831743240356445,
      "accuracy": 0.5625,
      "grad_norm": 4.010859966278076
    },
    {
      "step": 162,
      "loss": 0.3761734366416931,
      "accuracy": 0.4375,
      "grad_norm": 2.431657075881958
    },
    {
      "step": 163,
      "loss": 0.22226308286190033,
      "accuracy": 0.6875,
      "grad_norm": 3.03590726852417
    },
    {
      "step": 164,
      "loss": 0.38761115074157715,
      "accuracy": 0.3125,
      "grad_norm": 5.776550769805908
    },
    {
      "step": 165,
      "loss": 0.23566368222236633,
      "accuracy": 0.5625,
      "grad_norm": 1.4035736322402954
    },
    {
      "step": 166,
      "loss": 0.3308826684951782,
      "accuracy": 0.4375,
      "grad_norm": 4.535194396972656
    },
    {
      "step": 167,
      "loss": 0.20905731618404388,
      "accuracy": 0.5625,
      "grad_norm": 1.6931453943252563
    },
    {
      "step": 168,
      "loss": 0.18819597363471985,
      "accuracy": 0.8125,
      "grad_norm": 3.4188976287841797
    },
    {
      "step": 169,
      "loss": 0.28450697660446167,
      "accuracy": 0.4375,
      "grad_norm": 3.1033687591552734
    },
    {
      "step": 170,
      "loss": 0.19752249121665955,
      "accuracy": 0.625,
      "grad_norm": 1.9121142625808716
    },
    {
      "step": 171,
      "loss": 0.33150193095207214,
      "accuracy": 0.5625,
      "grad_norm": 3.518537998199463
    },
    {
      "step": 172,
      "loss": 0.22002673149108887,
      "accuracy": 0.625,
      "grad_norm": 2.3495395183563232
    },
    {
      "step": 173,
      "loss": 0.22015626728534698,
      "accuracy": 0.75,
      "grad_norm": 2.7596793174743652
    },
    {
      "step": 174,
      "loss": 0.280905544757843,
      "accuracy": 0.375,
      "grad_norm": 2.916355848312378
    },
    {
      "step": 175,
      "loss": 0.27490976452827454,
      "accuracy": 0.5,
      "grad_norm": 2.4129087924957275
    },
    {
      "step": 176,
      "loss": 0.1746031939983368,
      "accuracy": 0.8125,
      "grad_norm": 3.1600944995880127
    },
    {
      "step": 177,
      "loss": 0.29252320528030396,
      "accuracy": 0.25,
      "grad_norm": 4.117611408233643
    },
    {
      "step": 178,
      "loss": 0.17068058252334595,
      "accuracy": 0.75,
      "grad_norm": 2.376662015914917
    },
    {
      "step": 179,
      "loss": 0.49198517203330994,
      "accuracy": 0.25,
      "grad_norm": 8.785408020019531
    },
    {
      "step": 180,
      "loss": 0.41787809133529663,
      "accuracy": 0.375,
      "grad_norm": 6.759766578674316
    },
    {
      "step": 181,
      "loss": 0.22521397471427917,
      "accuracy": 0.6875,
      "grad_norm": 3.169238567352295
    },
    {
      "step": 182,
      "loss": 0.24463915824890137,
      "accuracy": 0.4375,
      "grad_norm": 2.74796986579895
    },
    {
      "step": 183,
      "loss": 0.20547428727149963,
      "accuracy": 0.625,
      "grad_norm": 1.7496074438095093
    },
    {
      "step": 184,
      "loss": 0.1649724245071411,
      "accuracy": 0.6875,
      "grad_norm": 1.4739062786102295
    },
    {
      "step": 185,
      "loss": 0.307851642370224,
      "accuracy": 0.4375,
      "grad_norm": 5.238747596740723
    },
    {
      "step": 186,
      "loss": 0.25326305627822876,
      "accuracy": 0.5625,
      "grad_norm": 3.020547389984131
    },
    {
      "step": 187,
      "loss": 0.24819257855415344,
      "accuracy": 0.5,
      "grad_norm": 2.64577054977417
    },
    {
      "step": 188,
      "loss": 0.27652496099472046,
      "accuracy": 0.625,
      "grad_norm": 3.17374324798584
    },
    {
      "step": 189,
      "loss": 0.34577125310897827,
      "accuracy": 0.5625,
      "grad_norm": 5.108368396759033
    },
    {
      "step": 190,
      "loss": 0.15891700983047485,
      "accuracy": 0.875,
      "grad_norm": 1.713796615600586
    },
    {
      "step": 191,
      "loss": 0.43840038776397705,
      "accuracy": 0.5,
      "grad_norm": 3.089289426803589
    },
    {
      "step": 192,
      "loss": 0.4265260696411133,
      "accuracy": 0.1875,
      "grad_norm": 3.9653568267822266
    },
    {
      "step": 193,
      "loss": 0.4333072304725647,
      "accuracy": 0.375,
      "grad_norm": 4.8013529777526855
    },
    {
      "step": 194,
      "loss": 0.24284300208091736,
      "accuracy": 0.625,
      "grad_norm": 3.789696216583252
    },
    {
      "step": 195,
      "loss": 0.19274044036865234,
      "accuracy": 0.625,
      "grad_norm": 2.20851993560791
    },
    {
      "step": 196,
      "loss": 0.2509724795818329,
      "accuracy": 0.5,
      "grad_norm": 2.6938424110412598
    },
    {
      "step": 197,
      "loss": 0.2464088648557663,
      "accuracy": 0.5625,
      "grad_norm": 2.8331809043884277
    },
    {
      "step": 198,
      "loss": 0.23174059391021729,
      "accuracy": 0.5625,
      "grad_norm": 2.674978256225586
    },
    {
      "step": 199,
      "loss": 0.28461408615112305,
      "accuracy": 0.375,
      "grad_norm": 4.364687442779541
    },
    {
      "step": 200,
      "loss": 0.289457231760025,
      "accuracy": 0.5,
      "grad_norm": 4.63718318939209
    },
    {
      "step": 201,
      "loss": 0.4219830632209778,
      "accuracy": 0.5,
      "grad_norm": 5.479804515838623
    },
    {
      "step": 202,
      "loss": 0.3141675591468811,
      "accuracy": 0.5625,
      "grad_norm": 6.1047797203063965
    },
    {
      "step": 203,
      "loss": 0.27403154969215393,
      "accuracy": 0.5625,
      "grad_norm": 1.967947006225586
    },
    {
      "step": 204,
      "loss": 0.2852989137172699,
      "accuracy": 0.4375,
      "grad_norm": 3.297654151916504
    },
    {
      "step": 205,
      "loss": 0.2116539180278778,
      "accuracy": 0.6875,
      "grad_norm": 2.9721405506134033
    },
    {
      "step": 206,
      "loss": 0.37302395701408386,
      "accuracy": 0.5,
      "grad_norm": 2.7485713958740234
    },
    {
      "step": 207,
      "loss": 0.2161908894777298,
      "accuracy": 0.625,
      "grad_norm": 3.3413209915161133
    },
    {
      "step": 208,
      "loss": 0.33027851581573486,
      "accuracy": 0.4375,
      "grad_norm": 3.466046094894409
    },
    {
      "step": 209,
      "loss": 0.2386871874332428,
      "accuracy": 0.625,
      "grad_norm": 4.497164249420166
    },
    {
      "step": 210,
      "loss": 0.5376440286636353,
      "accuracy": 0.25,
      "grad_norm": 5.598645210266113
    },
    {
      "step": 211,
      "loss": 0.11602962762117386,
      "accuracy": 0.8125,
      "grad_norm": 4.2076287269592285
    },
    {
      "step": 212,
      "loss": 0.334348201751709,
      "accuracy": 0.6875,
      "grad_norm": 4.085982799530029
    },
    {
      "step": 213,
      "loss": 0.23172461986541748,
      "accuracy": 0.5625,
      "grad_norm": 2.726374626159668
    },
    {
      "step": 214,
      "loss": 0.271198034286499,
      "accuracy": 0.625,
      "grad_norm": 3.9871957302093506
    },
    {
      "step": 215,
      "loss": 0.3264566957950592,
      "accuracy": 0.625,
      "grad_norm": 3.4897143840789795
    },
    {
      "step": 216,
      "loss": 0.23223070800304413,
      "accuracy": 0.375,
      "grad_norm": 2.0059635639190674
    },
    {
      "step": 217,
      "loss": 0.29139623045921326,
      "accuracy": 0.375,
      "grad_norm": 3.1312263011932373
    },
    {
      "step": 218,
      "loss": 0.21596628427505493,
      "accuracy": 0.6875,
      "grad_norm": 2.8443262577056885
    },
    {
      "step": 219,
      "loss": 0.255964457988739,
      "accuracy": 0.625,
      "grad_norm": 2.852794647216797
    },
    {
      "step": 220,
      "loss": 0.2111554741859436,
      "accuracy": 0.75,
      "grad_norm": 2.725229263305664
    },
    {
      "step": 221,
      "loss": 0.2635425329208374,
      "accuracy": 0.8125,
      "grad_norm": 3.417090654373169
    },
    {
      "step": 222,
      "loss": 0.28168290853500366,
      "accuracy": 0.4375,
      "grad_norm": 3.3071939945220947
    },
    {
      "step": 223,
      "loss": 0.23879499733448029,
      "accuracy": 0.4375,
      "grad_norm": 2.0534191131591797
    },
    {
      "step": 224,
      "loss": 0.2916821837425232,
      "accuracy": 0.5625,
      "grad_norm": 3.395354986190796
    },
    {
      "step": 225,
      "loss": 0.3008136749267578,
      "accuracy": 0.5,
      "grad_norm": 3.0169804096221924
    },
    {
      "step": 226,
      "loss": 0.28453874588012695,
      "accuracy": 0.5,
      "grad_norm": 3.3379974365234375
    },
    {
      "step": 227,
      "loss": 0.17319723963737488,
      "accuracy": 0.6875,
      "grad_norm": 2.6580357551574707
    },
    {
      "step": 228,
      "loss": 0.26641249656677246,
      "accuracy": 0.5,
      "grad_norm": 2.6323251724243164
    },
    {
      "step": 229,
      "loss": 0.19109296798706055,
      "accuracy": 0.6875,
      "grad_norm": 1.6775808334350586
    },
    {
      "step": 230,
      "loss": 0.3063760995864868,
      "accuracy": 0.5,
      "grad_norm": 3.1033966541290283
    },
    {
      "step": 231,
      "loss": 0.31509339809417725,
      "accuracy": 0.375,
      "grad_norm": 4.976998805999756
    },
    {
      "step": 232,
      "loss": 0.2002318799495697,
      "accuracy": 0.6875,
      "grad_norm": 2.1191630363464355
    },
    {
      "step": 233,
      "loss": 0.25165852904319763,
      "accuracy": 0.6875,
      "grad_norm": 2.351508617401123
    },
    {
      "step": 234,
      "loss": 0.48350146412849426,
      "accuracy": 0.4375,
      "grad_norm": 3.7625837326049805
    },
    {
      "step": 235,
      "loss": 0.3546670377254486,
      "accuracy": 0.375,
      "grad_norm": 5.780008316040039
    },
    {
      "step": 236,
      "loss": 0.11882121860980988,
      "accuracy": 0.9375,
      "grad_norm": 1.8411431312561035
    },
    {
      "step": 237,
      "loss": 0.13091149926185608,
      "accuracy": 0.8125,
      "grad_norm": 1.400091528892517
    },
    {
      "step": 238,
      "loss": 0.26808491349220276,
      "accuracy": 0.5625,
      "grad_norm": 3.06486439704895
    },
    {
      "step": 239,
      "loss": 0.26561278104782104,
      "accuracy": 0.6875,
      "grad_norm": 2.4942312240600586
    },
    {
      "step": 240,
      "loss": 0.3706085681915283,
      "accuracy": 0.5625,
      "grad_norm": 2.8402843475341797
    },
    {
      "step": 241,
      "loss": 0.28587809205055237,
      "accuracy": 0.6875,
      "grad_norm": 3.3501482009887695
    },
    {
      "step": 242,
      "loss": 0.29862651228904724,
      "accuracy": 0.75,
      "grad_norm": 2.8303568363189697
    },
    {
      "step": 243,
      "loss": 0.16250742971897125,
      "accuracy": 0.625,
      "grad_norm": 3.4215087890625
    },
    {
      "step": 244,
      "loss": 0.2270752638578415,
      "accuracy": 0.6875,
      "grad_norm": 2.216356039047241
    },
    {
      "step": 245,
      "loss": 0.17338955402374268,
      "accuracy": 0.75,
      "grad_norm": 1.83214271068573
    },
    {
      "step": 246,
      "loss": 0.25967997312545776,
      "accuracy": 0.625,
      "grad_norm": 2.550733804702759
    },
    {
      "step": 247,
      "loss": 0.12479250133037567,
      "accuracy": 0.875,
      "grad_norm": 1.368708610534668
    },
    {
      "step": 248,
      "loss": 0.22286909818649292,
      "accuracy": 0.625,
      "grad_norm": 3.099350929260254
    },
    {
      "step": 249,
      "loss": 0.29532596468925476,
      "accuracy": 0.4375,
      "grad_norm": 3.45442271232605
    },
    {
      "step": 250,
      "loss": 0.16435478627681732,
      "accuracy": 0.75,
      "grad_norm": 1.9692617654800415
    },
    {
      "step": 251,
      "loss": 0.24906790256500244,
      "accuracy": 0.625,
      "grad_norm": 1.6469305753707886
    },
    {
      "step": 252,
      "loss": 0.3590490221977234,
      "accuracy": 0.5625,
      "grad_norm": 2.5375828742980957
    },
    {
      "step": 253,
      "loss": 0.1988132894039154,
      "accuracy": 0.5,
      "grad_norm": 2.5732855796813965
    },
    {
      "step": 254,
      "loss": 0.2283896803855896,
      "accuracy": 0.5625,
      "grad_norm": 2.2704405784606934
    },
    {
      "step": 255,
      "loss": 0.32236969470977783,
      "accuracy": 0.4375,
      "grad_norm": 3.0623481273651123
    },
    {
      "step": 256,
      "loss": 0.30924949049949646,
      "accuracy": 0.5,
      "grad_norm": 1.67529296875
    },
    {
      "step": 257,
      "loss": 0.20715254545211792,
      "accuracy": 0.75,
      "grad_norm": 2.1475515365600586
    },
    {
      "step": 258,
      "loss": 0.4155654311180115,
      "accuracy": 0.6875,
      "grad_norm": 4.235153675079346
    },
    {
      "step": 259,
      "loss": 0.18442648649215698,
      "accuracy": 0.625,
      "grad_norm": 2.1749184131622314
    },
    {
      "step": 260,
      "loss": 0.19389708340168,
      "accuracy": 0.75,
      "grad_norm": 1.590395212173462
    },
    {
      "step": 261,
      "loss": 0.1577853113412857,
      "accuracy": 0.6875,
      "grad_norm": 1.3433725833892822
    },
    {
      "step": 262,
      "loss": 0.21961118280887604,
      "accuracy": 0.5625,
      "grad_norm": 2.526822566986084
    },
    {
      "step": 263,
      "loss": 0.20971883833408356,
      "accuracy": 0.6875,
      "grad_norm": 2.3153529167175293
    },
    {
      "step": 264,
      "loss": 0.22177718579769135,
      "accuracy": 0.5625,
      "grad_norm": 4.265530109405518
    },
    {
      "step": 265,
      "loss": 0.24107782542705536,
      "accuracy": 0.6875,
      "grad_norm": 2.777202606201172
    },
    {
      "step": 266,
      "loss": 0.2810448408126831,
      "accuracy": 0.4375,
      "grad_norm": 2.8867883682250977
    },
    {
      "step": 267,
      "loss": 0.23073583841323853,
      "accuracy": 0.5,
      "grad_norm": 2.3593356609344482
    },
    {
      "step": 268,
      "loss": 0.26154401898384094,
      "accuracy": 0.5,
      "grad_norm": 4.00946044921875
    },
    {
      "step": 269,
      "loss": 0.20723193883895874,
      "accuracy": 0.6875,
      "grad_norm": 2.580604314804077
    },
    {
      "step": 270,
      "loss": 0.18061229586601257,
      "accuracy": 0.625,
      "grad_norm": 1.863582968711853
    },
    {
      "step": 271,
      "loss": 0.15351569652557373,
      "accuracy": 0.8125,
      "grad_norm": 2.1092264652252197
    },
    {
      "step": 272,
      "loss": 0.22617915272712708,
      "accuracy": 0.625,
      "grad_norm": 1.5853197574615479
    },
    {
      "step": 273,
      "loss": 0.16629715263843536,
      "accuracy": 0.75,
      "grad_norm": 1.7059119939804077
    },
    {
      "step": 274,
      "loss": 0.22031420469284058,
      "accuracy": 0.625,
      "grad_norm": 3.5349416732788086
    },
    {
      "step": 275,
      "loss": 0.15107953548431396,
      "accuracy": 0.8125,
      "grad_norm": 1.0124304294586182
    },
    {
      "step": 276,
      "loss": 0.18409991264343262,
      "accuracy": 0.6875,
      "grad_norm": 2.27958607673645
    },
    {
      "step": 277,
      "loss": 0.3415505290031433,
      "accuracy": 0.1875,
      "grad_norm": 6.357967376708984
    },
    {
      "step": 278,
      "loss": 0.38849398493766785,
      "accuracy": 0.5,
      "grad_norm": 6.186563014984131
    },
    {
      "step": 279,
      "loss": 0.29606693983078003,
      "accuracy": 0.5,
      "grad_norm": 4.103756427764893
    },
    {
      "step": 280,
      "loss": 0.23076914250850677,
      "accuracy": 0.6875,
      "grad_norm": 2.7396719455718994
    },
    {
      "step": 281,
      "loss": 0.31121712923049927,
      "accuracy": 0.6875,
      "grad_norm": 2.893933057785034
    },
    {
      "step": 282,
      "loss": 0.2903035581111908,
      "accuracy": 0.625,
      "grad_norm": 1.7679307460784912
    },
    {
      "step": 283,
      "loss": 0.18435099720954895,
      "accuracy": 0.625,
      "grad_norm": 3.867314577102661
    },
    {
      "step": 284,
      "loss": 0.14044082164764404,
      "accuracy": 0.75,
      "grad_norm": 1.702566385269165
    },
    {
      "step": 285,
      "loss": 0.27253830432891846,
      "accuracy": 0.5,
      "grad_norm": 4.1553239822387695
    },
    {
      "step": 286,
      "loss": 0.183359295129776,
      "accuracy": 0.5625,
      "grad_norm": 2.6959545612335205
    },
    {
      "step": 287,
      "loss": 0.3676624894142151,
      "accuracy": 0.375,
      "grad_norm": 1.789454698562622
    },
    {
      "step": 288,
      "loss": 0.32233744859695435,
      "accuracy": 0.5,
      "grad_norm": 6.021841049194336
    },
    {
      "step": 289,
      "loss": 0.3584395945072174,
      "accuracy": 0.4375,
      "grad_norm": 5.5157470703125
    },
    {
      "step": 290,
      "loss": 0.18398365378379822,
      "accuracy": 0.625,
      "grad_norm": 2.0530099868774414
    },
    {
      "step": 291,
      "loss": 0.3241506516933441,
      "accuracy": 0.5625,
      "grad_norm": 4.565909385681152
    },
    {
      "step": 292,
      "loss": 0.24951769411563873,
      "accuracy": 0.75,
      "grad_norm": 3.080761432647705
    },
    {
      "step": 293,
      "loss": 0.20671944320201874,
      "accuracy": 0.625,
      "grad_norm": 1.8390839099884033
    },
    {
      "step": 294,
      "loss": 0.3070606589317322,
      "accuracy": 0.625,
      "grad_norm": 3.3866329193115234
    },
    {
      "step": 295,
      "loss": 0.3342132568359375,
      "accuracy": 0.375,
      "grad_norm": 5.683109283447266
    },
    {
      "step": 296,
      "loss": 0.47474852204322815,
      "accuracy": 0.5,
      "grad_norm": 8.045215606689453
    },
    {
      "step": 297,
      "loss": 0.3494730591773987,
      "accuracy": 0.5625,
      "grad_norm": 5.112429618835449
    },
    {
      "step": 298,
      "loss": 0.33218058943748474,
      "accuracy": 0.5625,
      "grad_norm": 3.080864429473877
    },
    {
      "step": 299,
      "loss": 0.21811339259147644,
      "accuracy": 0.4375,
      "grad_norm": 3.624037265777588
    },
    {
      "step": 300,
      "loss": 0.2552957534790039,
      "accuracy": 0.625,
      "grad_norm": 1.978061318397522
    },
    {
      "step": 301,
      "loss": 0.3294735550880432,
      "accuracy": 0.5,
      "grad_norm": 8.74756145477295
    },
    {
      "step": 302,
      "loss": 0.54665607213974,
      "accuracy": 0.3125,
      "grad_norm": 11.000391006469727
    },
    {
      "step": 303,
      "loss": 0.4154835343360901,
      "accuracy": 0.5,
      "grad_norm": 5.730517864227295
    },
    {
      "step": 304,
      "loss": 0.3298948407173157,
      "accuracy": 0.5625,
      "grad_norm": 5.806608200073242
    },
    {
      "step": 305,
      "loss": 0.3751232326030731,
      "accuracy": 0.5,
      "grad_norm": 6.150837421417236
    },
    {
      "step": 306,
      "loss": 0.19450023770332336,
      "accuracy": 0.5625,
      "grad_norm": 3.2480387687683105
    },
    {
      "step": 307,
      "loss": 0.20485863089561462,
      "accuracy": 0.5625,
      "grad_norm": 1.4502860307693481
    },
    {
      "step": 308,
      "loss": 0.1860615760087967,
      "accuracy": 0.625,
      "grad_norm": 2.4032251834869385
    },
    {
      "step": 309,
      "loss": 0.15103232860565186,
      "accuracy": 0.6875,
      "grad_norm": 1.270204782485962
    },
    {
      "step": 310,
      "loss": 0.26549026370048523,
      "accuracy": 0.5625,
      "grad_norm": 3.3066697120666504
    },
    {
      "step": 311,
      "loss": 0.2031850665807724,
      "accuracy": 0.5625,
      "grad_norm": 2.512636423110962
    },
    {
      "step": 312,
      "loss": 0.26474902033805847,
      "accuracy": 0.6875,
      "grad_norm": 1.3838056325912476
    },
    {
      "step": 313,
      "loss": 0.21895524859428406,
      "accuracy": 0.5,
      "grad_norm": 2.9663503170013428
    },
    {
      "step": 314,
      "loss": 0.2978147268295288,
      "accuracy": 0.5,
      "grad_norm": 3.4801347255706787
    },
    {
      "step": 315,
      "loss": 0.3804726004600525,
      "accuracy": 0.375,
      "grad_norm": 4.373312473297119
    },
    {
      "step": 316,
      "loss": 0.21306921541690826,
      "accuracy": 0.625,
      "grad_norm": 2.9482643604278564
    },
    {
      "step": 317,
      "loss": 0.34220460057258606,
      "accuracy": 0.5625,
      "grad_norm": 2.512096643447876
    },
    {
      "step": 318,
      "loss": 0.26138797402381897,
      "accuracy": 0.5625,
      "grad_norm": 3.1200382709503174
    },
    {
      "step": 319,
      "loss": 0.4550725221633911,
      "accuracy": 0.4375,
      "grad_norm": 4.407790184020996
    },
    {
      "step": 320,
      "loss": 0.3042650818824768,
      "accuracy": 0.5,
      "grad_norm": 3.3021581172943115
    },
    {
      "step": 321,
      "loss": 0.3213050365447998,
      "accuracy": 0.5625,
      "grad_norm": 2.778073310852051
    },
    {
      "step": 322,
      "loss": 0.4696435332298279,
      "accuracy": 0.5,
      "grad_norm": 3.3509109020233154
    },
    {
      "step": 323,
      "loss": 0.22366608679294586,
      "accuracy": 0.625,
      "grad_norm": 2.593324661254883
    },
    {
      "step": 324,
      "loss": 0.13543131947517395,
      "accuracy": 0.75,
      "grad_norm": 1.5267677307128906
    },
    {
      "step": 325,
      "loss": 0.17674103379249573,
      "accuracy": 0.875,
      "grad_norm": 1.5137829780578613
    },
    {
      "step": 326,
      "loss": 0.32564079761505127,
      "accuracy": 0.5,
      "grad_norm": 2.9117348194122314
    },
    {
      "step": 327,
      "loss": 0.24824956059455872,
      "accuracy": 0.5625,
      "grad_norm": 2.2769625186920166
    },
    {
      "step": 328,
      "loss": 0.2497279942035675,
      "accuracy": 0.4375,
      "grad_norm": 2.3867015838623047
    },
    {
      "step": 329,
      "loss": 0.18465903401374817,
      "accuracy": 0.75,
      "grad_norm": 1.9027833938598633
    },
    {
      "step": 330,
      "loss": 0.174151211977005,
      "accuracy": 0.6875,
      "grad_norm": 2.2306315898895264
    },
    {
      "step": 331,
      "loss": 0.28517764806747437,
      "accuracy": 0.375,
      "grad_norm": 1.7986299991607666
    },
    {
      "step": 332,
      "loss": 0.2768562436103821,
      "accuracy": 0.4375,
      "grad_norm": 2.663020610809326
    },
    {
      "step": 333,
      "loss": 0.1644534468650818,
      "accuracy": 0.6875,
      "grad_norm": 1.9116437435150146
    },
    {
      "step": 334,
      "loss": 0.21919351816177368,
      "accuracy": 0.5625,
      "grad_norm": 1.050956130027771
    },
    {
      "step": 335,
      "loss": 0.22611570358276367,
      "accuracy": 0.4375,
      "grad_norm": 1.6204051971435547
    },
    {
      "step": 336,
      "loss": 0.18390649557113647,
      "accuracy": 0.625,
      "grad_norm": 1.5695436000823975
    },
    {
      "step": 337,
      "loss": 0.2391451895236969,
      "accuracy": 0.5625,
      "grad_norm": 2.446153163909912
    },
    {
      "step": 338,
      "loss": 0.17115521430969238,
      "accuracy": 0.625,
      "grad_norm": 2.02543568611145
    },
    {
      "step": 339,
      "loss": 0.2096448838710785,
      "accuracy": 0.5625,
      "grad_norm": 2.831618547439575
    },
    {
      "step": 340,
      "loss": 0.14691662788391113,
      "accuracy": 0.75,
      "grad_norm": 1.1732770204544067
    },
    {
      "step": 341,
      "loss": 0.31042423844337463,
      "accuracy": 0.5625,
      "grad_norm": 2.3465914726257324
    },
    {
      "step": 342,
      "loss": 0.14983811974525452,
      "accuracy": 0.6875,
      "grad_norm": 2.2869083881378174
    },
    {
      "step": 343,
      "loss": 0.2522297501564026,
      "accuracy": 0.5625,
      "grad_norm": 2.223118782043457
    },
    {
      "step": 344,
      "loss": 0.2170725166797638,
      "accuracy": 0.5625,
      "grad_norm": 2.876210927963257
    },
    {
      "step": 345,
      "loss": 0.16427096724510193,
      "accuracy": 0.75,
      "grad_norm": 1.4880430698394775
    },
    {
      "step": 346,
      "loss": 0.31368815898895264,
      "accuracy": 0.5,
      "grad_norm": 2.2817602157592773
    },
    {
      "step": 347,
      "loss": 0.2713402211666107,
      "accuracy": 0.5,
      "grad_norm": 2.434187889099121
    },
    {
      "step": 348,
      "loss": 0.17154407501220703,
      "accuracy": 0.6875,
      "grad_norm": 2.4456381797790527
    },
    {
      "step": 349,
      "loss": 0.27588149905204773,
      "accuracy": 0.5625,
      "grad_norm": 2.0332446098327637
    },
    {
      "step": 350,
      "loss": 0.24252402782440186,
      "accuracy": 0.5,
      "grad_norm": 2.893355369567871
    },
    {
      "step": 351,
      "loss": 0.2584662437438965,
      "accuracy": 0.6875,
      "grad_norm": 3.18426513671875
    },
    {
      "step": 352,
      "loss": 0.24797603487968445,
      "accuracy": 0.625,
      "grad_norm": 2.1979875564575195
    },
    {
      "step": 353,
      "loss": 0.18937411904335022,
      "accuracy": 0.625,
      "grad_norm": 1.7251697778701782
    },
    {
      "step": 354,
      "loss": 0.2929299473762512,
      "accuracy": 0.625,
      "grad_norm": 1.8643994331359863
    },
    {
      "step": 355,
      "loss": 0.1672574281692505,
      "accuracy": 0.6875,
      "grad_norm": 1.8142814636230469
    },
    {
      "step": 356,
      "loss": 0.18403448164463043,
      "accuracy": 0.75,
      "grad_norm": 2.32309889793396
    },
    {
      "step": 357,
      "loss": 0.19219571352005005,
      "accuracy": 0.875,
      "grad_norm": 1.038578987121582
    },
    {
      "step": 358,
      "loss": 0.2378988415002823,
      "accuracy": 0.5625,
      "grad_norm": 1.73770272731781
    },
    {
      "step": 359,
      "loss": 0.18261192739009857,
      "accuracy": 0.75,
      "grad_norm": 2.4290945529937744
    },
    {
      "step": 360,
      "loss": 0.15050747990608215,
      "accuracy": 0.75,
      "grad_norm": 1.4330151081085205
    },
    {
      "step": 361,
      "loss": 0.18644538521766663,
      "accuracy": 0.625,
      "grad_norm": 1.9865986108779907
    },
    {
      "step": 362,
      "loss": 0.17321887612342834,
      "accuracy": 0.6875,
      "grad_norm": 1.1393628120422363
    },
    {
      "step": 363,
      "loss": 0.20301848649978638,
      "accuracy": 0.625,
      "grad_norm": 2.128032684326172
    },
    {
      "step": 364,
      "loss": 0.23056091368198395,
      "accuracy": 0.5,
      "grad_norm": 2.6432604789733887
    },
    {
      "step": 365,
      "loss": 0.18003079295158386,
      "accuracy": 0.75,
      "grad_norm": 1.6986103057861328
    },
    {
      "step": 366,
      "loss": 0.19615018367767334,
      "accuracy": 0.5625,
      "grad_norm": 2.804955244064331
    },
    {
      "step": 367,
      "loss": 0.17511406540870667,
      "accuracy": 0.6875,
      "grad_norm": 1.84261155128479
    },
    {
      "step": 368,
      "loss": 0.15885156393051147,
      "accuracy": 0.625,
      "grad_norm": 1.9588038921356201
    },
    {
      "step": 369,
      "loss": 0.13836783170700073,
      "accuracy": 0.6875,
      "grad_norm": 1.4561877250671387
    },
    {
      "step": 370,
      "loss": 0.18426240980625153,
      "accuracy": 0.5,
      "grad_norm": 1.8392456769943237
    },
    {
      "step": 371,
      "loss": 0.28522372245788574,
      "accuracy": 0.4375,
      "grad_norm": 4.061978816986084
    },
    {
      "step": 372,
      "loss": 0.2194756269454956,
      "accuracy": 0.5625,
      "grad_norm": 3.004822015762329
    },
    {
      "step": 373,
      "loss": 0.30184271931648254,
      "accuracy": 0.5,
      "grad_norm": 4.174779891967773
    },
    {
      "step": 374,
      "loss": 0.17468971014022827,
      "accuracy": 0.6875,
      "grad_norm": 2.1659319400787354
    },
    {
      "step": 375,
      "loss": 0.35920462012290955,
      "accuracy": 0.5,
      "grad_norm": 2.8412909507751465
    },
    {
      "step": 376,
      "loss": 0.22693027555942535,
      "accuracy": 0.6875,
      "grad_norm": 3.645317554473877
    },
    {
      "step": 377,
      "loss": 0.18365949392318726,
      "accuracy": 0.75,
      "grad_norm": 3.747278928756714
    },
    {
      "step": 378,
      "loss": 0.3797074556350708,
      "accuracy": 0.625,
      "grad_norm": 2.493547201156616
    },
    {
      "step": 379,
      "loss": 0.17278090119361877,
      "accuracy": 0.75,
      "grad_norm": 1.7808823585510254
    },
    {
      "step": 380,
      "loss": 0.20665785670280457,
      "accuracy": 0.625,
      "grad_norm": 3.0486879348754883
    },
    {
      "step": 381,
      "loss": 0.23984232544898987,
      "accuracy": 0.625,
      "grad_norm": 3.0995988845825195
    },
    {
      "step": 382,
      "loss": 0.28964781761169434,
      "accuracy": 0.5625,
      "grad_norm": 6.460280895233154
    },
    {
      "step": 383,
      "loss": 0.28307175636291504,
      "accuracy": 0.6875,
      "grad_norm": 3.6484155654907227
    },
    {
      "step": 384,
      "loss": 0.2954356372356415,
      "accuracy": 0.5,
      "grad_norm": 5.01894474029541
    },
    {
      "step": 385,
      "loss": 0.20426137745380402,
      "accuracy": 0.75,
      "grad_norm": 3.834101438522339
    },
    {
      "step": 386,
      "loss": 0.15680550038814545,
      "accuracy": 0.75,
      "grad_norm": 2.611889123916626
    },
    {
      "step": 387,
      "loss": 0.16277241706848145,
      "accuracy": 0.8125,
      "grad_norm": 1.3842369318008423
    },
    {
      "step": 388,
      "loss": 0.13783065974712372,
      "accuracy": 0.8125,
      "grad_norm": 2.146010398864746
    },
    {
      "step": 389,
      "loss": 0.17205846309661865,
      "accuracy": 0.6875,
      "grad_norm": 1.1918307542800903
    },
    {
      "step": 390,
      "loss": 0.20911303162574768,
      "accuracy": 0.6875,
      "grad_norm": 3.5159730911254883
    },
    {
      "step": 391,
      "loss": 0.1633419394493103,
      "accuracy": 0.75,
      "grad_norm": 2.173788070678711
    },
    {
      "step": 392,
      "loss": 0.40701377391815186,
      "accuracy": 0.4375,
      "grad_norm": 3.5374112129211426
    },
    {
      "step": 393,
      "loss": 0.09375576674938202,
      "accuracy": 0.875,
      "grad_norm": 1.0278667211532593
    },
    {
      "step": 394,
      "loss": 0.14338600635528564,
      "accuracy": 0.6875,
      "grad_norm": 1.1209619045257568
    },
    {
      "step": 395,
      "loss": 0.12570583820343018,
      "accuracy": 0.6875,
      "grad_norm": 1.245053768157959
    },
    {
      "step": 396,
      "loss": 0.23664671182632446,
      "accuracy": 0.625,
      "grad_norm": 6.160830020904541
    },
    {
      "step": 397,
      "loss": 0.2225313037633896,
      "accuracy": 0.375,
      "grad_norm": 3.96053409576416
    },
    {
      "step": 398,
      "loss": 0.10044445097446442,
      "accuracy": 0.875,
      "grad_norm": 1.4734140634536743
    },
    {
      "step": 399,
      "loss": 0.16845768690109253,
      "accuracy": 0.8125,
      "grad_norm": 3.3908817768096924
    },
    {
      "step": 400,
      "loss": 0.1843763142824173,
      "accuracy": 0.625,
      "grad_norm": 3.000293254852295
    },
    {
      "step": 401,
      "loss": 0.0720381885766983,
      "accuracy": 0.9375,
      "grad_norm": 1.2689833641052246
    },
    {
      "step": 402,
      "loss": 0.1032300591468811,
      "accuracy": 0.75,
      "grad_norm": 2.1399190425872803
    },
    {
      "step": 403,
      "loss": 0.16972139477729797,
      "accuracy": 0.75,
      "grad_norm": 1.9469705820083618
    },
    {
      "step": 404,
      "loss": 0.2573124170303345,
      "accuracy": 0.5625,
      "grad_norm": 5.70734977722168
    },
    {
      "step": 405,
      "loss": 0.1958441436290741,
      "accuracy": 0.625,
      "grad_norm": 5.061769485473633
    },
    {
      "step": 406,
      "loss": 0.19207444787025452,
      "accuracy": 0.5,
      "grad_norm": 5.43450927734375
    },
    {
      "step": 407,
      "loss": 0.12137667834758759,
      "accuracy": 0.875,
      "grad_norm": 2.509913921356201
    },
    {
      "step": 408,
      "loss": 0.1053180992603302,
      "accuracy": 0.875,
      "grad_norm": 0.9936413764953613
    },
    {
      "step": 409,
      "loss": 0.1536014974117279,
      "accuracy": 0.6875,
      "grad_norm": 2.1659700870513916
    },
    {
      "step": 410,
      "loss": 0.06209444999694824,
      "accuracy": 0.9375,
      "grad_norm": 1.0016483068466187
    },
    {
      "step": 411,
      "loss": 0.21283122897148132,
      "accuracy": 0.5,
      "grad_norm": 1.3108412027359009
    },
    {
      "step": 412,
      "loss": 0.14251309633255005,
      "accuracy": 0.625,
      "grad_norm": 2.447221279144287
    },
    {
      "step": 413,
      "loss": 0.2305833399295807,
      "accuracy": 0.5625,
      "grad_norm": 3.7625880241394043
    },
    {
      "step": 414,
      "loss": 0.13868090510368347,
      "accuracy": 0.75,
      "grad_norm": 1.7079819440841675
    },
    {
      "step": 415,
      "loss": 0.29227548837661743,
      "accuracy": 0.5,
      "grad_norm": 1.8635344505310059
    },
    {
      "step": 416,
      "loss": 0.26850318908691406,
      "accuracy": 0.5625,
      "grad_norm": 6.24984073638916
    },
    {
      "step": 417,
      "loss": 0.2106662541627884,
      "accuracy": 0.625,
      "grad_norm": 1.845692753791809
    },
    {
      "step": 418,
      "loss": 0.1788882166147232,
      "accuracy": 0.625,
      "grad_norm": 2.620720863342285
    },
    {
      "step": 419,
      "loss": 0.20132507383823395,
      "accuracy": 0.8125,
      "grad_norm": 3.8876733779907227
    },
    {
      "step": 420,
      "loss": 0.2043904811143875,
      "accuracy": 0.6875,
      "grad_norm": 4.143001556396484
    },
    {
      "step": 421,
      "loss": 0.27361631393432617,
      "accuracy": 0.6875,
      "grad_norm": 7.42363977432251
    },
    {
      "step": 422,
      "loss": 0.1418888419866562,
      "accuracy": 0.875,
      "grad_norm": 1.9181255102157593
    },
    {
      "step": 423,
      "loss": 0.15605147182941437,
      "accuracy": 0.75,
      "grad_norm": 1.5544631481170654
    },
    {
      "step": 424,
      "loss": 0.164279043674469,
      "accuracy": 0.6875,
      "grad_norm": 6.364798069000244
    },
    {
      "step": 425,
      "loss": 0.20876967906951904,
      "accuracy": 0.5625,
      "grad_norm": 9.718680381774902
    },
    {
      "step": 426,
      "loss": 0.19080409407615662,
      "accuracy": 0.6875,
      "grad_norm": 2.7360339164733887
    },
    {
      "step": 427,
      "loss": 0.1560448706150055,
      "accuracy": 0.75,
      "grad_norm": 1.562556266784668
    },
    {
      "step": 428,
      "loss": 0.12466675788164139,
      "accuracy": 0.8125,
      "grad_norm": 1.6523529291152954
    },
    {
      "step": 429,
      "loss": 0.1685645580291748,
      "accuracy": 0.6875,
      "grad_norm": 7.15401029586792
    },
    {
      "step": 430,
      "loss": 0.16838333010673523,
      "accuracy": 0.75,
      "grad_norm": 2.376523017883301
    },
    {
      "step": 431,
      "loss": 0.08443807065486908,
      "accuracy": 0.875,
      "grad_norm": 1.7178984880447388
    },
    {
      "step": 432,
      "loss": 0.14005553722381592,
      "accuracy": 0.75,
      "grad_norm": 2.7724056243896484
    },
    {
      "step": 433,
      "loss": 0.10737308859825134,
      "accuracy": 0.8125,
      "grad_norm": 0.8877576589584351
    },
    {
      "step": 434,
      "loss": 0.2656095027923584,
      "accuracy": 0.5,
      "grad_norm": 7.095798969268799
    },
    {
      "step": 435,
      "loss": 0.144502192735672,
      "accuracy": 0.75,
      "grad_norm": 3.203108072280884
    },
    {
      "step": 436,
      "loss": 0.18440085649490356,
      "accuracy": 0.75,
      "grad_norm": 2.353748083114624
    },
    {
      "step": 437,
      "loss": 0.19230589270591736,
      "accuracy": 0.625,
      "grad_norm": 5.233445644378662
    },
    {
      "step": 438,
      "loss": 0.06060108169913292,
      "accuracy": 0.9375,
      "grad_norm": 1.150412917137146
    },
    {
      "step": 439,
      "loss": 0.12326125800609589,
      "accuracy": 0.8125,
      "grad_norm": 1.2539597749710083
    },
    {
      "step": 440,
      "loss": 0.11237778514623642,
      "accuracy": 0.8125,
      "grad_norm": 1.8167166709899902
    },
    {
      "step": 441,
      "loss": 0.13159769773483276,
      "accuracy": 0.75,
      "grad_norm": 2.5317890644073486
    },
    {
      "step": 442,
      "loss": 0.1042584776878357,
      "accuracy": 0.8125,
      "grad_norm": 1.3020800352096558
    },
    {
      "step": 443,
      "loss": 0.10059958696365356,
      "accuracy": 0.875,
      "grad_norm": 1.2715100049972534
    },
    {
      "step": 444,
      "loss": 0.08093224465847015,
      "accuracy": 0.9375,
      "grad_norm": 0.9964509010314941
    },
    {
      "step": 445,
      "loss": 0.14929020404815674,
      "accuracy": 0.875,
      "grad_norm": 2.1648550033569336
    },
    {
      "step": 446,
      "loss": 0.06989754736423492,
      "accuracy": 1.0,
      "grad_norm": 1.5992459058761597
    },
    {
      "step": 447,
      "loss": 0.24188031256198883,
      "accuracy": 0.6875,
      "grad_norm": 2.0987112522125244
    },
    {
      "step": 448,
      "loss": 0.11566054075956345,
      "accuracy": 0.75,
      "grad_norm": 4.4257731437683105
    },
    {
      "step": 449,
      "loss": 0.07534749805927277,
      "accuracy": 0.875,
      "grad_norm": 1.2943556308746338
    },
    {
      "step": 450,
      "loss": 0.09445077180862427,
      "accuracy": 0.75,
      "grad_norm": 1.08659029006958
    },
    {
      "step": 451,
      "loss": 0.19648629426956177,
      "accuracy": 0.75,
      "grad_norm": 3.214721441268921
    },
    {
      "step": 452,
      "loss": 0.2027081847190857,
      "accuracy": 0.6875,
      "grad_norm": 3.6648595333099365
    },
    {
      "step": 453,
      "loss": 0.0530124269425869,
      "accuracy": 0.9375,
      "grad_norm": 1.4332468509674072
    },
    {
      "step": 454,
      "loss": 0.20989327132701874,
      "accuracy": 0.8125,
      "grad_norm": 7.85159158706665
    },
    {
      "step": 455,
      "loss": 0.3266093134880066,
      "accuracy": 0.625,
      "grad_norm": 9.87344741821289
    },
    {
      "step": 456,
      "loss": 0.48577725887298584,
      "accuracy": 0.625,
      "grad_norm": 9.718685150146484
    },
    {
      "step": 457,
      "loss": 0.2483651041984558,
      "accuracy": 0.8125,
      "grad_norm": 6.7482075691223145
    },
    {
      "step": 458,
      "loss": 0.2688552737236023,
      "accuracy": 0.75,
      "grad_norm": 4.107443332672119
    },
    {
      "step": 459,
      "loss": 0.12346740067005157,
      "accuracy": 0.75,
      "grad_norm": 3.6469979286193848
    },
    {
      "step": 460,
      "loss": 0.172769695520401,
      "accuracy": 0.6875,
      "grad_norm": 3.6652865409851074
    },
    {
      "step": 461,
      "loss": 0.08284638077020645,
      "accuracy": 0.875,
      "grad_norm": 2.6447036266326904
    },
    {
      "step": 462,
      "loss": 0.16938933730125427,
      "accuracy": 0.5625,
      "grad_norm": 2.101618766784668
    },
    {
      "step": 463,
      "loss": 0.1984877586364746,
      "accuracy": 0.6875,
      "grad_norm": 2.7112908363342285
    },
    {
      "step": 464,
      "loss": 0.10018811374902725,
      "accuracy": 0.6875,
      "grad_norm": 1.0266577005386353
    },
    {
      "step": 465,
      "loss": 0.17564614117145538,
      "accuracy": 0.75,
      "grad_norm": 1.1396822929382324
    },
    {
      "step": 466,
      "loss": 0.0710727795958519,
      "accuracy": 0.875,
      "grad_norm": 0.8418028354644775
    },
    {
      "step": 467,
      "loss": 0.17159810662269592,
      "accuracy": 0.6875,
      "grad_norm": 3.4444923400878906
    },
    {
      "step": 468,
      "loss": 0.21723373234272003,
      "accuracy": 0.8125,
      "grad_norm": 3.473172426223755
    },
    {
      "step": 469,
      "loss": 0.116209015250206,
      "accuracy": 0.875,
      "grad_norm": 2.1516551971435547
    },
    {
      "step": 470,
      "loss": 0.24682864546775818,
      "accuracy": 0.6875,
      "grad_norm": 13.477622032165527
    },
    {
      "step": 471,
      "loss": 0.14386527240276337,
      "accuracy": 0.8125,
      "grad_norm": 4.83961296081543
    },
    {
      "step": 472,
      "loss": 0.08460988849401474,
      "accuracy": 0.8125,
      "grad_norm": 1.2150942087173462
    },
    {
      "step": 473,
      "loss": 0.11670424044132233,
      "accuracy": 0.75,
      "grad_norm": 5.1601786613464355
    },
    {
      "step": 474,
      "loss": 0.22810359299182892,
      "accuracy": 0.8125,
      "grad_norm": 6.4490251541137695
    },
    {
      "step": 475,
      "loss": 0.25929147005081177,
      "accuracy": 0.6875,
      "grad_norm": 6.723894119262695
    },
    {
      "step": 476,
      "loss": 0.1790323555469513,
      "accuracy": 0.875,
      "grad_norm": 6.949661731719971
    },
    {
      "step": 477,
      "loss": 0.06869599968194962,
      "accuracy": 0.9375,
      "grad_norm": 3.457691192626953
    },
    {
      "step": 478,
      "loss": 0.17966145277023315,
      "accuracy": 0.75,
      "grad_norm": 4.964933395385742
    },
    {
      "step": 479,
      "loss": 0.09238703548908234,
      "accuracy": 0.8125,
      "grad_norm": 2.8915750980377197
    },
    {
      "step": 480,
      "loss": 0.19309072196483612,
      "accuracy": 0.75,
      "grad_norm": 6.1037116050720215
    },
    {
      "step": 481,
      "loss": 0.15910527110099792,
      "accuracy": 0.8125,
      "grad_norm": 6.415796279907227
    },
    {
      "step": 482,
      "loss": 0.1901228427886963,
      "accuracy": 0.625,
      "grad_norm": 4.694369792938232
    },
    {
      "step": 483,
      "loss": 0.15885427594184875,
      "accuracy": 0.6875,
      "grad_norm": 7.222885608673096
    },
    {
      "step": 484,
      "loss": 0.2532794177532196,
      "accuracy": 0.625,
      "grad_norm": 10.58947467803955
    },
    {
      "step": 485,
      "loss": 0.25752875208854675,
      "accuracy": 0.625,
      "grad_norm": 3.9460763931274414
    },
    {
      "step": 486,
      "loss": 0.07193153351545334,
      "accuracy": 0.9375,
      "grad_norm": 1.0089222192764282
    },
    {
      "step": 487,
      "loss": 0.09402704238891602,
      "accuracy": 0.8125,
      "grad_norm": 1.474652886390686
    },
    {
      "step": 488,
      "loss": 0.052805136889219284,
      "accuracy": 1.0,
      "grad_norm": 1.2349038124084473
    },
    {
      "step": 489,
      "loss": 0.08761555701494217,
      "accuracy": 0.8125,
      "grad_norm": 1.2704362869262695
    },
    {
      "step": 490,
      "loss": 0.11974763870239258,
      "accuracy": 0.8125,
      "grad_norm": 3.3705687522888184
    },
    {
      "step": 491,
      "loss": 0.15828698873519897,
      "accuracy": 0.875,
      "grad_norm": 2.099935531616211
    },
    {
      "step": 492,
      "loss": 0.12535972893238068,
      "accuracy": 0.875,
      "grad_norm": 3.2248756885528564
    },
    {
      "step": 493,
      "loss": 0.04424815624952316,
      "accuracy": 1.0,
      "grad_norm": 1.484835147857666
    },
    {
      "step": 494,
      "loss": 0.09982751309871674,
      "accuracy": 0.9375,
      "grad_norm": 1.2968344688415527
    },
    {
      "step": 495,
      "loss": 0.18188507854938507,
      "accuracy": 0.875,
      "grad_norm": 2.4026520252227783
    },
    {
      "step": 496,
      "loss": 0.1040957123041153,
      "accuracy": 0.8125,
      "grad_norm": 2.0431013107299805
    },
    {
      "step": 497,
      "loss": 0.07733551412820816,
      "accuracy": 0.875,
      "grad_norm": 1.0249911546707153
    },
    {
      "step": 498,
      "loss": 0.10184848308563232,
      "accuracy": 0.875,
      "grad_norm": 1.3317880630493164
    },
    {
      "step": 499,
      "loss": 0.2284023016691208,
      "accuracy": 0.5625,
      "grad_norm": 10.425925254821777
    },
    {
      "step": 500,
      "loss": 0.16967007517814636,
      "accuracy": 0.75,
      "grad_norm": 7.975362300872803
    },
    {
      "step": 501,
      "loss": 0.18660804629325867,
      "accuracy": 0.8125,
      "grad_norm": 4.059722423553467
    },
    {
      "step": 502,
      "loss": 0.19205312430858612,
      "accuracy": 0.6875,
      "grad_norm": 7.1976823806762695
    },
    {
      "step": 503,
      "loss": 0.09031669050455093,
      "accuracy": 0.875,
      "grad_norm": 2.417952060699463
    },
    {
      "step": 504,
      "loss": 0.1604892760515213,
      "accuracy": 0.6875,
      "grad_norm": 3.0256705284118652
    },
    {
      "step": 505,
      "loss": 0.14541590213775635,
      "accuracy": 0.75,
      "grad_norm": 3.966862201690674
    },
    {
      "step": 506,
      "loss": 0.056904539465904236,
      "accuracy": 0.9375,
      "grad_norm": 0.3916742205619812
    },
    {
      "step": 507,
      "loss": 0.12020004540681839,
      "accuracy": 0.75,
      "grad_norm": 1.8370182514190674
    },
    {
      "step": 508,
      "loss": 0.08416224271059036,
      "accuracy": 0.8125,
      "grad_norm": 0.9547616839408875
    },
    {
      "step": 509,
      "loss": 0.038561657071113586,
      "accuracy": 1.0,
      "grad_norm": 1.4507499933242798
    },
    {
      "step": 510,
      "loss": 0.10224679112434387,
      "accuracy": 0.8125,
      "grad_norm": 3.3756890296936035
    },
    {
      "step": 511,
      "loss": 0.16140827536582947,
      "accuracy": 0.75,
      "grad_norm": 5.5077314376831055
    },
    {
      "step": 512,
      "loss": 0.15419885516166687,
      "accuracy": 0.6875,
      "grad_norm": 4.838363170623779
    },
    {
      "step": 513,
      "loss": 0.24364560842514038,
      "accuracy": 0.625,
      "grad_norm": 3.370084524154663
    },
    {
      "step": 514,
      "loss": 0.1854909509420395,
      "accuracy": 0.6875,
      "grad_norm": 5.508421421051025
    },
    {
      "step": 515,
      "loss": 0.10050849616527557,
      "accuracy": 0.8125,
      "grad_norm": 5.3716816902160645
    },
    {
      "step": 516,
      "loss": 0.13667233288288116,
      "accuracy": 0.8125,
      "grad_norm": 2.691211700439453
    },
    {
      "step": 517,
      "loss": 0.031129902228713036,
      "accuracy": 1.0,
      "grad_norm": 0.9740326404571533
    },
    {
      "step": 518,
      "loss": 0.24512368440628052,
      "accuracy": 0.6875,
      "grad_norm": 7.102262020111084
    },
    {
      "step": 519,
      "loss": 0.14901182055473328,
      "accuracy": 0.5625,
      "grad_norm": 6.516363143920898
    },
    {
      "step": 520,
      "loss": 0.14298290014266968,
      "accuracy": 0.8125,
      "grad_norm": 8.011556625366211
    },
    {
      "step": 521,
      "loss": 0.0830703005194664,
      "accuracy": 0.8125,
      "grad_norm": 5.419067859649658
    },
    {
      "step": 522,
      "loss": 0.11377260088920593,
      "accuracy": 0.75,
      "grad_norm": 0.9882319569587708
    },
    {
      "step": 523,
      "loss": 0.11229416728019714,
      "accuracy": 0.875,
      "grad_norm": 2.8981380462646484
    },
    {
      "step": 524,
      "loss": 0.1577930748462677,
      "accuracy": 0.875,
      "grad_norm": 4.1864914894104
    },
    {
      "step": 525,
      "loss": 0.1723407357931137,
      "accuracy": 0.75,
      "grad_norm": 2.1544554233551025
    },
    {
      "step": 526,
      "loss": 0.10864953696727753,
      "accuracy": 0.75,
      "grad_norm": 4.900877952575684
    },
    {
      "step": 527,
      "loss": 0.13302132487297058,
      "accuracy": 0.75,
      "grad_norm": 0.7275628447532654
    },
    {
      "step": 528,
      "loss": 0.11181394010782242,
      "accuracy": 0.75,
      "grad_norm": 1.2709554433822632
    },
    {
      "step": 529,
      "loss": 0.10199318826198578,
      "accuracy": 0.875,
      "grad_norm": 0.7789027094841003
    },
    {
      "step": 530,
      "loss": 0.181911438703537,
      "accuracy": 0.6875,
      "grad_norm": 4.046498775482178
    },
    {
      "step": 531,
      "loss": 0.08012295514345169,
      "accuracy": 0.9375,
      "grad_norm": 0.9318891763687134
    },
    {
      "step": 532,
      "loss": 0.07752599567174911,
      "accuracy": 0.8125,
      "grad_norm": 0.6685188412666321
    },
    {
      "step": 533,
      "loss": 0.034494172781705856,
      "accuracy": 1.0,
      "grad_norm": 0.6164014935493469
    },
    {
      "step": 534,
      "loss": 0.1282305121421814,
      "accuracy": 0.875,
      "grad_norm": 2.0376229286193848
    },
    {
      "step": 535,
      "loss": 0.09470747411251068,
      "accuracy": 0.8125,
      "grad_norm": 2.030391216278076
    },
    {
      "step": 536,
      "loss": 0.09757107496261597,
      "accuracy": 0.75,
      "grad_norm": 2.466905355453491
    },
    {
      "step": 537,
      "loss": 0.09902507811784744,
      "accuracy": 0.875,
      "grad_norm": 0.7633629441261292
    },
    {
      "step": 538,
      "loss": 0.09353572875261307,
      "accuracy": 0.8125,
      "grad_norm": 3.279568910598755
    },
    {
      "step": 539,
      "loss": 0.1355980783700943,
      "accuracy": 0.6875,
      "grad_norm": 1.4422740936279297
    },
    {
      "step": 540,
      "loss": 0.06929987668991089,
      "accuracy": 0.9375,
      "grad_norm": 1.610226035118103
    },
    {
      "step": 541,
      "loss": 0.054246190935373306,
      "accuracy": 1.0,
      "grad_norm": 0.5739944577217102
    },
    {
      "step": 542,
      "loss": 0.06505336612462997,
      "accuracy": 0.9375,
      "grad_norm": 0.6584092974662781
    },
    {
      "step": 543,
      "loss": 0.12724937498569489,
      "accuracy": 0.6875,
      "grad_norm": 2.4277749061584473
    },
    {
      "step": 544,
      "loss": 0.08119633793830872,
      "accuracy": 0.875,
      "grad_norm": 2.1018993854522705
    },
    {
      "step": 545,
      "loss": 0.10354145616292953,
      "accuracy": 0.8125,
      "grad_norm": 4.536710262298584
    },
    {
      "step": 546,
      "loss": 0.05416082590818405,
      "accuracy": 0.9375,
      "grad_norm": 1.3124529123306274
    },
    {
      "step": 547,
      "loss": 0.0980391800403595,
      "accuracy": 0.875,
      "grad_norm": 5.712586402893066
    },
    {
      "step": 548,
      "loss": 0.14104080200195312,
      "accuracy": 0.8125,
      "grad_norm": 4.7130866050720215
    },
    {
      "step": 549,
      "loss": 0.12500539422035217,
      "accuracy": 0.75,
      "grad_norm": 3.2856993675231934
    },
    {
      "step": 550,
      "loss": 0.08599327504634857,
      "accuracy": 0.8125,
      "grad_norm": 5.369844913482666
    },
    {
      "step": 551,
      "loss": 0.09123709052801132,
      "accuracy": 0.8125,
      "grad_norm": 2.575505495071411
    },
    {
      "step": 552,
      "loss": 0.019816529005765915,
      "accuracy": 1.0,
      "grad_norm": 1.0997467041015625
    },
    {
      "step": 553,
      "loss": 0.14696110785007477,
      "accuracy": 0.8125,
      "grad_norm": 1.941253900527954
    },
    {
      "step": 554,
      "loss": 0.10780596733093262,
      "accuracy": 0.6875,
      "grad_norm": 4.011034965515137
    },
    {
      "step": 555,
      "loss": 0.07763121277093887,
      "accuracy": 0.8125,
      "grad_norm": 3.491058826446533
    },
    {
      "step": 556,
      "loss": 0.0909184068441391,
      "accuracy": 0.9375,
      "grad_norm": 3.089951515197754
    },
    {
      "step": 557,
      "loss": 0.19771312177181244,
      "accuracy": 0.75,
      "grad_norm": 3.3891515731811523
    },
    {
      "step": 558,
      "loss": 0.07145277410745621,
      "accuracy": 0.9375,
      "grad_norm": 1.1094810962677002
    },
    {
      "step": 559,
      "loss": 0.12920652329921722,
      "accuracy": 0.75,
      "grad_norm": 2.43091082572937
    },
    {
      "step": 560,
      "loss": 0.12272623181343079,
      "accuracy": 0.8125,
      "grad_norm": 2.431213617324829
    },
    {
      "step": 561,
      "loss": 0.15966317057609558,
      "accuracy": 0.6875,
      "grad_norm": 3.1588897705078125
    },
    {
      "step": 562,
      "loss": 0.031616900116205215,
      "accuracy": 1.0,
      "grad_norm": 0.4878566265106201
    },
    {
      "step": 563,
      "loss": 0.03067798912525177,
      "accuracy": 0.9375,
      "grad_norm": 0.9688727855682373
    },
    {
      "step": 564,
      "loss": 0.05535207688808441,
      "accuracy": 0.9375,
      "grad_norm": 0.610224187374115
    },
    {
      "step": 565,
      "loss": 0.13360445201396942,
      "accuracy": 0.8125,
      "grad_norm": 1.033555269241333
    },
    {
      "step": 566,
      "loss": 0.03916756436228752,
      "accuracy": 0.875,
      "grad_norm": 0.9030243754386902
    },
    {
      "step": 567,
      "loss": 0.10149199515581131,
      "accuracy": 0.8125,
      "grad_norm": 1.7082912921905518
    },
    {
      "step": 568,
      "loss": 0.07851655036211014,
      "accuracy": 0.9375,
      "grad_norm": 1.6262800693511963
    },
    {
      "step": 569,
      "loss": 0.10010835528373718,
      "accuracy": 0.8125,
      "grad_norm": 1.8592514991760254
    },
    {
      "step": 570,
      "loss": 0.04376829043030739,
      "accuracy": 0.9375,
      "grad_norm": 1.2985230684280396
    },
    {
      "step": 571,
      "loss": 0.04667523503303528,
      "accuracy": 0.9375,
      "grad_norm": 0.9958977103233337
    },
    {
      "step": 572,
      "loss": 0.0528796911239624,
      "accuracy": 0.875,
      "grad_norm": 1.1549068689346313
    },
    {
      "step": 573,
      "loss": 0.16351184248924255,
      "accuracy": 0.9375,
      "grad_norm": 1.9467055797576904
    },
    {
      "step": 574,
      "loss": 0.04530404880642891,
      "accuracy": 0.9375,
      "grad_norm": 0.9538751840591431
    },
    {
      "step": 575,
      "loss": 0.07801932841539383,
      "accuracy": 0.9375,
      "grad_norm": 0.7723270058631897
    },
    {
      "step": 576,
      "loss": 0.09888803958892822,
      "accuracy": 0.8125,
      "grad_norm": 0.9763073921203613
    },
    {
      "step": 577,
      "loss": 0.13942910730838776,
      "accuracy": 0.8125,
      "grad_norm": 2.3590593338012695
    },
    {
      "step": 578,
      "loss": 0.09547314792871475,
      "accuracy": 0.8125,
      "grad_norm": 0.5665659308433533
    },
    {
      "step": 579,
      "loss": 0.11892655491828918,
      "accuracy": 0.9375,
      "grad_norm": 2.216257333755493
    },
    {
      "step": 580,
      "loss": 0.09582599997520447,
      "accuracy": 0.875,
      "grad_norm": 5.080032825469971
    },
    {
      "step": 581,
      "loss": 0.09849215298891068,
      "accuracy": 0.75,
      "grad_norm": 0.9105217456817627
    },
    {
      "step": 582,
      "loss": 0.0855025127530098,
      "accuracy": 0.8125,
      "grad_norm": 1.5627336502075195
    },
    {
      "step": 583,
      "loss": 0.07700550556182861,
      "accuracy": 0.9375,
      "grad_norm": 4.168289661407471
    },
    {
      "step": 584,
      "loss": 0.16394662857055664,
      "accuracy": 0.625,
      "grad_norm": 5.0745086669921875
    },
    {
      "step": 585,
      "loss": 0.08993332087993622,
      "accuracy": 0.8125,
      "grad_norm": 2.370435953140259
    },
    {
      "step": 586,
      "loss": 0.09678515791893005,
      "accuracy": 0.8125,
      "grad_norm": 2.011327028274536
    },
    {
      "step": 587,
      "loss": 0.037878409028053284,
      "accuracy": 1.0,
      "grad_norm": 1.1562422513961792
    },
    {
      "step": 588,
      "loss": 0.09411855787038803,
      "accuracy": 0.75,
      "grad_norm": 0.4355710744857788
    },
    {
      "step": 589,
      "loss": 0.1264178305864334,
      "accuracy": 0.75,
      "grad_norm": 2.2170279026031494
    },
    {
      "step": 590,
      "loss": 0.05458497628569603,
      "accuracy": 0.9375,
      "grad_norm": 2.175140619277954
    },
    {
      "step": 591,
      "loss": 0.2074989676475525,
      "accuracy": 0.75,
      "grad_norm": 8.05198860168457
    },
    {
      "step": 592,
      "loss": 0.17002218961715698,
      "accuracy": 0.6875,
      "grad_norm": 6.1583991050720215
    },
    {
      "step": 593,
      "loss": 0.04009558632969856,
      "accuracy": 0.9375,
      "grad_norm": 2.011124610900879
    },
    {
      "step": 594,
      "loss": 0.04954873397946358,
      "accuracy": 0.875,
      "grad_norm": 1.1782914400100708
    },
    {
      "step": 595,
      "loss": 0.17185235023498535,
      "accuracy": 0.75,
      "grad_norm": 1.572278380393982
    },
    {
      "step": 596,
      "loss": 0.07290986180305481,
      "accuracy": 0.8125,
      "grad_norm": 3.4420888423919678
    },
    {
      "step": 597,
      "loss": 0.2084709256887436,
      "accuracy": 0.8125,
      "grad_norm": 7.02169942855835
    },
    {
      "step": 598,
      "loss": 0.038810014724731445,
      "accuracy": 0.875,
      "grad_norm": 1.7987747192382812
    },
    {
      "step": 599,
      "loss": 0.018861617892980576,
      "accuracy": 1.0,
      "grad_norm": 0.47848302125930786
    },
    {
      "step": 600,
      "loss": 0.04076747968792915,
      "accuracy": 0.9375,
      "grad_norm": 0.5473839640617371
    },
    {
      "step": 601,
      "loss": 0.10027523338794708,
      "accuracy": 0.8125,
      "grad_norm": 1.6234039068222046
    },
    {
      "step": 602,
      "loss": 0.06473348289728165,
      "accuracy": 0.875,
      "grad_norm": 2.291234254837036
    },
    {
      "step": 603,
      "loss": 0.11880485713481903,
      "accuracy": 0.75,
      "grad_norm": 2.5191569328308105
    },
    {
      "step": 604,
      "loss": 0.05758562684059143,
      "accuracy": 0.875,
      "grad_norm": 2.7222900390625
    },
    {
      "step": 605,
      "loss": 0.017950091511011124,
      "accuracy": 1.0,
      "grad_norm": 0.45904842019081116
    },
    {
      "step": 606,
      "loss": 0.051400281488895416,
      "accuracy": 0.9375,
      "grad_norm": 1.3601571321487427
    },
    {
      "step": 607,
      "loss": 0.08002620190382004,
      "accuracy": 0.875,
      "grad_norm": 1.5157305002212524
    },
    {
      "step": 608,
      "loss": 0.10080833733081818,
      "accuracy": 0.875,
      "grad_norm": 1.2867379188537598
    },
    {
      "step": 609,
      "loss": 0.098138228058815,
      "accuracy": 0.9375,
      "grad_norm": 1.6775912046432495
    },
    {
      "step": 610,
      "loss": 0.19167040288448334,
      "accuracy": 0.75,
      "grad_norm": 4.204855918884277
    },
    {
      "step": 611,
      "loss": 0.05656270310282707,
      "accuracy": 0.9375,
      "grad_norm": 1.4483174085617065
    },
    {
      "step": 612,
      "loss": 0.06508824229240417,
      "accuracy": 0.875,
      "grad_norm": 1.0190480947494507
    },
    {
      "step": 613,
      "loss": 0.05382365733385086,
      "accuracy": 0.9375,
      "grad_norm": 1.624315857887268
    },
    {
      "step": 614,
      "loss": 0.01701938360929489,
      "accuracy": 1.0,
      "grad_norm": 0.3785875141620636
    },
    {
      "step": 615,
      "loss": 0.05863974988460541,
      "accuracy": 0.9375,
      "grad_norm": 0.4846835136413574
    },
    {
      "step": 616,
      "loss": 0.12184187769889832,
      "accuracy": 0.8125,
      "grad_norm": 1.9381382465362549
    },
    {
      "step": 617,
      "loss": 0.08090828359127045,
      "accuracy": 0.875,
      "grad_norm": 3.368774890899658
    },
    {
      "step": 618,
      "loss": 0.08537618815898895,
      "accuracy": 0.9375,
      "grad_norm": 2.2697412967681885
    },
    {
      "step": 619,
      "loss": 0.06567931175231934,
      "accuracy": 0.8125,
      "grad_norm": 2.398120641708374
    },
    {
      "step": 620,
      "loss": 0.09455344825983047,
      "accuracy": 0.8125,
      "grad_norm": 3.6046934127807617
    },
    {
      "step": 621,
      "loss": 0.07149838656187057,
      "accuracy": 0.9375,
      "grad_norm": 0.709758996963501
    },
    {
      "step": 622,
      "loss": 0.042652469128370285,
      "accuracy": 0.9375,
      "grad_norm": 0.8188955187797546
    },
    {
      "step": 623,
      "loss": 0.07115693390369415,
      "accuracy": 0.875,
      "grad_norm": 0.7542362213134766
    },
    {
      "step": 624,
      "loss": 0.030517123639583588,
      "accuracy": 1.0,
      "grad_norm": 0.4831952750682831
    },
    {
      "step": 625,
      "loss": 0.04607737809419632,
      "accuracy": 0.9375,
      "grad_norm": 1.1000926494598389
    },
    {
      "step": 626,
      "loss": 0.03634241595864296,
      "accuracy": 0.9375,
      "grad_norm": 1.8992218971252441
    },
    {
      "step": 627,
      "loss": 0.0804678201675415,
      "accuracy": 0.875,
      "grad_norm": 3.178628444671631
    },
    {
      "step": 628,
      "loss": 0.1717027872800827,
      "accuracy": 0.8125,
      "grad_norm": 2.2314651012420654
    },
    {
      "step": 629,
      "loss": 0.17048536241054535,
      "accuracy": 0.8125,
      "grad_norm": 1.206644892692566
    },
    {
      "step": 630,
      "loss": 0.039538007229566574,
      "accuracy": 0.9375,
      "grad_norm": 0.40461108088493347
    },
    {
      "step": 631,
      "loss": 0.08436673134565353,
      "accuracy": 0.75,
      "grad_norm": 1.661684274673462
    },
    {
      "step": 632,
      "loss": 0.20990663766860962,
      "accuracy": 0.8125,
      "grad_norm": 1.969665288925171
    },
    {
      "step": 633,
      "loss": 0.057584766298532486,
      "accuracy": 0.875,
      "grad_norm": 0.7005870342254639
    },
    {
      "step": 634,
      "loss": 0.0254377331584692,
      "accuracy": 1.0,
      "grad_norm": 0.33680787682533264
    },
    {
      "step": 635,
      "loss": 0.08430719375610352,
      "accuracy": 0.9375,
      "grad_norm": 0.8064860105514526
    },
    {
      "step": 636,
      "loss": 0.039598070085048676,
      "accuracy": 0.9375,
      "grad_norm": 0.8517012000083923
    },
    {
      "step": 637,
      "loss": 0.06638330966234207,
      "accuracy": 0.9375,
      "grad_norm": 1.2874730825424194
    },
    {
      "step": 638,
      "loss": 0.11170700937509537,
      "accuracy": 0.8125,
      "grad_norm": 1.3966418504714966
    },
    {
      "step": 639,
      "loss": 0.06748878210783005,
      "accuracy": 0.8125,
      "grad_norm": 0.47372952103614807
    },
    {
      "step": 640,
      "loss": 0.04380595311522484,
      "accuracy": 0.9375,
      "grad_norm": 0.7216223478317261
    },
    {
      "step": 641,
      "loss": 0.13109424710273743,
      "accuracy": 0.8125,
      "grad_norm": 4.236502647399902
    },
    {
      "step": 642,
      "loss": 0.053137149661779404,
      "accuracy": 0.9375,
      "grad_norm": 3.046400547027588
    },
    {
      "step": 643,
      "loss": 0.2946634888648987,
      "accuracy": 0.6875,
      "grad_norm": 4.651173114776611
    },
    {
      "step": 644,
      "loss": 0.16443011164665222,
      "accuracy": 0.875,
      "grad_norm": 4.647246360778809
    },
    {
      "step": 645,
      "loss": 0.09041571617126465,
      "accuracy": 0.875,
      "grad_norm": 0.8328309655189514
    },
    {
      "step": 646,
      "loss": 0.17791853845119476,
      "accuracy": 0.875,
      "grad_norm": 1.6494799852371216
    },
    {
      "step": 647,
      "loss": 0.09321703761816025,
      "accuracy": 0.9375,
      "grad_norm": 2.0113255977630615
    },
    {
      "step": 648,
      "loss": 0.07203897833824158,
      "accuracy": 0.875,
      "grad_norm": 1.9944146871566772
    },
    {
      "step": 649,
      "loss": 0.15068750083446503,
      "accuracy": 0.6875,
      "grad_norm": 1.3722749948501587
    },
    {
      "step": 650,
      "loss": 0.08971431851387024,
      "accuracy": 0.875,
      "grad_norm": 7.892026424407959
    },
    {
      "step": 651,
      "loss": 0.298245906829834,
      "accuracy": 0.6875,
      "grad_norm": 3.2672460079193115
    },
    {
      "step": 652,
      "loss": 0.0997205376625061,
      "accuracy": 0.875,
      "grad_norm": 5.029042720794678
    },
    {
      "step": 653,
      "loss": 0.05193396285176277,
      "accuracy": 0.9375,
      "grad_norm": 0.18504327535629272
    },
    {
      "step": 654,
      "loss": 0.07507854700088501,
      "accuracy": 0.9375,
      "grad_norm": 2.756833791732788
    },
    {
      "step": 655,
      "loss": 0.09970022737979889,
      "accuracy": 0.875,
      "grad_norm": 1.8364835977554321
    },
    {
      "step": 656,
      "loss": 0.13194677233695984,
      "accuracy": 0.8125,
      "grad_norm": 1.4205769300460815
    },
    {
      "step": 657,
      "loss": 0.0960608422756195,
      "accuracy": 0.875,
      "grad_norm": 4.056612491607666
    },
    {
      "step": 658,
      "loss": 0.13731279969215393,
      "accuracy": 0.875,
      "grad_norm": 4.698889255523682
    },
    {
      "step": 659,
      "loss": 0.09708467870950699,
      "accuracy": 0.8125,
      "grad_norm": 6.288201808929443
    },
    {
      "step": 660,
      "loss": 0.05093016475439072,
      "accuracy": 1.0,
      "grad_norm": 1.6059571504592896
    },
    {
      "step": 661,
      "loss": 0.10229160636663437,
      "accuracy": 0.75,
      "grad_norm": 1.2481520175933838
    },
    {
      "step": 662,
      "loss": 0.0967070460319519,
      "accuracy": 0.8125,
      "grad_norm": 2.0175700187683105
    },
    {
      "step": 663,
      "loss": 0.01761486753821373,
      "accuracy": 1.0,
      "grad_norm": 1.539178490638733
    },
    {
      "step": 664,
      "loss": 0.1544286161661148,
      "accuracy": 0.625,
      "grad_norm": 8.70584774017334
    },
    {
      "step": 665,
      "loss": 0.05837481841444969,
      "accuracy": 0.9375,
      "grad_norm": 1.145934820175171
    },
    {
      "step": 666,
      "loss": 0.04258228838443756,
      "accuracy": 0.9375,
      "grad_norm": 2.062084436416626
    },
    {
      "step": 667,
      "loss": 0.0640125647187233,
      "accuracy": 0.8125,
      "grad_norm": 2.9835968017578125
    },
    {
      "step": 668,
      "loss": 0.09892734885215759,
      "accuracy": 0.875,
      "grad_norm": 4.877077102661133
    },
    {
      "step": 669,
      "loss": 0.19281087815761566,
      "accuracy": 0.75,
      "grad_norm": 2.248969316482544
    },
    {
      "step": 670,
      "loss": 0.04269762709736824,
      "accuracy": 0.9375,
      "grad_norm": 0.2966987192630768
    },
    {
      "step": 671,
      "loss": 0.07271096110343933,
      "accuracy": 0.875,
      "grad_norm": 1.1625663042068481
    },
    {
      "step": 672,
      "loss": 0.11431770771741867,
      "accuracy": 0.6875,
      "grad_norm": 3.7596282958984375
    },
    {
      "step": 673,
      "loss": 0.18727917969226837,
      "accuracy": 0.625,
      "grad_norm": 5.631235599517822
    },
    {
      "step": 674,
      "loss": 0.07808460295200348,
      "accuracy": 0.9375,
      "grad_norm": 4.053391933441162
    },
    {
      "step": 675,
      "loss": 0.06866977363824844,
      "accuracy": 0.9375,
      "grad_norm": 3.3424623012542725
    },
    {
      "step": 676,
      "loss": 0.05887396261096001,
      "accuracy": 0.8125,
      "grad_norm": 0.962232232093811
    },
    {
      "step": 677,
      "loss": 0.06457442790269852,
      "accuracy": 0.875,
      "grad_norm": 0.8386467099189758
    },
    {
      "step": 678,
      "loss": 0.05896135792136192,
      "accuracy": 0.875,
      "grad_norm": 1.4366565942764282
    },
    {
      "step": 679,
      "loss": 0.059676311910152435,
      "accuracy": 0.9375,
      "grad_norm": 2.69360089302063
    },
    {
      "step": 680,
      "loss": 0.062422145158052444,
      "accuracy": 0.875,
      "grad_norm": 3.821739912033081
    },
    {
      "step": 681,
      "loss": 0.04560987651348114,
      "accuracy": 0.875,
      "grad_norm": 1.8746929168701172
    },
    {
      "step": 682,
      "loss": 0.09314529597759247,
      "accuracy": 0.875,
      "grad_norm": 2.606189012527466
    },
    {
      "step": 683,
      "loss": 0.104669488966465,
      "accuracy": 0.875,
      "grad_norm": 1.4908195734024048
    },
    {
      "step": 684,
      "loss": 0.06931122392416,
      "accuracy": 0.875,
      "grad_norm": 0.9320806860923767
    },
    {
      "step": 685,
      "loss": 0.1349162608385086,
      "accuracy": 0.875,
      "grad_norm": 1.6428089141845703
    },
    {
      "step": 686,
      "loss": 0.055456798523664474,
      "accuracy": 0.875,
      "grad_norm": 1.578902006149292
    },
    {
      "step": 687,
      "loss": 0.08881040662527084,
      "accuracy": 0.8125,
      "grad_norm": 2.8859832286834717
    },
    {
      "step": 688,
      "loss": 0.07425713539123535,
      "accuracy": 0.9375,
      "grad_norm": 2.9765355587005615
    },
    {
      "step": 689,
      "loss": 0.05252448096871376,
      "accuracy": 0.9375,
      "grad_norm": 0.563173770904541
    },
    {
      "step": 690,
      "loss": 0.12318206578493118,
      "accuracy": 0.75,
      "grad_norm": 1.887298345565796
    },
    {
      "step": 691,
      "loss": 0.05252114310860634,
      "accuracy": 0.9375,
      "grad_norm": 1.0293216705322266
    },
    {
      "step": 692,
      "loss": 0.05763861909508705,
      "accuracy": 0.875,
      "grad_norm": 0.939866840839386
    },
    {
      "step": 693,
      "loss": 0.09240668267011642,
      "accuracy": 0.8125,
      "grad_norm": 0.6145270466804504
    },
    {
      "step": 694,
      "loss": 0.10762333869934082,
      "accuracy": 0.8125,
      "grad_norm": 3.068525552749634
    },
    {
      "step": 695,
      "loss": 0.214034304022789,
      "accuracy": 0.8125,
      "grad_norm": 1.5790438652038574
    },
    {
      "step": 696,
      "loss": 0.048104941844940186,
      "accuracy": 0.9375,
      "grad_norm": 0.8586984872817993
    },
    {
      "step": 697,
      "loss": 0.019366173073649406,
      "accuracy": 1.0,
      "grad_norm": 0.4511927366256714
    },
    {
      "step": 698,
      "loss": 0.030320364981889725,
      "accuracy": 0.9375,
      "grad_norm": 0.3525472581386566
    },
    {
      "step": 699,
      "loss": 0.030722573399543762,
      "accuracy": 1.0,
      "grad_norm": 0.6594426035881042
    },
    {
      "step": 700,
      "loss": 0.10900530964136124,
      "accuracy": 0.875,
      "grad_norm": 0.646405816078186
    },
    {
      "step": 701,
      "loss": 0.013836978003382683,
      "accuracy": 1.0,
      "grad_norm": 0.3445030152797699
    },
    {
      "step": 702,
      "loss": 0.048939675092697144,
      "accuracy": 0.875,
      "grad_norm": 0.8915466070175171
    },
    {
      "step": 703,
      "loss": 0.09240148961544037,
      "accuracy": 0.8125,
      "grad_norm": 2.7347681522369385
    },
    {
      "step": 704,
      "loss": 0.046430811285972595,
      "accuracy": 0.875,
      "grad_norm": 2.89007830619812
    },
    {
      "step": 705,
      "loss": 0.007150745019316673,
      "accuracy": 1.0,
      "grad_norm": 0.1235763356089592
    },
    {
      "step": 706,
      "loss": 0.10721975564956665,
      "accuracy": 0.875,
      "grad_norm": 1.1456379890441895
    },
    {
      "step": 707,
      "loss": 0.1680857092142105,
      "accuracy": 0.8125,
      "grad_norm": 2.001143455505371
    },
    {
      "step": 708,
      "loss": 0.17092515528202057,
      "accuracy": 0.75,
      "grad_norm": 2.1418192386627197
    },
    {
      "step": 709,
      "loss": 0.08283796906471252,
      "accuracy": 0.8125,
      "grad_norm": 1.3608134984970093
    },
    {
      "step": 710,
      "loss": 0.19402462244033813,
      "accuracy": 0.625,
      "grad_norm": 3.777074098587036
    },
    {
      "step": 711,
      "loss": 0.14149880409240723,
      "accuracy": 0.75,
      "grad_norm": 2.96404767036438
    },
    {
      "step": 712,
      "loss": 0.12937188148498535,
      "accuracy": 0.75,
      "grad_norm": 3.278007984161377
    },
    {
      "step": 713,
      "loss": 0.05648057907819748,
      "accuracy": 0.875,
      "grad_norm": 0.8193235993385315
    },
    {
      "step": 714,
      "loss": 0.0650264099240303,
      "accuracy": 0.875,
      "grad_norm": 0.9798704981803894
    },
    {
      "step": 715,
      "loss": 0.031186753883957863,
      "accuracy": 1.0,
      "grad_norm": 0.7380251884460449
    },
    {
      "step": 716,
      "loss": 0.045934583991765976,
      "accuracy": 0.875,
      "grad_norm": 0.7272459864616394
    },
    {
      "step": 717,
      "loss": 0.03285752981901169,
      "accuracy": 0.9375,
      "grad_norm": 2.480454206466675
    },
    {
      "step": 718,
      "loss": 0.011843595653772354,
      "accuracy": 1.0,
      "grad_norm": 0.6097543835639954
    },
    {
      "step": 719,
      "loss": 0.24824999272823334,
      "accuracy": 0.8125,
      "grad_norm": 2.9111475944519043
    },
    {
      "step": 720,
      "loss": 0.1848667562007904,
      "accuracy": 0.75,
      "grad_norm": 1.7976101636886597
    },
    {
      "step": 721,
      "loss": 0.08334344625473022,
      "accuracy": 0.875,
      "grad_norm": 0.8061315417289734
    },
    {
      "step": 722,
      "loss": 0.014216150157153606,
      "accuracy": 1.0,
      "grad_norm": 0.548138439655304
    },
    {
      "step": 723,
      "loss": 0.11038865149021149,
      "accuracy": 0.8125,
      "grad_norm": 0.862795352935791
    },
    {
      "step": 724,
      "loss": 0.10550103336572647,
      "accuracy": 0.8125,
      "grad_norm": 1.9457812309265137
    },
    {
      "step": 725,
      "loss": 0.08678686618804932,
      "accuracy": 0.8125,
      "grad_norm": 2.0558300018310547
    },
    {
      "step": 726,
      "loss": 0.05339264124631882,
      "accuracy": 0.9375,
      "grad_norm": 1.4611057043075562
    },
    {
      "step": 727,
      "loss": 0.08003177493810654,
      "accuracy": 0.8125,
      "grad_norm": 2.2533600330352783
    },
    {
      "step": 728,
      "loss": 0.018787629902362823,
      "accuracy": 1.0,
      "grad_norm": 0.22887064516544342
    },
    {
      "step": 729,
      "loss": 0.11892104148864746,
      "accuracy": 0.875,
      "grad_norm": 1.1779561042785645
    },
    {
      "step": 730,
      "loss": 0.036166347563266754,
      "accuracy": 0.9375,
      "grad_norm": 1.3035000562667847
    },
    {
      "step": 731,
      "loss": 0.05306923761963844,
      "accuracy": 0.875,
      "grad_norm": 0.6227501630783081
    },
    {
      "step": 732,
      "loss": 0.0730908140540123,
      "accuracy": 0.875,
      "grad_norm": 1.2797082662582397
    },
    {
      "step": 733,
      "loss": 0.03364540636539459,
      "accuracy": 0.9375,
      "grad_norm": 0.6392219066619873
    },
    {
      "step": 734,
      "loss": 0.05875864624977112,
      "accuracy": 0.875,
      "grad_norm": 0.32658711075782776
    },
    {
      "step": 735,
      "loss": 0.08821937441825867,
      "accuracy": 0.9375,
      "grad_norm": 0.5059306621551514
    },
    {
      "step": 736,
      "loss": 0.05809761583805084,
      "accuracy": 0.9375,
      "grad_norm": 0.7807311415672302
    },
    {
      "step": 737,
      "loss": 0.16972249746322632,
      "accuracy": 0.75,
      "grad_norm": 2.2314043045043945
    },
    {
      "step": 738,
      "loss": 0.014005739241838455,
      "accuracy": 1.0,
      "grad_norm": 2.8924288749694824
    },
    {
      "step": 739,
      "loss": 0.02757178246974945,
      "accuracy": 1.0,
      "grad_norm": 0.5521577000617981
    },
    {
      "step": 740,
      "loss": 0.04769865423440933,
      "accuracy": 0.9375,
      "grad_norm": 0.4785641133785248
    },
    {
      "step": 741,
      "loss": 0.19235429167747498,
      "accuracy": 0.8125,
      "grad_norm": 1.6880214214324951
    },
    {
      "step": 742,
      "loss": 0.05138131603598595,
      "accuracy": 0.9375,
      "grad_norm": 0.532010018825531
    },
    {
      "step": 743,
      "loss": 0.019460322335362434,
      "accuracy": 1.0,
      "grad_norm": 0.4969194829463959
    },
    {
      "step": 744,
      "loss": 0.15107525885105133,
      "accuracy": 0.75,
      "grad_norm": 1.9417107105255127
    },
    {
      "step": 745,
      "loss": 0.013773441314697266,
      "accuracy": 1.0,
      "grad_norm": 0.3070765435695648
    },
    {
      "step": 746,
      "loss": 0.06182485073804855,
      "accuracy": 0.875,
      "grad_norm": 0.6184689402580261
    },
    {
      "step": 747,
      "loss": 0.11108202487230301,
      "accuracy": 0.875,
      "grad_norm": 5.124358654022217
    },
    {
      "step": 748,
      "loss": 0.027351869270205498,
      "accuracy": 0.9375,
      "grad_norm": 0.28909799456596375
    },
    {
      "step": 749,
      "loss": 0.03424306958913803,
      "accuracy": 0.9375,
      "grad_norm": 0.44866445660591125
    },
    {
      "step": 750,
      "loss": 0.09346736967563629,
      "accuracy": 0.875,
      "grad_norm": 2.3777735233306885
    },
    {
      "step": 751,
      "loss": 0.08933664858341217,
      "accuracy": 0.875,
      "grad_norm": 1.0508261919021606
    },
    {
      "step": 752,
      "loss": 0.015034272335469723,
      "accuracy": 1.0,
      "grad_norm": 0.325884610414505
    },
    {
      "step": 753,
      "loss": 0.06662065535783768,
      "accuracy": 0.9375,
      "grad_norm": 0.6353627443313599
    },
    {
      "step": 754,
      "loss": 0.04638133943080902,
      "accuracy": 0.9375,
      "grad_norm": 0.42683497071266174
    },
    {
      "step": 755,
      "loss": 0.10171971470117569,
      "accuracy": 0.875,
      "grad_norm": 2.0457651615142822
    },
    {
      "step": 756,
      "loss": 0.017499471083283424,
      "accuracy": 1.0,
      "grad_norm": 1.2957763671875
    },
    {
      "step": 757,
      "loss": 0.0276532880961895,
      "accuracy": 0.9375,
      "grad_norm": 0.5209450125694275
    },
    {
      "step": 758,
      "loss": 0.0445520356297493,
      "accuracy": 0.9375,
      "grad_norm": 2.3889758586883545
    },
    {
      "step": 759,
      "loss": 0.06279271841049194,
      "accuracy": 0.9375,
      "grad_norm": 0.744675874710083
    },
    {
      "step": 760,
      "loss": 0.05014728382229805,
      "accuracy": 0.875,
      "grad_norm": 0.24576584994792938
    },
    {
      "step": 761,
      "loss": 0.033209897577762604,
      "accuracy": 0.875,
      "grad_norm": 0.2577449083328247
    },
    {
      "step": 762,
      "loss": 0.09998007863759995,
      "accuracy": 0.8125,
      "grad_norm": 2.6414291858673096
    },
    {
      "step": 763,
      "loss": 0.07078313082456589,
      "accuracy": 0.8125,
      "grad_norm": 0.4533834755420685
    },
    {
      "step": 764,
      "loss": 0.0593191459774971,
      "accuracy": 0.875,
      "grad_norm": 2.7791168689727783
    },
    {
      "step": 765,
      "loss": 0.135483056306839,
      "accuracy": 0.875,
      "grad_norm": 2.7118446826934814
    },
    {
      "step": 766,
      "loss": 0.10377257317304611,
      "accuracy": 0.8125,
      "grad_norm": 3.377509117126465
    },
    {
      "step": 767,
      "loss": 0.039510540664196014,
      "accuracy": 1.0,
      "grad_norm": 0.8734555840492249
    },
    {
      "step": 768,
      "loss": 0.09204339981079102,
      "accuracy": 0.8125,
      "grad_norm": 4.964529991149902
    },
    {
      "step": 769,
      "loss": 0.3769473433494568,
      "accuracy": 0.75,
      "grad_norm": 6.54030179977417
    },
    {
      "step": 770,
      "loss": 0.25103288888931274,
      "accuracy": 0.5625,
      "grad_norm": 7.376866340637207
    },
    {
      "step": 771,
      "loss": 0.13325007259845734,
      "accuracy": 0.8125,
      "grad_norm": 5.400729656219482
    },
    {
      "step": 772,
      "loss": 0.018848491832613945,
      "accuracy": 1.0,
      "grad_norm": 0.5845528841018677
    },
    {
      "step": 773,
      "loss": 0.027187878265976906,
      "accuracy": 0.9375,
      "grad_norm": 1.5109155178070068
    },
    {
      "step": 774,
      "loss": 0.06580666452646255,
      "accuracy": 0.9375,
      "grad_norm": 2.425562620162964
    },
    {
      "step": 775,
      "loss": 0.0934559628367424,
      "accuracy": 0.8125,
      "grad_norm": 1.4016610383987427
    },
    {
      "step": 776,
      "loss": 0.009298263117671013,
      "accuracy": 1.0,
      "grad_norm": 0.2743590176105499
    },
    {
      "step": 777,
      "loss": 0.010481523349881172,
      "accuracy": 1.0,
      "grad_norm": 0.3801569938659668
    },
    {
      "step": 778,
      "loss": 0.11189448833465576,
      "accuracy": 0.8125,
      "grad_norm": 1.1515710353851318
    },
    {
      "step": 779,
      "loss": 0.09625077992677689,
      "accuracy": 0.8125,
      "grad_norm": 1.091389775276184
    },
    {
      "step": 780,
      "loss": 0.06761843711137772,
      "accuracy": 0.9375,
      "grad_norm": 1.0387294292449951
    },
    {
      "step": 781,
      "loss": 0.0585796944797039,
      "accuracy": 0.875,
      "grad_norm": 0.5475177764892578
    },
    {
      "step": 782,
      "loss": 0.0262004304677248,
      "accuracy": 1.0,
      "grad_norm": 0.5796432495117188
    },
    {
      "step": 783,
      "loss": 0.018504690378904343,
      "accuracy": 1.0,
      "grad_norm": 0.3972805440425873
    },
    {
      "step": 784,
      "loss": 0.04357035458087921,
      "accuracy": 0.875,
      "grad_norm": 1.7085233926773071
    },
    {
      "step": 785,
      "loss": 0.05864095315337181,
      "accuracy": 0.9375,
      "grad_norm": 0.6900784969329834
    },
    {
      "step": 786,
      "loss": 0.04533684626221657,
      "accuracy": 0.9375,
      "grad_norm": 1.0114578008651733
    },
    {
      "step": 787,
      "loss": 0.03129999712109566,
      "accuracy": 1.0,
      "grad_norm": 0.6435384750366211
    },
    {
      "step": 788,
      "loss": 0.03295739367604256,
      "accuracy": 1.0,
      "grad_norm": 1.4720726013183594
    },
    {
      "step": 789,
      "loss": 0.008456026203930378,
      "accuracy": 1.0,
      "grad_norm": 0.18613219261169434
    },
    {
      "step": 790,
      "loss": 0.02915123477578163,
      "accuracy": 0.9375,
      "grad_norm": 2.417656183242798
    },
    {
      "step": 791,
      "loss": 0.05199655890464783,
      "accuracy": 0.875,
      "grad_norm": 0.31751853227615356
    },
    {
      "step": 792,
      "loss": 0.09890805929899216,
      "accuracy": 0.8125,
      "grad_norm": 3.3374245166778564
    },
    {
      "step": 793,
      "loss": 0.09957791864871979,
      "accuracy": 0.875,
      "grad_norm": 2.0753676891326904
    },
    {
      "step": 794,
      "loss": 0.0323280394077301,
      "accuracy": 0.9375,
      "grad_norm": 0.317782998085022
    },
    {
      "step": 795,
      "loss": 0.05285346135497093,
      "accuracy": 0.9375,
      "grad_norm": 2.100712299346924
    },
    {
      "step": 796,
      "loss": 0.05960985645651817,
      "accuracy": 0.8125,
      "grad_norm": 1.343361735343933
    },
    {
      "step": 797,
      "loss": 0.07429921627044678,
      "accuracy": 0.875,
      "grad_norm": 0.44827285408973694
    },
    {
      "step": 798,
      "loss": 0.08792228996753693,
      "accuracy": 0.875,
      "grad_norm": 1.8753002882003784
    },
    {
      "step": 799,
      "loss": 0.15601038932800293,
      "accuracy": 0.8125,
      "grad_norm": 2.2070212364196777
    },
    {
      "step": 800,
      "loss": 0.09085475653409958,
      "accuracy": 0.875,
      "grad_norm": 0.5186538696289062
    },
    {
      "step": 801,
      "loss": 0.09572296589612961,
      "accuracy": 0.875,
      "grad_norm": 1.398451328277588
    },
    {
      "step": 802,
      "loss": 0.08406625688076019,
      "accuracy": 0.875,
      "grad_norm": 0.6982479691505432
    },
    {
      "step": 803,
      "loss": 0.03762953728437424,
      "accuracy": 0.9375,
      "grad_norm": 1.2079209089279175
    },
    {
      "step": 804,
      "loss": 0.10846953094005585,
      "accuracy": 0.875,
      "grad_norm": 3.975450277328491
    },
    {
      "step": 805,
      "loss": 0.0932818204164505,
      "accuracy": 0.6875,
      "grad_norm": 0.46057963371276855
    },
    {
      "step": 806,
      "loss": 0.0684301033616066,
      "accuracy": 0.875,
      "grad_norm": 1.1249109506607056
    },
    {
      "step": 807,
      "loss": 0.033287130296230316,
      "accuracy": 1.0,
      "grad_norm": 0.8018173575401306
    },
    {
      "step": 808,
      "loss": 0.0660114660859108,
      "accuracy": 0.8125,
      "grad_norm": 0.6897851228713989
    },
    {
      "step": 809,
      "loss": 0.1142905056476593,
      "accuracy": 0.8125,
      "grad_norm": 1.3573493957519531
    },
    {
      "step": 810,
      "loss": 0.03263646364212036,
      "accuracy": 0.9375,
      "grad_norm": 0.31886935234069824
    },
    {
      "step": 811,
      "loss": 0.03768124431371689,
      "accuracy": 1.0,
      "grad_norm": 1.0883084535598755
    },
    {
      "step": 812,
      "loss": 0.05428019165992737,
      "accuracy": 1.0,
      "grad_norm": 0.6404805183410645
    },
    {
      "step": 813,
      "loss": 0.034824926406145096,
      "accuracy": 0.9375,
      "grad_norm": 0.3410179913043976
    },
    {
      "step": 814,
      "loss": 0.027389513328671455,
      "accuracy": 0.9375,
      "grad_norm": 0.2755086123943329
    },
    {
      "step": 815,
      "loss": 0.02128564566373825,
      "accuracy": 1.0,
      "grad_norm": 0.5255445837974548
    },
    {
      "step": 816,
      "loss": 0.009246496483683586,
      "accuracy": 1.0,
      "grad_norm": 0.18101152777671814
    },
    {
      "step": 817,
      "loss": 0.013951731845736504,
      "accuracy": 1.0,
      "grad_norm": 0.40769293904304504
    },
    {
      "step": 818,
      "loss": 0.03204711899161339,
      "accuracy": 0.9375,
      "grad_norm": 0.31700995564460754
    },
    {
      "step": 819,
      "loss": 0.07359414547681808,
      "accuracy": 0.875,
      "grad_norm": 2.5648772716522217
    },
    {
      "step": 820,
      "loss": 0.002157856710255146,
      "accuracy": 1.0,
      "grad_norm": 0.06349699944257736
    },
    {
      "step": 821,
      "loss": 0.04194614291191101,
      "accuracy": 0.875,
      "grad_norm": 0.9571819305419922
    },
    {
      "step": 822,
      "loss": 0.04844273254275322,
      "accuracy": 0.9375,
      "grad_norm": 0.41260814666748047
    },
    {
      "step": 823,
      "loss": 0.08934427797794342,
      "accuracy": 0.8125,
      "grad_norm": 0.9287340044975281
    },
    {
      "step": 824,
      "loss": 0.1127246767282486,
      "accuracy": 0.8125,
      "grad_norm": 7.102725982666016
    },
    {
      "step": 825,
      "loss": 0.011524663306772709,
      "accuracy": 1.0,
      "grad_norm": 0.3304934799671173
    },
    {
      "step": 826,
      "loss": 0.00787313561886549,
      "accuracy": 1.0,
      "grad_norm": 0.130608469247818
    },
    {
      "step": 827,
      "loss": 0.029143257066607475,
      "accuracy": 0.9375,
      "grad_norm": 0.48693040013313293
    },
    {
      "step": 828,
      "loss": 0.058580439537763596,
      "accuracy": 0.875,
      "grad_norm": 1.2789664268493652
    },
    {
      "step": 829,
      "loss": 0.002756127156317234,
      "accuracy": 1.0,
      "grad_norm": 0.1662353128194809
    },
    {
      "step": 830,
      "loss": 0.07032976299524307,
      "accuracy": 0.8125,
      "grad_norm": 1.7170933485031128
    },
    {
      "step": 831,
      "loss": 0.010960732586681843,
      "accuracy": 1.0,
      "grad_norm": 0.43477997183799744
    },
    {
      "step": 832,
      "loss": 0.035878900438547134,
      "accuracy": 0.875,
      "grad_norm": 0.9113113284111023
    },
    {
      "step": 833,
      "loss": 0.095387302339077,
      "accuracy": 0.9375,
      "grad_norm": 1.5559495687484741
    },
    {
      "step": 834,
      "loss": 0.017471173778176308,
      "accuracy": 0.9375,
      "grad_norm": 0.32829752564430237
    },
    {
      "step": 835,
      "loss": 0.049560144543647766,
      "accuracy": 0.875,
      "grad_norm": 1.840264916419983
    },
    {
      "step": 836,
      "loss": 0.027911430224776268,
      "accuracy": 0.9375,
      "grad_norm": 0.5826008319854736
    },
    {
      "step": 837,
      "loss": 0.12145495414733887,
      "accuracy": 0.875,
      "grad_norm": 0.8802333474159241
    },
    {
      "step": 838,
      "loss": 0.1771836131811142,
      "accuracy": 0.75,
      "grad_norm": 4.634762763977051
    },
    {
      "step": 839,
      "loss": 0.03649826720356941,
      "accuracy": 0.875,
      "grad_norm": 1.7768162488937378
    },
    {
      "step": 840,
      "loss": 0.09373610466718674,
      "accuracy": 0.9375,
      "grad_norm": 0.41345712542533875
    },
    {
      "step": 841,
      "loss": 0.1072794497013092,
      "accuracy": 0.875,
      "grad_norm": 1.3689348697662354
    },
    {
      "step": 842,
      "loss": 0.005760227330029011,
      "accuracy": 1.0,
      "grad_norm": 0.14027643203735352
    },
    {
      "step": 843,
      "loss": 0.02711835876107216,
      "accuracy": 0.9375,
      "grad_norm": 2.039748430252075
    },
    {
      "step": 844,
      "loss": 0.022661373019218445,
      "accuracy": 1.0,
      "grad_norm": 0.5674440860748291
    },
    {
      "step": 845,
      "loss": 0.03128448873758316,
      "accuracy": 0.875,
      "grad_norm": 0.5189818143844604
    },
    {
      "step": 846,
      "loss": 0.02749507874250412,
      "accuracy": 0.9375,
      "grad_norm": 1.3549296855926514
    },
    {
      "step": 847,
      "loss": 0.025243384763598442,
      "accuracy": 0.9375,
      "grad_norm": 0.18929308652877808
    },
    {
      "step": 848,
      "loss": 0.009962016716599464,
      "accuracy": 1.0,
      "grad_norm": 0.2832525968551636
    },
    {
      "step": 849,
      "loss": 0.06317241489887238,
      "accuracy": 0.875,
      "grad_norm": 0.5802066922187805
    },
    {
      "step": 850,
      "loss": 0.11869381368160248,
      "accuracy": 0.8125,
      "grad_norm": 1.1301074028015137
    },
    {
      "step": 851,
      "loss": 0.01731088198721409,
      "accuracy": 1.0,
      "grad_norm": 0.8050065040588379
    },
    {
      "step": 852,
      "loss": 0.057909950613975525,
      "accuracy": 0.9375,
      "grad_norm": 0.2655714750289917
    },
    {
      "step": 853,
      "loss": 0.09555824846029282,
      "accuracy": 0.875,
      "grad_norm": 2.312182903289795
    },
    {
      "step": 854,
      "loss": 0.0647258311510086,
      "accuracy": 0.8125,
      "grad_norm": 1.950096845626831
    },
    {
      "step": 855,
      "loss": 0.09053989499807358,
      "accuracy": 0.8125,
      "grad_norm": 0.8364058136940002
    },
    {
      "step": 856,
      "loss": 0.04984394833445549,
      "accuracy": 0.875,
      "grad_norm": 0.5213877558708191
    },
    {
      "step": 857,
      "loss": 0.05733664333820343,
      "accuracy": 0.875,
      "grad_norm": 0.4906984269618988
    },
    {
      "step": 858,
      "loss": 0.028709618374705315,
      "accuracy": 0.9375,
      "grad_norm": 0.3566228449344635
    },
    {
      "step": 859,
      "loss": 0.04623692110180855,
      "accuracy": 0.9375,
      "grad_norm": 0.7774451971054077
    },
    {
      "step": 860,
      "loss": 0.024235831573605537,
      "accuracy": 1.0,
      "grad_norm": 0.8562015891075134
    },
    {
      "step": 861,
      "loss": 0.03824682906270027,
      "accuracy": 0.9375,
      "grad_norm": 1.030826210975647
    },
    {
      "step": 862,
      "loss": 0.03732626140117645,
      "accuracy": 0.9375,
      "grad_norm": 0.2328198403120041
    },
    {
      "step": 863,
      "loss": 0.08177104592323303,
      "accuracy": 0.75,
      "grad_norm": 0.7470208406448364
    },
    {
      "step": 864,
      "loss": 0.026799114421010017,
      "accuracy": 1.0,
      "grad_norm": 0.34677138924598694
    },
    {
      "step": 865,
      "loss": 0.03885951265692711,
      "accuracy": 0.9375,
      "grad_norm": 0.2687184512615204
    },
    {
      "step": 866,
      "loss": 0.036476098001003265,
      "accuracy": 0.9375,
      "grad_norm": 0.7268427014350891
    },
    {
      "step": 867,
      "loss": 0.09367894381284714,
      "accuracy": 0.75,
      "grad_norm": 1.733106017112732
    },
    {
      "step": 868,
      "loss": 0.042968861758708954,
      "accuracy": 0.875,
      "grad_norm": 1.9549280405044556
    },
    {
      "step": 869,
      "loss": 0.15144586563110352,
      "accuracy": 0.8125,
      "grad_norm": 1.4596298933029175
    },
    {
      "step": 870,
      "loss": 0.002613530494272709,
      "accuracy": 1.0,
      "grad_norm": 0.06229141727089882
    },
    {
      "step": 871,
      "loss": 0.08610639721155167,
      "accuracy": 0.9375,
      "grad_norm": 1.7801328897476196
    },
    {
      "step": 872,
      "loss": 0.008559138514101505,
      "accuracy": 1.0,
      "grad_norm": 0.2284800112247467
    },
    {
      "step": 873,
      "loss": 0.01078829262405634,
      "accuracy": 1.0,
      "grad_norm": 0.2370505928993225
    },
    {
      "step": 874,
      "loss": 0.05041271075606346,
      "accuracy": 0.9375,
      "grad_norm": 0.5521754622459412
    },
    {
      "step": 875,
      "loss": 0.007229039445519447,
      "accuracy": 1.0,
      "grad_norm": 0.24016916751861572
    },
    {
      "step": 876,
      "loss": 0.16650567948818207,
      "accuracy": 0.8125,
      "grad_norm": 1.4167439937591553
    },
    {
      "step": 877,
      "loss": 0.04493396729230881,
      "accuracy": 0.9375,
      "grad_norm": 0.6013224720954895
    },
    {
      "step": 878,
      "loss": 0.09544456750154495,
      "accuracy": 0.8125,
      "grad_norm": 4.45601749420166
    },
    {
      "step": 879,
      "loss": 0.06953256577253342,
      "accuracy": 0.8125,
      "grad_norm": 1.3915680646896362
    },
    {
      "step": 880,
      "loss": 0.08801929652690887,
      "accuracy": 0.8125,
      "grad_norm": 1.709145426750183
    },
    {
      "step": 881,
      "loss": 0.019228292629122734,
      "accuracy": 1.0,
      "grad_norm": 0.65340256690979
    },
    {
      "step": 882,
      "loss": 0.012849485501646996,
      "accuracy": 1.0,
      "grad_norm": 0.33533599972724915
    },
    {
      "step": 883,
      "loss": 0.09173961728811264,
      "accuracy": 0.8125,
      "grad_norm": 1.7482560873031616
    },
    {
      "step": 884,
      "loss": 0.11312789469957352,
      "accuracy": 0.75,
      "grad_norm": 1.228164792060852
    },
    {
      "step": 885,
      "loss": 0.07865215837955475,
      "accuracy": 0.875,
      "grad_norm": 1.3150224685668945
    },
    {
      "step": 886,
      "loss": 0.09537691622972488,
      "accuracy": 0.875,
      "grad_norm": 0.8715484738349915
    },
    {
      "step": 887,
      "loss": 0.077803835272789,
      "accuracy": 0.75,
      "grad_norm": 0.8160632848739624
    },
    {
      "step": 888,
      "loss": 0.1150125190615654,
      "accuracy": 0.6875,
      "grad_norm": 1.7092524766921997
    },
    {
      "step": 889,
      "loss": 0.08769117295742035,
      "accuracy": 0.75,
      "grad_norm": 1.2473742961883545
    },
    {
      "step": 890,
      "loss": 0.031075170263648033,
      "accuracy": 0.9375,
      "grad_norm": 0.6001669764518738
    },
    {
      "step": 891,
      "loss": 0.046976715326309204,
      "accuracy": 0.9375,
      "grad_norm": 0.2583727538585663
    },
    {
      "step": 892,
      "loss": 0.058767497539520264,
      "accuracy": 0.8125,
      "grad_norm": 0.5570555329322815
    },
    {
      "step": 893,
      "loss": 0.06421525776386261,
      "accuracy": 0.875,
      "grad_norm": 0.28458738327026367
    },
    {
      "step": 894,
      "loss": 0.035523369908332825,
      "accuracy": 0.9375,
      "grad_norm": 0.44244691729545593
    },
    {
      "step": 895,
      "loss": 0.07590806484222412,
      "accuracy": 0.875,
      "grad_norm": 0.42845600843429565
    },
    {
      "step": 896,
      "loss": 0.04633982852101326,
      "accuracy": 0.9375,
      "grad_norm": 0.8885809779167175
    },
    {
      "step": 897,
      "loss": 0.026026366278529167,
      "accuracy": 0.9375,
      "grad_norm": 0.7193156480789185
    },
    {
      "step": 898,
      "loss": 0.05284075438976288,
      "accuracy": 0.875,
      "grad_norm": 3.9177377223968506
    },
    {
      "step": 899,
      "loss": 0.23277035355567932,
      "accuracy": 0.8125,
      "grad_norm": 3.1298227310180664
    },
    {
      "step": 900,
      "loss": 0.02840014174580574,
      "accuracy": 0.9375,
      "grad_norm": 0.20218688249588013
    },
    {
      "step": 901,
      "loss": 0.22002100944519043,
      "accuracy": 0.875,
      "grad_norm": 6.028491020202637
    },
    {
      "step": 902,
      "loss": 0.028159378096461296,
      "accuracy": 1.0,
      "grad_norm": 0.6445714831352234
    },
    {
      "step": 903,
      "loss": 0.024322057142853737,
      "accuracy": 0.9375,
      "grad_norm": 0.3031823933124542
    },
    {
      "step": 904,
      "loss": 0.02936839684844017,
      "accuracy": 1.0,
      "grad_norm": 0.7550786137580872
    },
    {
      "step": 905,
      "loss": 0.06261347234249115,
      "accuracy": 0.9375,
      "grad_norm": 0.4143458902835846
    },
    {
      "step": 906,
      "loss": 0.04477836936712265,
      "accuracy": 0.9375,
      "grad_norm": 1.1789051294326782
    },
    {
      "step": 907,
      "loss": 0.05521520972251892,
      "accuracy": 0.9375,
      "grad_norm": 0.19503691792488098
    },
    {
      "step": 908,
      "loss": 0.00921169389039278,
      "accuracy": 1.0,
      "grad_norm": 0.20267353951931
    },
    {
      "step": 909,
      "loss": 0.1360633224248886,
      "accuracy": 0.8125,
      "grad_norm": 1.562256932258606
    },
    {
      "step": 910,
      "loss": 0.06839311867952347,
      "accuracy": 0.875,
      "grad_norm": 0.6777217388153076
    },
    {
      "step": 911,
      "loss": 0.071243517100811,
      "accuracy": 0.875,
      "grad_norm": 0.6536561250686646
    },
    {
      "step": 912,
      "loss": 0.06519326567649841,
      "accuracy": 0.875,
      "grad_norm": 0.517520546913147
    },
    {
      "step": 913,
      "loss": 0.04790712520480156,
      "accuracy": 0.9375,
      "grad_norm": 0.2525307834148407
    },
    {
      "step": 914,
      "loss": 0.0825631394982338,
      "accuracy": 0.8125,
      "grad_norm": 4.688798904418945
    },
    {
      "step": 915,
      "loss": 0.03976595401763916,
      "accuracy": 0.875,
      "grad_norm": 1.7576594352722168
    },
    {
      "step": 916,
      "loss": 0.0160581786185503,
      "accuracy": 1.0,
      "grad_norm": 0.3781457245349884
    },
    {
      "step": 917,
      "loss": 0.07249129563570023,
      "accuracy": 0.8125,
      "grad_norm": 1.4344059228897095
    },
    {
      "step": 918,
      "loss": 0.040213119238615036,
      "accuracy": 0.9375,
      "grad_norm": 0.6082442402839661
    },
    {
      "step": 919,
      "loss": 0.09202440083026886,
      "accuracy": 0.8125,
      "grad_norm": 1.4785759449005127
    },
    {
      "step": 920,
      "loss": 0.015882210806012154,
      "accuracy": 1.0,
      "grad_norm": 0.40607571601867676
    },
    {
      "step": 921,
      "loss": 0.045543622225522995,
      "accuracy": 0.9375,
      "grad_norm": 1.1573486328125
    },
    {
      "step": 922,
      "loss": 0.03990177437663078,
      "accuracy": 0.9375,
      "grad_norm": 0.7221644520759583
    },
    {
      "step": 923,
      "loss": 0.03250068426132202,
      "accuracy": 0.875,
      "grad_norm": 0.3346800208091736
    },
    {
      "step": 924,
      "loss": 0.12605686485767365,
      "accuracy": 0.6875,
      "grad_norm": 7.832393169403076
    },
    {
      "step": 925,
      "loss": 0.1536284238100052,
      "accuracy": 0.6875,
      "grad_norm": 6.692935943603516
    },
    {
      "step": 926,
      "loss": 0.029822278767824173,
      "accuracy": 0.9375,
      "grad_norm": 1.1882100105285645
    },
    {
      "step": 927,
      "loss": 0.06157185882329941,
      "accuracy": 0.875,
      "grad_norm": 3.8717589378356934
    },
    {
      "step": 928,
      "loss": 0.06950506567955017,
      "accuracy": 0.8125,
      "grad_norm": 2.379018783569336
    },
    {
      "step": 929,
      "loss": 0.00875113531947136,
      "accuracy": 1.0,
      "grad_norm": 0.7260303497314453
    },
    {
      "step": 930,
      "loss": 0.06792563945055008,
      "accuracy": 0.8125,
      "grad_norm": 0.9418763518333435
    },
    {
      "step": 931,
      "loss": 0.01585111767053604,
      "accuracy": 1.0,
      "grad_norm": 0.46348756551742554
    },
    {
      "step": 932,
      "loss": 0.04148612916469574,
      "accuracy": 0.9375,
      "grad_norm": 0.3339097499847412
    },
    {
      "step": 933,
      "loss": 0.06903098523616791,
      "accuracy": 0.9375,
      "grad_norm": 0.30625635385513306
    },
    {
      "step": 934,
      "loss": 0.14939281344413757,
      "accuracy": 0.8125,
      "grad_norm": 1.3530341386795044
    },
    {
      "step": 935,
      "loss": 0.027773182839155197,
      "accuracy": 1.0,
      "grad_norm": 0.8349664807319641
    },
    {
      "step": 936,
      "loss": 0.045076146721839905,
      "accuracy": 0.9375,
      "grad_norm": 0.4080718159675598
    },
    {
      "step": 937,
      "loss": 0.09094130247831345,
      "accuracy": 0.8125,
      "grad_norm": 0.5830133557319641
    },
    {
      "step": 938,
      "loss": 0.027648989111185074,
      "accuracy": 1.0,
      "grad_norm": 0.6729909181594849
    },
    {
      "step": 939,
      "loss": 0.0482625737786293,
      "accuracy": 0.9375,
      "grad_norm": 0.8642879724502563
    },
    {
      "step": 940,
      "loss": 0.02196371555328369,
      "accuracy": 1.0,
      "grad_norm": 0.5194223523139954
    },
    {
      "step": 941,
      "loss": 0.048560552299022675,
      "accuracy": 0.875,
      "grad_norm": 0.2653106153011322
    },
    {
      "step": 942,
      "loss": 0.033967308700084686,
      "accuracy": 0.9375,
      "grad_norm": 0.2707279920578003
    },
    {
      "step": 943,
      "loss": 0.03162350133061409,
      "accuracy": 0.875,
      "grad_norm": 0.5616216063499451
    },
    {
      "step": 944,
      "loss": 0.02995511330664158,
      "accuracy": 1.0,
      "grad_norm": 0.6480413675308228
    },
    {
      "step": 945,
      "loss": 0.037735771387815475,
      "accuracy": 0.9375,
      "grad_norm": 0.22351495921611786
    },
    {
      "step": 946,
      "loss": 0.05824801325798035,
      "accuracy": 0.875,
      "grad_norm": 0.242668017745018
    },
    {
      "step": 947,
      "loss": 0.014752903021872044,
      "accuracy": 1.0,
      "grad_norm": 0.1900729387998581
    },
    {
      "step": 948,
      "loss": 0.11320044845342636,
      "accuracy": 0.9375,
      "grad_norm": 1.0770041942596436
    },
    {
      "step": 949,
      "loss": 0.05256855487823486,
      "accuracy": 0.8125,
      "grad_norm": 0.31729647517204285
    },
    {
      "step": 950,
      "loss": 0.015597104094922543,
      "accuracy": 1.0,
      "grad_norm": 0.4036963880062103
    },
    {
      "step": 951,
      "loss": 0.011400824412703514,
      "accuracy": 1.0,
      "grad_norm": 0.2655412256717682
    },
    {
      "step": 952,
      "loss": 0.020479142665863037,
      "accuracy": 0.9375,
      "grad_norm": 0.18931593000888824
    },
    {
      "step": 953,
      "loss": 0.021488312631845474,
      "accuracy": 0.9375,
      "grad_norm": 1.2912861108779907
    },
    {
      "step": 954,
      "loss": 0.032818786799907684,
      "accuracy": 1.0,
      "grad_norm": 2.015450954437256
    },
    {
      "step": 955,
      "loss": 0.04807871952652931,
      "accuracy": 0.875,
      "grad_norm": 0.608098030090332
    },
    {
      "step": 956,
      "loss": 0.00606548972427845,
      "accuracy": 1.0,
      "grad_norm": 0.15759198367595673
    },
    {
      "step": 957,
      "loss": 0.06741058826446533,
      "accuracy": 0.9375,
      "grad_norm": 0.43660545349121094
    },
    {
      "step": 958,
      "loss": 0.0063952854834496975,
      "accuracy": 1.0,
      "grad_norm": 0.6830052733421326
    },
    {
      "step": 959,
      "loss": 0.02752723917365074,
      "accuracy": 1.0,
      "grad_norm": 1.2544547319412231
    },
    {
      "step": 960,
      "loss": 0.07382310926914215,
      "accuracy": 0.9375,
      "grad_norm": 0.5599722266197205
    },
    {
      "step": 961,
      "loss": 0.0380215086042881,
      "accuracy": 0.9375,
      "grad_norm": 1.6334246397018433
    },
    {
      "step": 962,
      "loss": 0.030669206753373146,
      "accuracy": 0.9375,
      "grad_norm": 1.803324580192566
    },
    {
      "step": 963,
      "loss": 0.011049142107367516,
      "accuracy": 1.0,
      "grad_norm": 0.23922954499721527
    },
    {
      "step": 964,
      "loss": 0.08662059158086777,
      "accuracy": 0.875,
      "grad_norm": 5.232348918914795
    },
    {
      "step": 965,
      "loss": 0.1151428297162056,
      "accuracy": 0.9375,
      "grad_norm": 2.0678491592407227
    },
    {
      "step": 966,
      "loss": 0.12033528089523315,
      "accuracy": 0.875,
      "grad_norm": 0.9277565479278564
    },
    {
      "step": 967,
      "loss": 0.06465906649827957,
      "accuracy": 0.9375,
      "grad_norm": 0.6658481955528259
    },
    {
      "step": 968,
      "loss": 0.04612157866358757,
      "accuracy": 0.875,
      "grad_norm": 0.9900665283203125
    },
    {
      "step": 969,
      "loss": 0.021356089040637016,
      "accuracy": 1.0,
      "grad_norm": 0.4405968189239502
    },
    {
      "step": 970,
      "loss": 0.02559238113462925,
      "accuracy": 1.0,
      "grad_norm": 0.33019205927848816
    },
    {
      "step": 971,
      "loss": 0.048718761652708054,
      "accuracy": 0.875,
      "grad_norm": 0.7799397110939026
    },
    {
      "step": 972,
      "loss": 0.04557526484131813,
      "accuracy": 0.9375,
      "grad_norm": 1.087847352027893
    },
    {
      "step": 973,
      "loss": 0.0075104618445038795,
      "accuracy": 1.0,
      "grad_norm": 0.2585078179836273
    },
    {
      "step": 974,
      "loss": 0.1375255435705185,
      "accuracy": 0.75,
      "grad_norm": 3.1968533992767334
    },
    {
      "step": 975,
      "loss": 0.03316722437739372,
      "accuracy": 0.9375,
      "grad_norm": 1.0379505157470703
    },
    {
      "step": 976,
      "loss": 0.1442500650882721,
      "accuracy": 0.6875,
      "grad_norm": 4.550056457519531
    },
    {
      "step": 977,
      "loss": 0.11269310861825943,
      "accuracy": 0.6875,
      "grad_norm": 1.225602626800537
    },
    {
      "step": 978,
      "loss": 0.06829292327165604,
      "accuracy": 0.875,
      "grad_norm": 1.4335298538208008
    },
    {
      "step": 979,
      "loss": 0.05847850441932678,
      "accuracy": 0.9375,
      "grad_norm": 0.4790290296077728
    },
    {
      "step": 980,
      "loss": 0.2027767300605774,
      "accuracy": 0.875,
      "grad_norm": 3.822350025177002
    },
    {
      "step": 981,
      "loss": 0.03290262445807457,
      "accuracy": 1.0,
      "grad_norm": 1.871313452720642
    },
    {
      "step": 982,
      "loss": 0.09208798408508301,
      "accuracy": 0.75,
      "grad_norm": 2.8193960189819336
    },
    {
      "step": 983,
      "loss": 0.020184118300676346,
      "accuracy": 1.0,
      "grad_norm": 0.46322816610336304
    },
    {
      "step": 984,
      "loss": 0.10828346759080887,
      "accuracy": 0.8125,
      "grad_norm": 0.7302085757255554
    },
    {
      "step": 985,
      "loss": 0.035936206579208374,
      "accuracy": 0.9375,
      "grad_norm": 0.31439080834388733
    },
    {
      "step": 986,
      "loss": 0.04989291727542877,
      "accuracy": 0.9375,
      "grad_norm": 0.6138320565223694
    },
    {
      "step": 987,
      "loss": 0.06707359850406647,
      "accuracy": 0.8125,
      "grad_norm": 0.6671087145805359
    },
    {
      "step": 988,
      "loss": 0.046534497290849686,
      "accuracy": 0.9375,
      "grad_norm": 0.4258207380771637
    },
    {
      "step": 989,
      "loss": 0.05422702431678772,
      "accuracy": 0.9375,
      "grad_norm": 0.6528689861297607
    },
    {
      "step": 990,
      "loss": 0.09212853759527206,
      "accuracy": 0.8125,
      "grad_norm": 1.5515488386154175
    },
    {
      "step": 991,
      "loss": 0.07582110166549683,
      "accuracy": 0.875,
      "grad_norm": 0.5011014938354492
    },
    {
      "step": 992,
      "loss": 0.056395336985588074,
      "accuracy": 0.875,
      "grad_norm": 0.2334439605474472
    },
    {
      "step": 993,
      "loss": 0.06201604753732681,
      "accuracy": 0.9375,
      "grad_norm": 2.6635031700134277
    },
    {
      "step": 994,
      "loss": 0.037310969084501266,
      "accuracy": 0.9375,
      "grad_norm": 0.2602461576461792
    },
    {
      "step": 995,
      "loss": 0.014199419878423214,
      "accuracy": 1.0,
      "grad_norm": 0.3816826045513153
    },
    {
      "step": 996,
      "loss": 0.03596235066652298,
      "accuracy": 0.9375,
      "grad_norm": 0.25243985652923584
    },
    {
      "step": 997,
      "loss": 0.03278161957859993,
      "accuracy": 0.9375,
      "grad_norm": 0.23484313488006592
    },
    {
      "step": 998,
      "loss": 0.03366941958665848,
      "accuracy": 0.9375,
      "grad_norm": 0.33770039677619934
    },
    {
      "step": 999,
      "loss": 0.06799362599849701,
      "accuracy": 0.875,
      "grad_norm": 1.0182249546051025
    },
    {
      "step": 1000,
      "loss": 0.052858684211969376,
      "accuracy": 0.875,
      "grad_norm": 0.5462146997451782
    },
    {
      "step": 1001,
      "loss": 0.015916509553790092,
      "accuracy": 0.9375,
      "grad_norm": 0.30758020281791687
    },
    {
      "step": 1002,
      "loss": 0.1269550323486328,
      "accuracy": 0.875,
      "grad_norm": 1.7450127601623535
    },
    {
      "step": 1003,
      "loss": 0.053057581186294556,
      "accuracy": 0.875,
      "grad_norm": 0.5050062537193298
    },
    {
      "step": 1004,
      "loss": 0.05777361989021301,
      "accuracy": 0.875,
      "grad_norm": 0.34352076053619385
    },
    {
      "step": 1005,
      "loss": 0.11651185154914856,
      "accuracy": 0.8125,
      "grad_norm": 3.356569766998291
    },
    {
      "step": 1006,
      "loss": 0.01820758357644081,
      "accuracy": 0.9375,
      "grad_norm": 0.2278990000486374
    },
    {
      "step": 1007,
      "loss": 0.004573079291731119,
      "accuracy": 1.0,
      "grad_norm": 0.09536097943782806
    },
    {
      "step": 1008,
      "loss": 0.14383329451084137,
      "accuracy": 0.8125,
      "grad_norm": 1.2264838218688965
    },
    {
      "step": 1009,
      "loss": 0.03693413734436035,
      "accuracy": 0.875,
      "grad_norm": 0.7410632967948914
    },
    {
      "step": 1010,
      "loss": 0.019605426117777824,
      "accuracy": 1.0,
      "grad_norm": 0.1823437362909317
    },
    {
      "step": 1011,
      "loss": 0.19377803802490234,
      "accuracy": 0.75,
      "grad_norm": 1.122406244277954
    },
    {
      "step": 1012,
      "loss": 0.07567357271909714,
      "accuracy": 0.875,
      "grad_norm": 0.8532028794288635
    },
    {
      "step": 1013,
      "loss": 0.017191795632243156,
      "accuracy": 0.9375,
      "grad_norm": 0.40450504422187805
    },
    {
      "step": 1014,
      "loss": 0.04723239690065384,
      "accuracy": 0.875,
      "grad_norm": 0.4120965600013733
    },
    {
      "step": 1015,
      "loss": 0.06169351562857628,
      "accuracy": 0.9375,
      "grad_norm": 0.9472514986991882
    },
    {
      "step": 1016,
      "loss": 0.035699259489774704,
      "accuracy": 1.0,
      "grad_norm": 0.8287580013275146
    },
    {
      "step": 1017,
      "loss": 0.02978580817580223,
      "accuracy": 0.9375,
      "grad_norm": 0.1641075760126114
    },
    {
      "step": 1018,
      "loss": 0.028016911819577217,
      "accuracy": 1.0,
      "grad_norm": 0.5854572653770447
    },
    {
      "step": 1019,
      "loss": 0.038084372878074646,
      "accuracy": 0.9375,
      "grad_norm": 0.4495183527469635
    },
    {
      "step": 1020,
      "loss": 0.009754223749041557,
      "accuracy": 1.0,
      "grad_norm": 0.18938486278057098
    },
    {
      "step": 1021,
      "loss": 0.005737039726227522,
      "accuracy": 1.0,
      "grad_norm": 0.12269216775894165
    },
    {
      "step": 1022,
      "loss": 0.008595621213316917,
      "accuracy": 1.0,
      "grad_norm": 0.21516123414039612
    },
    {
      "step": 1023,
      "loss": 0.049554985016584396,
      "accuracy": 0.9375,
      "grad_norm": 0.4269898533821106
    },
    {
      "step": 1024,
      "loss": 0.049896884709596634,
      "accuracy": 0.9375,
      "grad_norm": 1.1196002960205078
    },
    {
      "step": 1025,
      "loss": 0.007113228086382151,
      "accuracy": 1.0,
      "grad_norm": 0.1903829276561737
    },
    {
      "step": 1026,
      "loss": 0.004521755501627922,
      "accuracy": 1.0,
      "grad_norm": 0.12807539105415344
    },
    {
      "step": 1027,
      "loss": 0.0054464153945446014,
      "accuracy": 1.0,
      "grad_norm": 0.17281000316143036
    },
    {
      "step": 1028,
      "loss": 0.03743116930127144,
      "accuracy": 0.9375,
      "grad_norm": 0.46871837973594666
    },
    {
      "step": 1029,
      "loss": 0.023792661726474762,
      "accuracy": 0.9375,
      "grad_norm": 0.9468626976013184
    },
    {
      "step": 1030,
      "loss": 0.12469714134931564,
      "accuracy": 0.875,
      "grad_norm": 0.9952860474586487
    },
    {
      "step": 1031,
      "loss": 0.08221479505300522,
      "accuracy": 0.875,
      "grad_norm": 2.1961593627929688
    },
    {
      "step": 1032,
      "loss": 0.06166882812976837,
      "accuracy": 0.875,
      "grad_norm": 0.7335164546966553
    },
    {
      "step": 1033,
      "loss": 0.1409917175769806,
      "accuracy": 0.875,
      "grad_norm": 3.2573084831237793
    },
    {
      "step": 1034,
      "loss": 0.08915454894304276,
      "accuracy": 0.9375,
      "grad_norm": 2.342374563217163
    },
    {
      "step": 1035,
      "loss": 0.029459109529852867,
      "accuracy": 0.9375,
      "grad_norm": 0.1433568298816681
    },
    {
      "step": 1036,
      "loss": 0.007536264136433601,
      "accuracy": 1.0,
      "grad_norm": 0.20408199727535248
    },
    {
      "step": 1037,
      "loss": 0.04269716888666153,
      "accuracy": 0.9375,
      "grad_norm": 0.19000263512134552
    },
    {
      "step": 1038,
      "loss": 0.06062248349189758,
      "accuracy": 0.875,
      "grad_norm": 0.4728517532348633
    },
    {
      "step": 1039,
      "loss": 0.049051765352487564,
      "accuracy": 0.9375,
      "grad_norm": 1.197252631187439
    },
    {
      "step": 1040,
      "loss": 0.05851529911160469,
      "accuracy": 0.875,
      "grad_norm": 0.47087594866752625
    },
    {
      "step": 1041,
      "loss": 0.06439211964607239,
      "accuracy": 0.9375,
      "grad_norm": 0.2805982828140259
    },
    {
      "step": 1042,
      "loss": 0.017092861235141754,
      "accuracy": 1.0,
      "grad_norm": 0.43296995759010315
    },
    {
      "step": 1043,
      "loss": 0.08067627996206284,
      "accuracy": 0.8125,
      "grad_norm": 0.7380747199058533
    },
    {
      "step": 1044,
      "loss": 0.06352651119232178,
      "accuracy": 0.8125,
      "grad_norm": 0.9666642546653748
    },
    {
      "step": 1045,
      "loss": 0.07067723572254181,
      "accuracy": 0.875,
      "grad_norm": 0.5744795203208923
    },
    {
      "step": 1046,
      "loss": 0.017295969650149345,
      "accuracy": 1.0,
      "grad_norm": 0.18697531521320343
    },
    {
      "step": 1047,
      "loss": 0.026671189814805984,
      "accuracy": 1.0,
      "grad_norm": 0.5688778758049011
    },
    {
      "step": 1048,
      "loss": 0.03572015091776848,
      "accuracy": 0.9375,
      "grad_norm": 0.6758304238319397
    },
    {
      "step": 1049,
      "loss": 0.057895079255104065,
      "accuracy": 0.9375,
      "grad_norm": 0.8823667764663696
    },
    {
      "step": 1050,
      "loss": 0.0312936007976532,
      "accuracy": 1.0,
      "grad_norm": 0.24902698397636414
    },
    {
      "step": 1051,
      "loss": 0.024450164288282394,
      "accuracy": 1.0,
      "grad_norm": 0.23272313177585602
    },
    {
      "step": 1052,
      "loss": 0.06024370342493057,
      "accuracy": 0.875,
      "grad_norm": 0.5385867953300476
    },
    {
      "step": 1053,
      "loss": 0.01571822538971901,
      "accuracy": 1.0,
      "grad_norm": 0.4290280044078827
    },
    {
      "step": 1054,
      "loss": 0.03871071711182594,
      "accuracy": 0.9375,
      "grad_norm": 0.4832572638988495
    },
    {
      "step": 1055,
      "loss": 0.10849200934171677,
      "accuracy": 0.8125,
      "grad_norm": 4.86793327331543
    },
    {
      "step": 1056,
      "loss": 0.04602833837270737,
      "accuracy": 0.875,
      "grad_norm": 1.3913631439208984
    },
    {
      "step": 1057,
      "loss": 0.01022620964795351,
      "accuracy": 1.0,
      "grad_norm": 0.32735690474510193
    },
    {
      "step": 1058,
      "loss": 0.009818404912948608,
      "accuracy": 1.0,
      "grad_norm": 0.14213791489601135
    },
    {
      "step": 1059,
      "loss": 0.052454303950071335,
      "accuracy": 0.875,
      "grad_norm": 0.4190545082092285
    },
    {
      "step": 1060,
      "loss": 0.09948749840259552,
      "accuracy": 0.9375,
      "grad_norm": 0.959047794342041
    },
    {
      "step": 1061,
      "loss": 0.02032298408448696,
      "accuracy": 1.0,
      "grad_norm": 0.7336460947990417
    },
    {
      "step": 1062,
      "loss": 0.051716528832912445,
      "accuracy": 0.875,
      "grad_norm": 2.094843864440918
    },
    {
      "step": 1063,
      "loss": 0.01618368923664093,
      "accuracy": 1.0,
      "grad_norm": 0.5656358599662781
    },
    {
      "step": 1064,
      "loss": 0.013593344017863274,
      "accuracy": 1.0,
      "grad_norm": 0.5414111614227295
    },
    {
      "step": 1065,
      "loss": 0.04333958774805069,
      "accuracy": 0.875,
      "grad_norm": 0.8213124871253967
    },
    {
      "step": 1066,
      "loss": 0.03709246590733528,
      "accuracy": 0.9375,
      "grad_norm": 0.5470715165138245
    },
    {
      "step": 1067,
      "loss": 0.006731575354933739,
      "accuracy": 1.0,
      "grad_norm": 0.2566467523574829
    },
    {
      "step": 1068,
      "loss": 0.00222119502723217,
      "accuracy": 1.0,
      "grad_norm": 0.04927438125014305
    },
    {
      "step": 1069,
      "loss": 0.04331154376268387,
      "accuracy": 0.9375,
      "grad_norm": 0.38970160484313965
    },
    {
      "step": 1070,
      "loss": 0.06466731429100037,
      "accuracy": 0.875,
      "grad_norm": 0.8889341354370117
    },
    {
      "step": 1071,
      "loss": 0.029453087598085403,
      "accuracy": 0.9375,
      "grad_norm": 0.44069212675094604
    },
    {
      "step": 1072,
      "loss": 0.046072956174612045,
      "accuracy": 0.9375,
      "grad_norm": 0.2881869971752167
    },
    {
      "step": 1073,
      "loss": 0.04017969220876694,
      "accuracy": 0.875,
      "grad_norm": 0.4010123312473297
    },
    {
      "step": 1074,
      "loss": 0.043606992810964584,
      "accuracy": 0.875,
      "grad_norm": 0.8302598595619202
    },
    {
      "step": 1075,
      "loss": 0.12451407313346863,
      "accuracy": 0.8125,
      "grad_norm": 5.498426914215088
    },
    {
      "step": 1076,
      "loss": 0.08690176159143448,
      "accuracy": 0.875,
      "grad_norm": 2.305399179458618
    },
    {
      "step": 1077,
      "loss": 0.03232082724571228,
      "accuracy": 0.9375,
      "grad_norm": 1.001829981803894
    },
    {
      "step": 1078,
      "loss": 0.0207207091152668,
      "accuracy": 1.0,
      "grad_norm": 0.26924949884414673
    },
    {
      "step": 1079,
      "loss": 0.04825856536626816,
      "accuracy": 0.875,
      "grad_norm": 0.32287338376045227
    },
    {
      "step": 1080,
      "loss": 0.09294057637453079,
      "accuracy": 0.9375,
      "grad_norm": 0.7572934627532959
    },
    {
      "step": 1081,
      "loss": 0.07598672062158585,
      "accuracy": 0.875,
      "grad_norm": 0.965522289276123
    },
    {
      "step": 1082,
      "loss": 0.007033106405287981,
      "accuracy": 1.0,
      "grad_norm": 0.14683791995048523
    },
    {
      "step": 1083,
      "loss": 0.02715843729674816,
      "accuracy": 0.9375,
      "grad_norm": 0.5950099229812622
    },
    {
      "step": 1084,
      "loss": 0.10465435683727264,
      "accuracy": 0.875,
      "grad_norm": 1.2846183776855469
    },
    {
      "step": 1085,
      "loss": 0.08861400187015533,
      "accuracy": 0.875,
      "grad_norm": 1.606894612312317
    },
    {
      "step": 1086,
      "loss": 0.08529297262430191,
      "accuracy": 0.8125,
      "grad_norm": 3.1745951175689697
    },
    {
      "step": 1087,
      "loss": 0.039735905826091766,
      "accuracy": 0.9375,
      "grad_norm": 1.1623646020889282
    },
    {
      "step": 1088,
      "loss": 0.09464820474386215,
      "accuracy": 0.875,
      "grad_norm": 0.45356878638267517
    },
    {
      "step": 1089,
      "loss": 0.07655545324087143,
      "accuracy": 0.8125,
      "grad_norm": 0.6615099906921387
    },
    {
      "step": 1090,
      "loss": 0.01357647217810154,
      "accuracy": 1.0,
      "grad_norm": 0.4009070098400116
    },
    {
      "step": 1091,
      "loss": 0.01690823771059513,
      "accuracy": 1.0,
      "grad_norm": 0.3986518383026123
    },
    {
      "step": 1092,
      "loss": 0.1107466071844101,
      "accuracy": 0.8125,
      "grad_norm": 0.6432188749313354
    },
    {
      "step": 1093,
      "loss": 0.057600729167461395,
      "accuracy": 0.9375,
      "grad_norm": 0.4630439281463623
    },
    {
      "step": 1094,
      "loss": 0.011317242868244648,
      "accuracy": 1.0,
      "grad_norm": 0.5741927027702332
    },
    {
      "step": 1095,
      "loss": 0.08857259154319763,
      "accuracy": 0.875,
      "grad_norm": 1.00435209274292
    },
    {
      "step": 1096,
      "loss": 0.04380101338028908,
      "accuracy": 0.9375,
      "grad_norm": 0.4415818154811859
    },
    {
      "step": 1097,
      "loss": 0.06921335309743881,
      "accuracy": 0.875,
      "grad_norm": 0.7032762765884399
    },
    {
      "step": 1098,
      "loss": 0.08297893404960632,
      "accuracy": 0.875,
      "grad_norm": 0.8849053978919983
    },
    {
      "step": 1099,
      "loss": 0.024662582203745842,
      "accuracy": 1.0,
      "grad_norm": 0.6052112579345703
    },
    {
      "step": 1100,
      "loss": 0.060010794550180435,
      "accuracy": 0.875,
      "grad_norm": 0.33200588822364807
    },
    {
      "step": 1101,
      "loss": 0.03845585137605667,
      "accuracy": 1.0,
      "grad_norm": 0.6017650961875916
    },
    {
      "step": 1102,
      "loss": 0.03595075383782387,
      "accuracy": 0.9375,
      "grad_norm": 0.44822174310684204
    },
    {
      "step": 1103,
      "loss": 0.025553898885846138,
      "accuracy": 1.0,
      "grad_norm": 0.9518858790397644
    },
    {
      "step": 1104,
      "loss": 0.06331408768892288,
      "accuracy": 0.875,
      "grad_norm": 0.5846693515777588
    },
    {
      "step": 1105,
      "loss": 0.03459591045975685,
      "accuracy": 0.9375,
      "grad_norm": 0.5264251232147217
    },
    {
      "step": 1106,
      "loss": 0.07524517923593521,
      "accuracy": 0.875,
      "grad_norm": 1.279799222946167
    },
    {
      "step": 1107,
      "loss": 0.020323364064097404,
      "accuracy": 1.0,
      "grad_norm": 0.8790386319160461
    },
    {
      "step": 1108,
      "loss": 0.1159706711769104,
      "accuracy": 0.875,
      "grad_norm": 3.1598873138427734
    },
    {
      "step": 1109,
      "loss": 0.008269509300589561,
      "accuracy": 1.0,
      "grad_norm": 0.24386653304100037
    },
    {
      "step": 1110,
      "loss": 0.017822058871388435,
      "accuracy": 1.0,
      "grad_norm": 0.325947105884552
    },
    {
      "step": 1111,
      "loss": 0.008408978581428528,
      "accuracy": 1.0,
      "grad_norm": 0.2027657926082611
    },
    {
      "step": 1112,
      "loss": 0.010150987654924393,
      "accuracy": 1.0,
      "grad_norm": 0.26827272772789
    },
    {
      "step": 1113,
      "loss": 0.07713523507118225,
      "accuracy": 0.875,
      "grad_norm": 0.7470130324363708
    },
    {
      "step": 1114,
      "loss": 0.07720709592103958,
      "accuracy": 0.875,
      "grad_norm": 0.7242470383644104
    },
    {
      "step": 1115,
      "loss": 0.03607621788978577,
      "accuracy": 0.9375,
      "grad_norm": 0.5052611231803894
    },
    {
      "step": 1116,
      "loss": 0.06889107823371887,
      "accuracy": 0.9375,
      "grad_norm": 1.7128560543060303
    },
    {
      "step": 1117,
      "loss": 0.0959426760673523,
      "accuracy": 0.9375,
      "grad_norm": 0.907864511013031
    },
    {
      "step": 1118,
      "loss": 0.01764683425426483,
      "accuracy": 1.0,
      "grad_norm": 0.45862603187561035
    },
    {
      "step": 1119,
      "loss": 0.0372004508972168,
      "accuracy": 0.875,
      "grad_norm": 0.38754281401634216
    },
    {
      "step": 1120,
      "loss": 0.015983909368515015,
      "accuracy": 1.0,
      "grad_norm": 0.22423192858695984
    },
    {
      "step": 1121,
      "loss": 0.07342211902141571,
      "accuracy": 0.875,
      "grad_norm": 0.6535084247589111
    },
    {
      "step": 1122,
      "loss": 0.02502201870083809,
      "accuracy": 1.0,
      "grad_norm": 0.8876445889472961
    },
    {
      "step": 1123,
      "loss": 0.05371643230319023,
      "accuracy": 0.9375,
      "grad_norm": 0.2949562668800354
    },
    {
      "step": 1124,
      "loss": 0.005707095842808485,
      "accuracy": 1.0,
      "grad_norm": 0.16063818335533142
    },
    {
      "step": 1125,
      "loss": 0.007558492477983236,
      "accuracy": 1.0,
      "grad_norm": 0.17859286069869995
    },
    {
      "step": 1126,
      "loss": 0.037575870752334595,
      "accuracy": 0.9375,
      "grad_norm": 1.3432152271270752
    },
    {
      "step": 1127,
      "loss": 0.0390213318169117,
      "accuracy": 0.9375,
      "grad_norm": 0.4817293882369995
    },
    {
      "step": 1128,
      "loss": 0.014240175485610962,
      "accuracy": 1.0,
      "grad_norm": 0.6630296111106873
    },
    {
      "step": 1129,
      "loss": 0.037546999752521515,
      "accuracy": 0.9375,
      "grad_norm": 0.48407337069511414
    },
    {
      "step": 1130,
      "loss": 0.02230844832956791,
      "accuracy": 0.9375,
      "grad_norm": 0.36887553334236145
    },
    {
      "step": 1131,
      "loss": 0.004065872170031071,
      "accuracy": 1.0,
      "grad_norm": 0.12106232345104218
    },
    {
      "step": 1132,
      "loss": 0.013401627540588379,
      "accuracy": 1.0,
      "grad_norm": 0.16102521121501923
    },
    {
      "step": 1133,
      "loss": 0.008122636936604977,
      "accuracy": 1.0,
      "grad_norm": 0.2588515281677246
    },
    {
      "step": 1134,
      "loss": 0.02249336615204811,
      "accuracy": 0.9375,
      "grad_norm": 0.3506874740123749
    },
    {
      "step": 1135,
      "loss": 0.0063568283803761005,
      "accuracy": 1.0,
      "grad_norm": 0.2005925178527832
    },
    {
      "step": 1136,
      "loss": 0.01662069745361805,
      "accuracy": 0.9375,
      "grad_norm": 0.3509654402732849
    },
    {
      "step": 1137,
      "loss": 0.01568322256207466,
      "accuracy": 1.0,
      "grad_norm": 0.6074312925338745
    },
    {
      "step": 1138,
      "loss": 0.16974757611751556,
      "accuracy": 0.8125,
      "grad_norm": 1.5418447256088257
    },
    {
      "step": 1139,
      "loss": 0.04226917773485184,
      "accuracy": 0.9375,
      "grad_norm": 1.4278967380523682
    },
    {
      "step": 1140,
      "loss": 0.05057784542441368,
      "accuracy": 0.875,
      "grad_norm": 1.8888894319534302
    },
    {
      "step": 1141,
      "loss": 0.002176065929234028,
      "accuracy": 1.0,
      "grad_norm": 0.05577660724520683
    },
    {
      "step": 1142,
      "loss": 0.06398209184408188,
      "accuracy": 0.875,
      "grad_norm": 3.504776954650879
    },
    {
      "step": 1143,
      "loss": 0.07653488963842392,
      "accuracy": 0.8125,
      "grad_norm": 2.8699238300323486
    },
    {
      "step": 1144,
      "loss": 0.060736335813999176,
      "accuracy": 0.875,
      "grad_norm": 1.893949031829834
    },
    {
      "step": 1145,
      "loss": 0.060251809656620026,
      "accuracy": 0.875,
      "grad_norm": 2.0305566787719727
    },
    {
      "step": 1146,
      "loss": 0.07145575433969498,
      "accuracy": 0.9375,
      "grad_norm": 0.37062758207321167
    },
    {
      "step": 1147,
      "loss": 0.025326570495963097,
      "accuracy": 0.9375,
      "grad_norm": 0.8899424076080322
    },
    {
      "step": 1148,
      "loss": 0.04952811822295189,
      "accuracy": 0.9375,
      "grad_norm": 0.8648704886436462
    },
    {
      "step": 1149,
      "loss": 0.07775545865297318,
      "accuracy": 0.875,
      "grad_norm": 1.0266942977905273
    },
    {
      "step": 1150,
      "loss": 0.06383498758077621,
      "accuracy": 0.9375,
      "grad_norm": 0.4207894802093506
    },
    {
      "step": 1151,
      "loss": 0.027972137555480003,
      "accuracy": 0.9375,
      "grad_norm": 0.19387187063694
    },
    {
      "step": 1152,
      "loss": 0.022868696600198746,
      "accuracy": 0.9375,
      "grad_norm": 0.5487743020057678
    },
    {
      "step": 1153,
      "loss": 0.009752683341503143,
      "accuracy": 1.0,
      "grad_norm": 0.28624585270881653
    },
    {
      "step": 1154,
      "loss": 0.009820845909416676,
      "accuracy": 1.0,
      "grad_norm": 0.26279327273368835
    },
    {
      "step": 1155,
      "loss": 0.008344353176653385,
      "accuracy": 1.0,
      "grad_norm": 0.2341630458831787
    },
    {
      "step": 1156,
      "loss": 0.03085688129067421,
      "accuracy": 0.9375,
      "grad_norm": 0.552273690700531
    },
    {
      "step": 1157,
      "loss": 0.05837353318929672,
      "accuracy": 0.875,
      "grad_norm": 0.4339297413825989
    },
    {
      "step": 1158,
      "loss": 0.05053186044096947,
      "accuracy": 0.9375,
      "grad_norm": 1.0561163425445557
    },
    {
      "step": 1159,
      "loss": 0.048703987151384354,
      "accuracy": 0.9375,
      "grad_norm": 0.3628780245780945
    },
    {
      "step": 1160,
      "loss": 0.08979377150535583,
      "accuracy": 0.875,
      "grad_norm": 0.7288558483123779
    },
    {
      "step": 1161,
      "loss": 0.06640864163637161,
      "accuracy": 0.8125,
      "grad_norm": 2.255239486694336
    },
    {
      "step": 1162,
      "loss": 0.04092848673462868,
      "accuracy": 0.9375,
      "grad_norm": 0.24630916118621826
    },
    {
      "step": 1163,
      "loss": 0.03058280423283577,
      "accuracy": 0.875,
      "grad_norm": 0.21650798618793488
    },
    {
      "step": 1164,
      "loss": 0.027173487469553947,
      "accuracy": 1.0,
      "grad_norm": 0.36153197288513184
    },
    {
      "step": 1165,
      "loss": 0.007462010253220797,
      "accuracy": 1.0,
      "grad_norm": 0.18282347917556763
    },
    {
      "step": 1166,
      "loss": 0.05022668465971947,
      "accuracy": 0.875,
      "grad_norm": 0.975826621055603
    },
    {
      "step": 1167,
      "loss": 0.028156789019703865,
      "accuracy": 0.9375,
      "grad_norm": 0.6178075075149536
    },
    {
      "step": 1168,
      "loss": 0.0504944808781147,
      "accuracy": 0.875,
      "grad_norm": 0.4027297794818878
    },
    {
      "step": 1169,
      "loss": 0.023142822086811066,
      "accuracy": 1.0,
      "grad_norm": 0.6257515549659729
    },
    {
      "step": 1170,
      "loss": 0.13231943547725677,
      "accuracy": 0.8125,
      "grad_norm": 2.0749690532684326
    },
    {
      "step": 1171,
      "loss": 0.03825339302420616,
      "accuracy": 0.9375,
      "grad_norm": 2.974246025085449
    },
    {
      "step": 1172,
      "loss": 0.009208914823830128,
      "accuracy": 1.0,
      "grad_norm": 0.2509123682975769
    },
    {
      "step": 1173,
      "loss": 0.1777440309524536,
      "accuracy": 0.6875,
      "grad_norm": 1.7525683641433716
    },
    {
      "step": 1174,
      "loss": 0.06692716479301453,
      "accuracy": 0.8125,
      "grad_norm": 0.3934937119483948
    },
    {
      "step": 1175,
      "loss": 0.0243296530097723,
      "accuracy": 0.9375,
      "grad_norm": 0.3324914574623108
    },
    {
      "step": 1176,
      "loss": 0.009334961883723736,
      "accuracy": 1.0,
      "grad_norm": 0.34497323632240295
    },
    {
      "step": 1177,
      "loss": 0.037061601877212524,
      "accuracy": 0.9375,
      "grad_norm": 0.7807577848434448
    },
    {
      "step": 1178,
      "loss": 0.05306890979409218,
      "accuracy": 0.8125,
      "grad_norm": 1.106208324432373
    },
    {
      "step": 1179,
      "loss": 0.06323826313018799,
      "accuracy": 0.9375,
      "grad_norm": 0.3760974109172821
    },
    {
      "step": 1180,
      "loss": 0.0510765016078949,
      "accuracy": 0.9375,
      "grad_norm": 1.2260442972183228
    },
    {
      "step": 1181,
      "loss": 0.020098719745874405,
      "accuracy": 0.9375,
      "grad_norm": 0.4506797194480896
    },
    {
      "step": 1182,
      "loss": 0.036702025681734085,
      "accuracy": 0.875,
      "grad_norm": 0.8698586225509644
    },
    {
      "step": 1183,
      "loss": 0.023469602689146996,
      "accuracy": 0.9375,
      "grad_norm": 3.796199321746826
    },
    {
      "step": 1184,
      "loss": 0.058088213205337524,
      "accuracy": 0.9375,
      "grad_norm": 3.310643196105957
    },
    {
      "step": 1185,
      "loss": 0.0367414765059948,
      "accuracy": 0.9375,
      "grad_norm": 0.8205744028091431
    },
    {
      "step": 1186,
      "loss": 0.10193756967782974,
      "accuracy": 0.8125,
      "grad_norm": 1.0407006740570068
    },
    {
      "step": 1187,
      "loss": 0.04322412610054016,
      "accuracy": 0.875,
      "grad_norm": 0.828845202922821
    },
    {
      "step": 1188,
      "loss": 0.061335239559412,
      "accuracy": 0.875,
      "grad_norm": 0.9621737599372864
    },
    {
      "step": 1189,
      "loss": 0.06137275695800781,
      "accuracy": 0.875,
      "grad_norm": 0.42278245091438293
    },
    {
      "step": 1190,
      "loss": 0.03604806959629059,
      "accuracy": 0.9375,
      "grad_norm": 0.9685088396072388
    },
    {
      "step": 1191,
      "loss": 0.0315132737159729,
      "accuracy": 0.9375,
      "grad_norm": 0.5114112496376038
    },
    {
      "step": 1192,
      "loss": 0.03499162569642067,
      "accuracy": 0.9375,
      "grad_norm": 0.8475452661514282
    },
    {
      "step": 1193,
      "loss": 0.008980920538306236,
      "accuracy": 1.0,
      "grad_norm": 0.25847721099853516
    },
    {
      "step": 1194,
      "loss": 0.042531657963991165,
      "accuracy": 0.9375,
      "grad_norm": 0.3340640664100647
    },
    {
      "step": 1195,
      "loss": 0.06095096468925476,
      "accuracy": 0.875,
      "grad_norm": 0.9175609946250916
    },
    {
      "step": 1196,
      "loss": 0.016615265980362892,
      "accuracy": 1.0,
      "grad_norm": 0.38505828380584717
    },
    {
      "step": 1197,
      "loss": 0.004244860261678696,
      "accuracy": 1.0,
      "grad_norm": 0.21758931875228882
    },
    {
      "step": 1198,
      "loss": 0.06893311440944672,
      "accuracy": 0.875,
      "grad_norm": 1.8529515266418457
    },
    {
      "step": 1199,
      "loss": 0.11991288512945175,
      "accuracy": 0.875,
      "grad_norm": 1.0365321636199951
    },
    {
      "step": 1200,
      "loss": 0.13960734009742737,
      "accuracy": 0.8125,
      "grad_norm": 1.0725041627883911
    },
    {
      "step": 1201,
      "loss": 0.04729379713535309,
      "accuracy": 0.9375,
      "grad_norm": 0.3372372090816498
    },
    {
      "step": 1202,
      "loss": 0.04629536345601082,
      "accuracy": 0.9375,
      "grad_norm": 0.4241865575313568
    },
    {
      "step": 1203,
      "loss": 0.07465732097625732,
      "accuracy": 0.9375,
      "grad_norm": 0.4033035933971405
    },
    {
      "step": 1204,
      "loss": 0.06457557529211044,
      "accuracy": 0.9375,
      "grad_norm": 0.3649696707725525
    },
    {
      "step": 1205,
      "loss": 0.04926655814051628,
      "accuracy": 0.875,
      "grad_norm": 0.661986768245697
    },
    {
      "step": 1206,
      "loss": 0.02617257833480835,
      "accuracy": 0.9375,
      "grad_norm": 1.0068187713623047
    },
    {
      "step": 1207,
      "loss": 0.04957003891468048,
      "accuracy": 0.9375,
      "grad_norm": 0.611746072769165
    },
    {
      "step": 1208,
      "loss": 0.02601991593837738,
      "accuracy": 0.9375,
      "grad_norm": 0.22075797617435455
    },
    {
      "step": 1209,
      "loss": 0.01866801269352436,
      "accuracy": 1.0,
      "grad_norm": 0.5820382237434387
    },
    {
      "step": 1210,
      "loss": 0.05057942494750023,
      "accuracy": 0.875,
      "grad_norm": 0.605552613735199
    },
    {
      "step": 1211,
      "loss": 0.06443892419338226,
      "accuracy": 0.875,
      "grad_norm": 1.7575857639312744
    },
    {
      "step": 1212,
      "loss": 0.033395085483789444,
      "accuracy": 1.0,
      "grad_norm": 0.9679633378982544
    },
    {
      "step": 1213,
      "loss": 0.07182943820953369,
      "accuracy": 0.8125,
      "grad_norm": 0.7353709936141968
    },
    {
      "step": 1214,
      "loss": 0.011472053825855255,
      "accuracy": 1.0,
      "grad_norm": 0.19208134710788727
    },
    {
      "step": 1215,
      "loss": 0.08246040344238281,
      "accuracy": 0.8125,
      "grad_norm": 0.6508734822273254
    },
    {
      "step": 1216,
      "loss": 0.06689734756946564,
      "accuracy": 0.875,
      "grad_norm": 0.5151975750923157
    },
    {
      "step": 1217,
      "loss": 0.0239572711288929,
      "accuracy": 0.9375,
      "grad_norm": 0.1461782306432724
    },
    {
      "step": 1218,
      "loss": 0.014081625267863274,
      "accuracy": 1.0,
      "grad_norm": 0.3648104667663574
    },
    {
      "step": 1219,
      "loss": 0.02729327604174614,
      "accuracy": 0.9375,
      "grad_norm": 0.30650120973587036
    },
    {
      "step": 1220,
      "loss": 0.06959501653909683,
      "accuracy": 0.875,
      "grad_norm": 0.6619651913642883
    },
    {
      "step": 1221,
      "loss": 0.02178594097495079,
      "accuracy": 0.9375,
      "grad_norm": 0.3649800419807434
    },
    {
      "step": 1222,
      "loss": 0.01191882323473692,
      "accuracy": 1.0,
      "grad_norm": 0.27250200510025024
    },
    {
      "step": 1223,
      "loss": 0.04367794841527939,
      "accuracy": 0.9375,
      "grad_norm": 0.5408423542976379
    },
    {
      "step": 1224,
      "loss": 0.007196417078375816,
      "accuracy": 1.0,
      "grad_norm": 0.22044378519058228
    },
    {
      "step": 1225,
      "loss": 0.025871694087982178,
      "accuracy": 0.9375,
      "grad_norm": 0.6921582818031311
    },
    {
      "step": 1226,
      "loss": 0.03487195447087288,
      "accuracy": 1.0,
      "grad_norm": 0.28519338369369507
    },
    {
      "step": 1227,
      "loss": 0.004156465642154217,
      "accuracy": 1.0,
      "grad_norm": 0.10509039461612701
    },
    {
      "step": 1228,
      "loss": 0.005751308053731918,
      "accuracy": 1.0,
      "grad_norm": 0.14777088165283203
    },
    {
      "step": 1229,
      "loss": 0.01820719800889492,
      "accuracy": 1.0,
      "grad_norm": 0.5319858193397522
    },
    {
      "step": 1230,
      "loss": 0.0671503022313118,
      "accuracy": 0.875,
      "grad_norm": 1.2299801111221313
    },
    {
      "step": 1231,
      "loss": 0.01219953317195177,
      "accuracy": 1.0,
      "grad_norm": 0.24652335047721863
    },
    {
      "step": 1232,
      "loss": 0.04054960235953331,
      "accuracy": 0.9375,
      "grad_norm": 0.4899734854698181
    },
    {
      "step": 1233,
      "loss": 0.07665455341339111,
      "accuracy": 0.9375,
      "grad_norm": 0.397614449262619
    },
    {
      "step": 1234,
      "loss": 0.012540779076516628,
      "accuracy": 1.0,
      "grad_norm": 0.2844882607460022
    },
    {
      "step": 1235,
      "loss": 0.060242440551519394,
      "accuracy": 0.9375,
      "grad_norm": 0.5683759450912476
    },
    {
      "step": 1236,
      "loss": 0.03315163403749466,
      "accuracy": 0.9375,
      "grad_norm": 0.33851468563079834
    },
    {
      "step": 1237,
      "loss": 0.009058701805770397,
      "accuracy": 1.0,
      "grad_norm": 0.2721530795097351
    },
    {
      "step": 1238,
      "loss": 0.02405994012951851,
      "accuracy": 1.0,
      "grad_norm": 0.5132521986961365
    },
    {
      "step": 1239,
      "loss": 0.021513039246201515,
      "accuracy": 1.0,
      "grad_norm": 0.3015724718570709
    },
    {
      "step": 1240,
      "loss": 0.06674882769584656,
      "accuracy": 0.9375,
      "grad_norm": 0.34426888823509216
    },
    {
      "step": 1241,
      "loss": 0.04371527582406998,
      "accuracy": 0.9375,
      "grad_norm": 2.120306968688965
    },
    {
      "step": 1242,
      "loss": 0.07659924775362015,
      "accuracy": 0.875,
      "grad_norm": 0.47258925437927246
    },
    {
      "step": 1243,
      "loss": 0.005385982804000378,
      "accuracy": 1.0,
      "grad_norm": 0.20481686294078827
    },
    {
      "step": 1244,
      "loss": 0.02540772780776024,
      "accuracy": 0.9375,
      "grad_norm": 1.3172677755355835
    },
    {
      "step": 1245,
      "loss": 0.02851785719394684,
      "accuracy": 0.9375,
      "grad_norm": 0.6969173550605774
    },
    {
      "step": 1246,
      "loss": 0.10315603762865067,
      "accuracy": 0.8125,
      "grad_norm": 1.340745449066162
    },
    {
      "step": 1247,
      "loss": 0.031111568212509155,
      "accuracy": 0.9375,
      "grad_norm": 0.39566221833229065
    },
    {
      "step": 1248,
      "loss": 0.07038554549217224,
      "accuracy": 0.875,
      "grad_norm": 1.1539618968963623
    },
    {
      "step": 1249,
      "loss": 0.09512341767549515,
      "accuracy": 0.8125,
      "grad_norm": 0.9618892669677734
    },
    {
      "step": 1250,
      "loss": 0.0634407103061676,
      "accuracy": 0.9375,
      "grad_norm": 0.5725077986717224
    },
    {
      "step": 1251,
      "loss": 0.04360286891460419,
      "accuracy": 0.9375,
      "grad_norm": 1.087579369544983
    },
    {
      "step": 1252,
      "loss": 0.056028950959444046,
      "accuracy": 0.9375,
      "grad_norm": 1.8325517177581787
    },
    {
      "step": 1253,
      "loss": 0.0595710463821888,
      "accuracy": 0.875,
      "grad_norm": 0.613118588924408
    },
    {
      "step": 1254,
      "loss": 0.049431655555963516,
      "accuracy": 0.875,
      "grad_norm": 0.5226997137069702
    },
    {
      "step": 1255,
      "loss": 0.012735391966998577,
      "accuracy": 1.0,
      "grad_norm": 0.24236807227134705
    },
    {
      "step": 1256,
      "loss": 0.02559785358607769,
      "accuracy": 1.0,
      "grad_norm": 0.2573196589946747
    },
    {
      "step": 1257,
      "loss": 0.03979630768299103,
      "accuracy": 0.9375,
      "grad_norm": 0.2772921919822693
    },
    {
      "step": 1258,
      "loss": 0.04662184789776802,
      "accuracy": 0.9375,
      "grad_norm": 0.26456621289253235
    },
    {
      "step": 1259,
      "loss": 0.07902251929044724,
      "accuracy": 0.9375,
      "grad_norm": 0.5073229074478149
    },
    {
      "step": 1260,
      "loss": 0.03495648130774498,
      "accuracy": 1.0,
      "grad_norm": 0.20103871822357178
    },
    {
      "step": 1261,
      "loss": 0.02846650406718254,
      "accuracy": 0.875,
      "grad_norm": 0.6001793146133423
    },
    {
      "step": 1262,
      "loss": 0.12218380719423294,
      "accuracy": 0.8125,
      "grad_norm": 1.546141266822815
    },
    {
      "step": 1263,
      "loss": 0.03822968155145645,
      "accuracy": 0.9375,
      "grad_norm": 1.3028455972671509
    },
    {
      "step": 1264,
      "loss": 0.029023243114352226,
      "accuracy": 0.9375,
      "grad_norm": 0.2554747760295868
    },
    {
      "step": 1265,
      "loss": 0.04611019045114517,
      "accuracy": 0.9375,
      "grad_norm": 0.3372880518436432
    },
    {
      "step": 1266,
      "loss": 0.04131511598825455,
      "accuracy": 0.9375,
      "grad_norm": 0.24809063971042633
    },
    {
      "step": 1267,
      "loss": 0.07534177601337433,
      "accuracy": 0.875,
      "grad_norm": 0.5120897889137268
    },
    {
      "step": 1268,
      "loss": 0.10192675143480301,
      "accuracy": 0.875,
      "grad_norm": 3.469266176223755
    },
    {
      "step": 1269,
      "loss": 0.01779542677104473,
      "accuracy": 0.9375,
      "grad_norm": 0.2517990171909332
    },
    {
      "step": 1270,
      "loss": 0.03354887664318085,
      "accuracy": 0.9375,
      "grad_norm": 0.5465219020843506
    },
    {
      "step": 1271,
      "loss": 0.02562776952981949,
      "accuracy": 1.0,
      "grad_norm": 0.3496599793434143
    },
    {
      "step": 1272,
      "loss": 0.03387284278869629,
      "accuracy": 1.0,
      "grad_norm": 0.766847550868988
    },
    {
      "step": 1273,
      "loss": 0.04740315303206444,
      "accuracy": 0.9375,
      "grad_norm": 1.296291708946228
    },
    {
      "step": 1274,
      "loss": 0.019027773290872574,
      "accuracy": 1.0,
      "grad_norm": 0.5420088768005371
    },
    {
      "step": 1275,
      "loss": 0.05969097837805748,
      "accuracy": 0.9375,
      "grad_norm": 0.32435786724090576
    },
    {
      "step": 1276,
      "loss": 0.1094934344291687,
      "accuracy": 0.8125,
      "grad_norm": 1.6326926946640015
    },
    {
      "step": 1277,
      "loss": 0.01454246137291193,
      "accuracy": 1.0,
      "grad_norm": 0.30362215638160706
    },
    {
      "step": 1278,
      "loss": 0.04190777987241745,
      "accuracy": 0.9375,
      "grad_norm": 0.4007646441459656
    },
    {
      "step": 1279,
      "loss": 0.02791699394583702,
      "accuracy": 0.9375,
      "grad_norm": 0.43107539415359497
    },
    {
      "step": 1280,
      "loss": 0.08080493658781052,
      "accuracy": 0.875,
      "grad_norm": 1.2830653190612793
    },
    {
      "step": 1281,
      "loss": 0.0057461196556687355,
      "accuracy": 1.0,
      "grad_norm": 0.1725049614906311
    },
    {
      "step": 1282,
      "loss": 0.0035754425916820765,
      "accuracy": 1.0,
      "grad_norm": 0.08088477700948715
    },
    {
      "step": 1283,
      "loss": 0.005803942214697599,
      "accuracy": 1.0,
      "grad_norm": 0.19858208298683167
    },
    {
      "step": 1284,
      "loss": 0.008618732914328575,
      "accuracy": 1.0,
      "grad_norm": 0.29661887884140015
    },
    {
      "step": 1285,
      "loss": 0.016513418406248093,
      "accuracy": 0.9375,
      "grad_norm": 0.750904381275177
    },
    {
      "step": 1286,
      "loss": 0.008328258991241455,
      "accuracy": 1.0,
      "grad_norm": 0.34013617038726807
    },
    {
      "step": 1287,
      "loss": 0.00393492728471756,
      "accuracy": 1.0,
      "grad_norm": 0.13600386679172516
    },
    {
      "step": 1288,
      "loss": 0.02810688503086567,
      "accuracy": 0.9375,
      "grad_norm": 1.9531692266464233
    },
    {
      "step": 1289,
      "loss": 0.009668498300015926,
      "accuracy": 1.0,
      "grad_norm": 0.4119666516780853
    },
    {
      "step": 1290,
      "loss": 0.00830696802586317,
      "accuracy": 1.0,
      "grad_norm": 0.990919828414917
    },
    {
      "step": 1291,
      "loss": 0.0027635982260107994,
      "accuracy": 1.0,
      "grad_norm": 0.06936652213335037
    },
    {
      "step": 1292,
      "loss": 0.1532021462917328,
      "accuracy": 0.6875,
      "grad_norm": 8.258153915405273
    },
    {
      "step": 1293,
      "loss": 0.10672449320554733,
      "accuracy": 0.8125,
      "grad_norm": 10.193470001220703
    },
    {
      "step": 1294,
      "loss": 0.11065451800823212,
      "accuracy": 0.8125,
      "grad_norm": 9.941469192504883
    },
    {
      "step": 1295,
      "loss": 0.018245508894324303,
      "accuracy": 0.9375,
      "grad_norm": 1.460512399673462
    },
    {
      "step": 1296,
      "loss": 0.00898437388241291,
      "accuracy": 1.0,
      "grad_norm": 0.32757464051246643
    },
    {
      "step": 1297,
      "loss": 0.043055951595306396,
      "accuracy": 0.9375,
      "grad_norm": 0.9278318285942078
    },
    {
      "step": 1298,
      "loss": 0.0021640234626829624,
      "accuracy": 1.0,
      "grad_norm": 0.055417366325855255
    },
    {
      "step": 1299,
      "loss": 0.04273666441440582,
      "accuracy": 0.9375,
      "grad_norm": 0.6060834527015686
    },
    {
      "step": 1300,
      "loss": 0.0032020569778978825,
      "accuracy": 1.0,
      "grad_norm": 0.28305575251579285
    },
    {
      "step": 1301,
      "loss": 0.0015912421513348818,
      "accuracy": 1.0,
      "grad_norm": 0.04756106063723564
    },
    {
      "step": 1302,
      "loss": 0.0016487682005390525,
      "accuracy": 1.0,
      "grad_norm": 0.03844817727804184
    },
    {
      "step": 1303,
      "loss": 0.003137097228318453,
      "accuracy": 1.0,
      "grad_norm": 0.10984106361865997
    },
    {
      "step": 1304,
      "loss": 0.05255098640918732,
      "accuracy": 0.9375,
      "grad_norm": 0.7895997762680054
    },
    {
      "step": 1305,
      "loss": 0.14615346491336823,
      "accuracy": 0.8125,
      "grad_norm": 1.6996599435806274
    },
    {
      "step": 1306,
      "loss": 0.001948108896613121,
      "accuracy": 1.0,
      "grad_norm": 0.04359298199415207
    },
    {
      "step": 1307,
      "loss": 0.0344545878469944,
      "accuracy": 0.9375,
      "grad_norm": 0.5712341666221619
    },
    {
      "step": 1308,
      "loss": 0.08197983354330063,
      "accuracy": 0.875,
      "grad_norm": 1.2365630865097046
    },
    {
      "step": 1309,
      "loss": 0.06983886659145355,
      "accuracy": 0.8125,
      "grad_norm": 2.012002944946289
    },
    {
      "step": 1310,
      "loss": 0.014144535176455975,
      "accuracy": 0.9375,
      "grad_norm": 0.6496257781982422
    },
    {
      "step": 1311,
      "loss": 0.0129983676597476,
      "accuracy": 1.0,
      "grad_norm": 0.49845412373542786
    },
    {
      "step": 1312,
      "loss": 0.15852345526218414,
      "accuracy": 0.8125,
      "grad_norm": 5.224266052246094
    },
    {
      "step": 1313,
      "loss": 0.22300681471824646,
      "accuracy": 0.75,
      "grad_norm": 5.722018718719482
    },
    {
      "step": 1314,
      "loss": 0.00702041108161211,
      "accuracy": 1.0,
      "grad_norm": 0.17167337238788605
    },
    {
      "step": 1315,
      "loss": 0.1417084038257599,
      "accuracy": 0.875,
      "grad_norm": 1.6076351404190063
    },
    {
      "step": 1316,
      "loss": 0.20394212007522583,
      "accuracy": 0.6875,
      "grad_norm": 5.928768157958984
    },
    {
      "step": 1317,
      "loss": 0.09770739823579788,
      "accuracy": 0.875,
      "grad_norm": 5.195276737213135
    },
    {
      "step": 1318,
      "loss": 0.012469781562685966,
      "accuracy": 1.0,
      "grad_norm": 0.5211740136146545
    },
    {
      "step": 1319,
      "loss": 0.03673333302140236,
      "accuracy": 1.0,
      "grad_norm": 0.385530024766922
    },
    {
      "step": 1320,
      "loss": 0.06041105091571808,
      "accuracy": 0.9375,
      "grad_norm": 0.3499361276626587
    },
    {
      "step": 1321,
      "loss": 0.013595042750239372,
      "accuracy": 1.0,
      "grad_norm": 0.38281866908073425
    },
    {
      "step": 1322,
      "loss": 0.012477022595703602,
      "accuracy": 1.0,
      "grad_norm": 0.16388636827468872
    },
    {
      "step": 1323,
      "loss": 0.04724668338894844,
      "accuracy": 0.9375,
      "grad_norm": 0.6203708648681641
    },
    {
      "step": 1324,
      "loss": 0.07117047905921936,
      "accuracy": 0.9375,
      "grad_norm": 1.3323235511779785
    },
    {
      "step": 1325,
      "loss": 0.058396581560373306,
      "accuracy": 0.875,
      "grad_norm": 1.0897011756896973
    },
    {
      "step": 1326,
      "loss": 0.06849242001771927,
      "accuracy": 0.9375,
      "grad_norm": 0.7069190740585327
    },
    {
      "step": 1327,
      "loss": 0.078423872590065,
      "accuracy": 0.875,
      "grad_norm": 0.69243323802948
    },
    {
      "step": 1328,
      "loss": 0.05012761428952217,
      "accuracy": 0.875,
      "grad_norm": 0.6954070329666138
    },
    {
      "step": 1329,
      "loss": 0.1311827003955841,
      "accuracy": 0.75,
      "grad_norm": 1.6924906969070435
    },
    {
      "step": 1330,
      "loss": 0.026426395401358604,
      "accuracy": 1.0,
      "grad_norm": 0.6731407046318054
    },
    {
      "step": 1331,
      "loss": 0.03910889849066734,
      "accuracy": 0.9375,
      "grad_norm": 0.8043737411499023
    },
    {
      "step": 1332,
      "loss": 0.029859885573387146,
      "accuracy": 1.0,
      "grad_norm": 0.5051479339599609
    },
    {
      "step": 1333,
      "loss": 0.03250271826982498,
      "accuracy": 0.9375,
      "grad_norm": 0.4404362440109253
    },
    {
      "step": 1334,
      "loss": 0.018222808837890625,
      "accuracy": 1.0,
      "grad_norm": 0.2660532593727112
    },
    {
      "step": 1335,
      "loss": 0.0330149345099926,
      "accuracy": 0.9375,
      "grad_norm": 0.7804901599884033
    },
    {
      "step": 1336,
      "loss": 0.04578017443418503,
      "accuracy": 0.9375,
      "grad_norm": 0.26638489961624146
    },
    {
      "step": 1337,
      "loss": 0.10472448170185089,
      "accuracy": 0.8125,
      "grad_norm": 1.4516910314559937
    },
    {
      "step": 1338,
      "loss": 0.07171260565519333,
      "accuracy": 0.875,
      "grad_norm": 0.5500586032867432
    },
    {
      "step": 1339,
      "loss": 0.023217178881168365,
      "accuracy": 1.0,
      "grad_norm": 0.3654245436191559
    },
    {
      "step": 1340,
      "loss": 0.009252221323549747,
      "accuracy": 1.0,
      "grad_norm": 0.23788785934448242
    },
    {
      "step": 1341,
      "loss": 0.006383100524544716,
      "accuracy": 1.0,
      "grad_norm": 0.14105023443698883
    },
    {
      "step": 1342,
      "loss": 0.018802756443619728,
      "accuracy": 0.9375,
      "grad_norm": 0.33411529660224915
    },
    {
      "step": 1343,
      "loss": 0.008381773717701435,
      "accuracy": 1.0,
      "grad_norm": 0.18318918347358704
    },
    {
      "step": 1344,
      "loss": 0.059597745537757874,
      "accuracy": 0.9375,
      "grad_norm": 0.32863932847976685
    },
    {
      "step": 1345,
      "loss": 0.018890397623181343,
      "accuracy": 0.9375,
      "grad_norm": 0.3311244547367096
    },
    {
      "step": 1346,
      "loss": 0.00950611662119627,
      "accuracy": 1.0,
      "grad_norm": 0.20291613042354584
    },
    {
      "step": 1347,
      "loss": 0.11140823364257812,
      "accuracy": 0.8125,
      "grad_norm": 1.4077575206756592
    },
    {
      "step": 1348,
      "loss": 0.026882126927375793,
      "accuracy": 0.9375,
      "grad_norm": 0.5442173480987549
    },
    {
      "step": 1349,
      "loss": 0.042205993086099625,
      "accuracy": 0.9375,
      "grad_norm": 0.37770363688468933
    },
    {
      "step": 1350,
      "loss": 0.005762510467320681,
      "accuracy": 1.0,
      "grad_norm": 0.16275696456432343
    },
    {
      "step": 1351,
      "loss": 0.003922209143638611,
      "accuracy": 1.0,
      "grad_norm": 0.11075890064239502
    },
    {
      "step": 1352,
      "loss": 0.07004212588071823,
      "accuracy": 0.875,
      "grad_norm": 0.5428378582000732
    },
    {
      "step": 1353,
      "loss": 0.03398329019546509,
      "accuracy": 0.875,
      "grad_norm": 0.5295934081077576
    },
    {
      "step": 1354,
      "loss": 0.026281150057911873,
      "accuracy": 1.0,
      "grad_norm": 0.4256364703178406
    },
    {
      "step": 1355,
      "loss": 0.013367537409067154,
      "accuracy": 1.0,
      "grad_norm": 0.5196176767349243
    },
    {
      "step": 1356,
      "loss": 0.006813845597207546,
      "accuracy": 1.0,
      "grad_norm": 0.17647922039031982
    },
    {
      "step": 1357,
      "loss": 0.06506875902414322,
      "accuracy": 0.875,
      "grad_norm": 1.5654124021530151
    },
    {
      "step": 1358,
      "loss": 0.0058900429867208,
      "accuracy": 1.0,
      "grad_norm": 0.13809095323085785
    },
    {
      "step": 1359,
      "loss": 0.07622622698545456,
      "accuracy": 0.8125,
      "grad_norm": 1.8337153196334839
    },
    {
      "step": 1360,
      "loss": 0.041558727622032166,
      "accuracy": 0.9375,
      "grad_norm": 0.6204656958580017
    },
    {
      "step": 1361,
      "loss": 0.026279721409082413,
      "accuracy": 0.9375,
      "grad_norm": 0.6380337476730347
    },
    {
      "step": 1362,
      "loss": 0.015723222866654396,
      "accuracy": 1.0,
      "grad_norm": 0.2238793820142746
    },
    {
      "step": 1363,
      "loss": 0.05259839445352554,
      "accuracy": 0.9375,
      "grad_norm": 0.6177293658256531
    },
    {
      "step": 1364,
      "loss": 0.06229781731963158,
      "accuracy": 0.875,
      "grad_norm": 1.5309401750564575
    },
    {
      "step": 1365,
      "loss": 0.05843671038746834,
      "accuracy": 0.8125,
      "grad_norm": 1.7216581106185913
    },
    {
      "step": 1366,
      "loss": 0.0035257129929959774,
      "accuracy": 1.0,
      "grad_norm": 0.08871061354875565
    },
    {
      "step": 1367,
      "loss": 0.009679527953267097,
      "accuracy": 1.0,
      "grad_norm": 0.5736691355705261
    },
    {
      "step": 1368,
      "loss": 0.060934606939554214,
      "accuracy": 0.9375,
      "grad_norm": 1.9427459239959717
    },
    {
      "step": 1369,
      "loss": 0.04238923266530037,
      "accuracy": 0.9375,
      "grad_norm": 0.27762484550476074
    },
    {
      "step": 1370,
      "loss": 0.019076306372880936,
      "accuracy": 0.9375,
      "grad_norm": 0.22429056465625763
    },
    {
      "step": 1371,
      "loss": 0.009940292686223984,
      "accuracy": 1.0,
      "grad_norm": 0.422184020280838
    },
    {
      "step": 1372,
      "loss": 0.03628682345151901,
      "accuracy": 1.0,
      "grad_norm": 0.7763640880584717
    },
    {
      "step": 1373,
      "loss": 0.05099207162857056,
      "accuracy": 0.9375,
      "grad_norm": 0.6309466361999512
    },
    {
      "step": 1374,
      "loss": 0.05117730796337128,
      "accuracy": 0.875,
      "grad_norm": 0.8782889246940613
    },
    {
      "step": 1375,
      "loss": 0.022595414891839027,
      "accuracy": 1.0,
      "grad_norm": 0.16129718720912933
    },
    {
      "step": 1376,
      "loss": 0.021609865128993988,
      "accuracy": 1.0,
      "grad_norm": 0.4630260765552521
    },
    {
      "step": 1377,
      "loss": 0.07119376212358475,
      "accuracy": 0.875,
      "grad_norm": 1.375536561012268
    },
    {
      "step": 1378,
      "loss": 0.01913430728018284,
      "accuracy": 0.9375,
      "grad_norm": 0.8988941311836243
    },
    {
      "step": 1379,
      "loss": 0.032872773706912994,
      "accuracy": 0.9375,
      "grad_norm": 1.1278289556503296
    },
    {
      "step": 1380,
      "loss": 0.0059182606637477875,
      "accuracy": 1.0,
      "grad_norm": 0.27076002955436707
    },
    {
      "step": 1381,
      "loss": 0.10334111005067825,
      "accuracy": 0.875,
      "grad_norm": 1.206379771232605
    },
    {
      "step": 1382,
      "loss": 0.12523053586483002,
      "accuracy": 0.8125,
      "grad_norm": 1.6563334465026855
    },
    {
      "step": 1383,
      "loss": 0.11299373209476471,
      "accuracy": 0.8125,
      "grad_norm": 1.2856831550598145
    },
    {
      "step": 1384,
      "loss": 0.06237446889281273,
      "accuracy": 0.875,
      "grad_norm": 1.8988057374954224
    },
    {
      "step": 1385,
      "loss": 0.0527929849922657,
      "accuracy": 0.9375,
      "grad_norm": 1.0207723379135132
    },
    {
      "step": 1386,
      "loss": 0.0016361532034352422,
      "accuracy": 1.0,
      "grad_norm": 0.03715568408370018
    },
    {
      "step": 1387,
      "loss": 0.12202905863523483,
      "accuracy": 0.75,
      "grad_norm": 2.108091354370117
    },
    {
      "step": 1388,
      "loss": 0.03535892814397812,
      "accuracy": 0.9375,
      "grad_norm": 0.7531205415725708
    },
    {
      "step": 1389,
      "loss": 0.03888283669948578,
      "accuracy": 0.875,
      "grad_norm": 1.603125810623169
    },
    {
      "step": 1390,
      "loss": 0.06331678479909897,
      "accuracy": 0.9375,
      "grad_norm": 2.329821825027466
    },
    {
      "step": 1391,
      "loss": 0.0803227350115776,
      "accuracy": 0.75,
      "grad_norm": 2.4359383583068848
    },
    {
      "step": 1392,
      "loss": 0.009215245954692364,
      "accuracy": 1.0,
      "grad_norm": 0.3064197301864624
    },
    {
      "step": 1393,
      "loss": 0.024933261796832085,
      "accuracy": 0.9375,
      "grad_norm": 0.7235860824584961
    },
    {
      "step": 1394,
      "loss": 0.04749859496951103,
      "accuracy": 0.8125,
      "grad_norm": 1.271600365638733
    },
    {
      "step": 1395,
      "loss": 0.083860844373703,
      "accuracy": 0.875,
      "grad_norm": 0.9379434585571289
    },
    {
      "step": 1396,
      "loss": 0.0212665144354105,
      "accuracy": 0.9375,
      "grad_norm": 0.21404942870140076
    },
    {
      "step": 1397,
      "loss": 0.0067255524918437,
      "accuracy": 1.0,
      "grad_norm": 0.15820856392383575
    },
    {
      "step": 1398,
      "loss": 0.0780838131904602,
      "accuracy": 0.875,
      "grad_norm": 0.913361132144928
    },
    {
      "step": 1399,
      "loss": 0.03196117281913757,
      "accuracy": 0.9375,
      "grad_norm": 0.7447218894958496
    },
    {
      "step": 1400,
      "loss": 0.034532081335783005,
      "accuracy": 0.9375,
      "grad_norm": 0.7678021788597107
    },
    {
      "step": 1401,
      "loss": 0.030625082552433014,
      "accuracy": 1.0,
      "grad_norm": 0.9208207130432129
    },
    {
      "step": 1402,
      "loss": 0.010503718629479408,
      "accuracy": 1.0,
      "grad_norm": 0.30352333188056946
    },
    {
      "step": 1403,
      "loss": 0.03292445093393326,
      "accuracy": 0.9375,
      "grad_norm": 0.6618949770927429
    },
    {
      "step": 1404,
      "loss": 0.03237157315015793,
      "accuracy": 0.9375,
      "grad_norm": 0.7211709022521973
    },
    {
      "step": 1405,
      "loss": 0.022389724850654602,
      "accuracy": 0.9375,
      "grad_norm": 0.6540056467056274
    },
    {
      "step": 1406,
      "loss": 0.029194604605436325,
      "accuracy": 0.9375,
      "grad_norm": 0.5503900647163391
    },
    {
      "step": 1407,
      "loss": 0.015586555935442448,
      "accuracy": 1.0,
      "grad_norm": 0.2656576931476593
    },
    {
      "step": 1408,
      "loss": 0.017142275348305702,
      "accuracy": 1.0,
      "grad_norm": 0.35599949955940247
    },
    {
      "step": 1409,
      "loss": 0.0839284285902977,
      "accuracy": 0.8125,
      "grad_norm": 1.4803069829940796
    },
    {
      "step": 1410,
      "loss": 0.0025134694296866655,
      "accuracy": 1.0,
      "grad_norm": 0.06341931968927383
    },
    {
      "step": 1411,
      "loss": 0.0616082102060318,
      "accuracy": 0.9375,
      "grad_norm": 0.6308468580245972
    },
    {
      "step": 1412,
      "loss": 0.009251970797777176,
      "accuracy": 1.0,
      "grad_norm": 0.14641258120536804
    },
    {
      "step": 1413,
      "loss": 0.01171908713877201,
      "accuracy": 1.0,
      "grad_norm": 0.4147866368293762
    },
    {
      "step": 1414,
      "loss": 0.07609374076128006,
      "accuracy": 0.875,
      "grad_norm": 0.9771170020103455
    },
    {
      "step": 1415,
      "loss": 0.0009598448523320258,
      "accuracy": 1.0,
      "grad_norm": 0.019483041018247604
    },
    {
      "step": 1416,
      "loss": 0.003063611686229706,
      "accuracy": 1.0,
      "grad_norm": 0.07440702617168427
    },
    {
      "step": 1417,
      "loss": 0.07223422825336456,
      "accuracy": 0.8125,
      "grad_norm": 1.648633360862732
    },
    {
      "step": 1418,
      "loss": 0.023101555183529854,
      "accuracy": 0.9375,
      "grad_norm": 0.4442465901374817
    },
    {
      "step": 1419,
      "loss": 0.016570378094911575,
      "accuracy": 1.0,
      "grad_norm": 0.3618173599243164
    },
    {
      "step": 1420,
      "loss": 0.018923725932836533,
      "accuracy": 1.0,
      "grad_norm": 0.5404239892959595
    },
    {
      "step": 1421,
      "loss": 0.05781501904129982,
      "accuracy": 0.875,
      "grad_norm": 0.8978239297866821
    },
    {
      "step": 1422,
      "loss": 0.004215550143271685,
      "accuracy": 1.0,
      "grad_norm": 0.14098931849002838
    },
    {
      "step": 1423,
      "loss": 0.012641862966120243,
      "accuracy": 1.0,
      "grad_norm": 0.733792245388031
    },
    {
      "step": 1424,
      "loss": 0.007743739057332277,
      "accuracy": 1.0,
      "grad_norm": 0.2727075517177582
    },
    {
      "step": 1425,
      "loss": 0.015612916089594364,
      "accuracy": 1.0,
      "grad_norm": 0.7698807120323181
    },
    {
      "step": 1426,
      "loss": 0.027248818427324295,
      "accuracy": 0.9375,
      "grad_norm": 0.7859179377555847
    },
    {
      "step": 1427,
      "loss": 0.0033228565007448196,
      "accuracy": 1.0,
      "grad_norm": 0.08026017993688583
    },
    {
      "step": 1428,
      "loss": 0.0044877538457512856,
      "accuracy": 1.0,
      "grad_norm": 0.10964161902666092
    },
    {
      "step": 1429,
      "loss": 0.04202805459499359,
      "accuracy": 0.9375,
      "grad_norm": 0.9357587099075317
    },
    {
      "step": 1430,
      "loss": 0.036663252860307693,
      "accuracy": 0.9375,
      "grad_norm": 0.8019790053367615
    },
    {
      "step": 1431,
      "loss": 0.056916430592536926,
      "accuracy": 0.875,
      "grad_norm": 1.7390128374099731
    },
    {
      "step": 1432,
      "loss": 0.04911259189248085,
      "accuracy": 0.9375,
      "grad_norm": 1.8009742498397827
    },
    {
      "step": 1433,
      "loss": 0.01398678869009018,
      "accuracy": 1.0,
      "grad_norm": 0.34189093112945557
    },
    {
      "step": 1434,
      "loss": 0.03332344442605972,
      "accuracy": 0.9375,
      "grad_norm": 0.6770639419555664
    },
    {
      "step": 1435,
      "loss": 0.018130207434296608,
      "accuracy": 1.0,
      "grad_norm": 1.1507911682128906
    },
    {
      "step": 1436,
      "loss": 0.12748198211193085,
      "accuracy": 0.8125,
      "grad_norm": 3.711972236633301
    },
    {
      "step": 1437,
      "loss": 0.11120092123746872,
      "accuracy": 0.8125,
      "grad_norm": 1.682645559310913
    },
    {
      "step": 1438,
      "loss": 0.02977851592004299,
      "accuracy": 0.9375,
      "grad_norm": 0.6718720197677612
    },
    {
      "step": 1439,
      "loss": 0.041462626308202744,
      "accuracy": 0.9375,
      "grad_norm": 1.1061921119689941
    },
    {
      "step": 1440,
      "loss": 0.03705209866166115,
      "accuracy": 0.9375,
      "grad_norm": 1.1951907873153687
    },
    {
      "step": 1441,
      "loss": 0.06297548860311508,
      "accuracy": 0.9375,
      "grad_norm": 0.7551674842834473
    },
    {
      "step": 1442,
      "loss": 0.11020468175411224,
      "accuracy": 0.875,
      "grad_norm": 1.1860737800598145
    },
    {
      "step": 1443,
      "loss": 0.04164652153849602,
      "accuracy": 0.875,
      "grad_norm": 0.37484803795814514
    },
    {
      "step": 1444,
      "loss": 0.01158037781715393,
      "accuracy": 1.0,
      "grad_norm": 0.14218950271606445
    },
    {
      "step": 1445,
      "loss": 0.003742634318768978,
      "accuracy": 1.0,
      "grad_norm": 0.1167498230934143
    },
    {
      "step": 1446,
      "loss": 0.0024507115595042706,
      "accuracy": 1.0,
      "grad_norm": 0.043276820331811905
    },
    {
      "step": 1447,
      "loss": 0.019401881843805313,
      "accuracy": 0.9375,
      "grad_norm": 0.5130581855773926
    },
    {
      "step": 1448,
      "loss": 0.0046591321006417274,
      "accuracy": 1.0,
      "grad_norm": 0.13093261420726776
    },
    {
      "step": 1449,
      "loss": 0.029132673516869545,
      "accuracy": 0.9375,
      "grad_norm": 0.29767024517059326
    },
    {
      "step": 1450,
      "loss": 0.003767963033169508,
      "accuracy": 1.0,
      "grad_norm": 0.09650687128305435
    },
    {
      "step": 1451,
      "loss": 0.011908503249287605,
      "accuracy": 1.0,
      "grad_norm": 0.4193131923675537
    },
    {
      "step": 1452,
      "loss": 0.007647324353456497,
      "accuracy": 1.0,
      "grad_norm": 0.18013902008533478
    },
    {
      "step": 1453,
      "loss": 0.02015089988708496,
      "accuracy": 0.9375,
      "grad_norm": 0.34864726662635803
    },
    {
      "step": 1454,
      "loss": 0.05132671818137169,
      "accuracy": 0.875,
      "grad_norm": 1.0975593328475952
    },
    {
      "step": 1455,
      "loss": 0.053023893386125565,
      "accuracy": 0.9375,
      "grad_norm": 0.6357976198196411
    },
    {
      "step": 1456,
      "loss": 0.023323772475123405,
      "accuracy": 0.9375,
      "grad_norm": 0.1975845843553543
    },
    {
      "step": 1457,
      "loss": 0.03959433361887932,
      "accuracy": 0.9375,
      "grad_norm": 0.9157572984695435
    },
    {
      "step": 1458,
      "loss": 0.030478252097964287,
      "accuracy": 0.9375,
      "grad_norm": 0.2593056559562683
    },
    {
      "step": 1459,
      "loss": 0.042148273438215256,
      "accuracy": 0.9375,
      "grad_norm": 1.0655794143676758
    },
    {
      "step": 1460,
      "loss": 0.1217878982424736,
      "accuracy": 0.875,
      "grad_norm": 1.5979435443878174
    },
    {
      "step": 1461,
      "loss": 0.08937682211399078,
      "accuracy": 0.8125,
      "grad_norm": 4.713439464569092
    },
    {
      "step": 1462,
      "loss": 0.038002122193574905,
      "accuracy": 0.9375,
      "grad_norm": 1.167981505393982
    },
    {
      "step": 1463,
      "loss": 0.044376567006111145,
      "accuracy": 0.8125,
      "grad_norm": 0.9029722213745117
    },
    {
      "step": 1464,
      "loss": 0.02705138735473156,
      "accuracy": 0.9375,
      "grad_norm": 0.5280276536941528
    },
    {
      "step": 1465,
      "loss": 0.017480365931987762,
      "accuracy": 1.0,
      "grad_norm": 0.8742492198944092
    },
    {
      "step": 1466,
      "loss": 0.02119101770222187,
      "accuracy": 0.9375,
      "grad_norm": 0.26293817162513733
    },
    {
      "step": 1467,
      "loss": 0.00941440649330616,
      "accuracy": 1.0,
      "grad_norm": 0.3846836984157562
    },
    {
      "step": 1468,
      "loss": 0.017186328768730164,
      "accuracy": 0.9375,
      "grad_norm": 0.4600774943828583
    },
    {
      "step": 1469,
      "loss": 0.009951150976121426,
      "accuracy": 1.0,
      "grad_norm": 0.12800480425357819
    },
    {
      "step": 1470,
      "loss": 0.007543238345533609,
      "accuracy": 1.0,
      "grad_norm": 0.3254953622817993
    },
    {
      "step": 1471,
      "loss": 0.0685269832611084,
      "accuracy": 0.875,
      "grad_norm": 1.8062968254089355
    },
    {
      "step": 1472,
      "loss": 0.023283833637833595,
      "accuracy": 0.9375,
      "grad_norm": 0.49056607484817505
    },
    {
      "step": 1473,
      "loss": 0.024527231231331825,
      "accuracy": 0.9375,
      "grad_norm": 0.9351897835731506
    },
    {
      "step": 1474,
      "loss": 0.019171681255102158,
      "accuracy": 0.9375,
      "grad_norm": 0.8362057209014893
    },
    {
      "step": 1475,
      "loss": 0.07869666814804077,
      "accuracy": 0.875,
      "grad_norm": 1.8618106842041016
    },
    {
      "step": 1476,
      "loss": 0.018164120614528656,
      "accuracy": 1.0,
      "grad_norm": 0.7537604570388794
    },
    {
      "step": 1477,
      "loss": 0.10439314693212509,
      "accuracy": 0.875,
      "grad_norm": 1.128935694694519
    },
    {
      "step": 1478,
      "loss": 0.05684438720345497,
      "accuracy": 0.875,
      "grad_norm": 0.7532562613487244
    },
    {
      "step": 1479,
      "loss": 0.01322677917778492,
      "accuracy": 1.0,
      "grad_norm": 0.5808274149894714
    },
    {
      "step": 1480,
      "loss": 0.013413459993898869,
      "accuracy": 1.0,
      "grad_norm": 0.4904782772064209
    },
    {
      "step": 1481,
      "loss": 0.04525955766439438,
      "accuracy": 0.9375,
      "grad_norm": 1.707109808921814
    },
    {
      "step": 1482,
      "loss": 0.010174601338803768,
      "accuracy": 1.0,
      "grad_norm": 0.48560333251953125
    },
    {
      "step": 1483,
      "loss": 0.001838507829234004,
      "accuracy": 1.0,
      "grad_norm": 0.0709848552942276
    },
    {
      "step": 1484,
      "loss": 0.014643248170614243,
      "accuracy": 1.0,
      "grad_norm": 0.17928889393806458
    },
    {
      "step": 1485,
      "loss": 0.010817553848028183,
      "accuracy": 1.0,
      "grad_norm": 0.2718144953250885
    },
    {
      "step": 1486,
      "loss": 0.01573357544839382,
      "accuracy": 0.9375,
      "grad_norm": 0.7683652639389038
    },
    {
      "step": 1487,
      "loss": 0.013121494092047215,
      "accuracy": 1.0,
      "grad_norm": 0.6581905484199524
    },
    {
      "step": 1488,
      "loss": 0.008858800865709782,
      "accuracy": 1.0,
      "grad_norm": 0.37569063901901245
    },
    {
      "step": 1489,
      "loss": 0.004980558529496193,
      "accuracy": 1.0,
      "grad_norm": 0.1632542908191681
    },
    {
      "step": 1490,
      "loss": 0.016368214040994644,
      "accuracy": 1.0,
      "grad_norm": 0.13115796446800232
    },
    {
      "step": 1491,
      "loss": 0.032917123287916183,
      "accuracy": 0.9375,
      "grad_norm": 0.8650380969047546
    },
    {
      "step": 1492,
      "loss": 0.0032943785190582275,
      "accuracy": 1.0,
      "grad_norm": 0.27418747544288635
    },
    {
      "step": 1493,
      "loss": 0.16867607831954956,
      "accuracy": 0.8125,
      "grad_norm": 1.8635565042495728
    },
    {
      "step": 1494,
      "loss": 0.16498352587223053,
      "accuracy": 0.75,
      "grad_norm": 1.5379081964492798
    },
    {
      "step": 1495,
      "loss": 0.03134007751941681,
      "accuracy": 0.9375,
      "grad_norm": 0.7514330744743347
    },
    {
      "step": 1496,
      "loss": 0.10879850387573242,
      "accuracy": 0.8125,
      "grad_norm": 4.291873931884766
    },
    {
      "step": 1497,
      "loss": 0.08412030339241028,
      "accuracy": 0.8125,
      "grad_norm": 3.307448387145996
    },
    {
      "step": 1498,
      "loss": 0.023444291204214096,
      "accuracy": 0.9375,
      "grad_norm": 0.8962125778198242
    },
    {
      "step": 1499,
      "loss": 0.05021859332919121,
      "accuracy": 0.9375,
      "grad_norm": 1.049178957939148
    },
    {
      "step": 1500,
      "loss": 0.022594014182686806,
      "accuracy": 0.9375,
      "grad_norm": 0.6876752972602844
    },
    {
      "step": 1501,
      "loss": 0.006302758120000362,
      "accuracy": 1.0,
      "grad_norm": 0.3039228022098541
    },
    {
      "step": 1502,
      "loss": 0.006024247966706753,
      "accuracy": 1.0,
      "grad_norm": 0.09561435133218765
    },
    {
      "step": 1503,
      "loss": 0.001473095384426415,
      "accuracy": 1.0,
      "grad_norm": 0.03392606973648071
    },
    {
      "step": 1504,
      "loss": 0.03400341793894768,
      "accuracy": 0.9375,
      "grad_norm": 0.7022849917411804
    },
    {
      "step": 1505,
      "loss": 0.012589411810040474,
      "accuracy": 1.0,
      "grad_norm": 0.12057407945394516
    },
    {
      "step": 1506,
      "loss": 0.07502289116382599,
      "accuracy": 0.875,
      "grad_norm": 1.0410239696502686
    },
    {
      "step": 1507,
      "loss": 0.002732793800532818,
      "accuracy": 1.0,
      "grad_norm": 0.044731639325618744
    },
    {
      "step": 1508,
      "loss": 0.03316734731197357,
      "accuracy": 0.9375,
      "grad_norm": 0.8073031306266785
    },
    {
      "step": 1509,
      "loss": 0.01853232830762863,
      "accuracy": 1.0,
      "grad_norm": 0.6140488982200623
    },
    {
      "step": 1510,
      "loss": 0.10088589042425156,
      "accuracy": 0.8125,
      "grad_norm": 1.5274337530136108
    },
    {
      "step": 1511,
      "loss": 0.017949769273400307,
      "accuracy": 1.0,
      "grad_norm": 0.19084545969963074
    },
    {
      "step": 1512,
      "loss": 0.04741692915558815,
      "accuracy": 0.9375,
      "grad_norm": 1.6665067672729492
    },
    {
      "step": 1513,
      "loss": 0.05578964576125145,
      "accuracy": 0.875,
      "grad_norm": 0.9591763019561768
    },
    {
      "step": 1514,
      "loss": 0.01158738974481821,
      "accuracy": 1.0,
      "grad_norm": 0.407151460647583
    },
    {
      "step": 1515,
      "loss": 0.029080508276820183,
      "accuracy": 0.9375,
      "grad_norm": 0.8063094019889832
    },
    {
      "step": 1516,
      "loss": 0.01668008416891098,
      "accuracy": 1.0,
      "grad_norm": 0.7419413924217224
    },
    {
      "step": 1517,
      "loss": 0.0096126738935709,
      "accuracy": 1.0,
      "grad_norm": 0.11652444303035736
    },
    {
      "step": 1518,
      "loss": 0.07939841598272324,
      "accuracy": 0.9375,
      "grad_norm": 0.41511404514312744
    },
    {
      "step": 1519,
      "loss": 0.002537638647481799,
      "accuracy": 1.0,
      "grad_norm": 0.06208138167858124
    },
    {
      "step": 1520,
      "loss": 0.08538665622472763,
      "accuracy": 0.9375,
      "grad_norm": 0.6800000667572021
    },
    {
      "step": 1521,
      "loss": 0.006649771239608526,
      "accuracy": 1.0,
      "grad_norm": 0.20809495449066162
    },
    {
      "step": 1522,
      "loss": 0.09862986207008362,
      "accuracy": 0.875,
      "grad_norm": 1.68593430519104
    },
    {
      "step": 1523,
      "loss": 0.0021455700043588877,
      "accuracy": 1.0,
      "grad_norm": 0.04954748973250389
    },
    {
      "step": 1524,
      "loss": 0.0037603694945573807,
      "accuracy": 1.0,
      "grad_norm": 0.12572698295116425
    },
    {
      "step": 1525,
      "loss": 0.04427885264158249,
      "accuracy": 0.9375,
      "grad_norm": 0.9163612127304077
    },
    {
      "step": 1526,
      "loss": 0.06098438426852226,
      "accuracy": 0.9375,
      "grad_norm": 0.3651336133480072
    },
    {
      "step": 1527,
      "loss": 0.01936475560069084,
      "accuracy": 0.9375,
      "grad_norm": 0.5010203123092651
    },
    {
      "step": 1528,
      "loss": 0.012506794184446335,
      "accuracy": 1.0,
      "grad_norm": 0.40587323904037476
    },
    {
      "step": 1529,
      "loss": 0.00501808850094676,
      "accuracy": 1.0,
      "grad_norm": 0.1726193130016327
    },
    {
      "step": 1530,
      "loss": 0.014384069480001926,
      "accuracy": 1.0,
      "grad_norm": 0.6184247136116028
    },
    {
      "step": 1531,
      "loss": 0.013418755494058132,
      "accuracy": 1.0,
      "grad_norm": 0.2861368954181671
    },
    {
      "step": 1532,
      "loss": 0.018384240567684174,
      "accuracy": 1.0,
      "grad_norm": 0.36160171031951904
    },
    {
      "step": 1533,
      "loss": 0.06740640103816986,
      "accuracy": 0.9375,
      "grad_norm": 1.145957350730896
    },
    {
      "step": 1534,
      "loss": 0.08771207928657532,
      "accuracy": 0.875,
      "grad_norm": 2.7841715812683105
    },
    {
      "step": 1535,
      "loss": 0.023649191483855247,
      "accuracy": 0.9375,
      "grad_norm": 0.8987310528755188
    },
    {
      "step": 1536,
      "loss": 0.003913617692887783,
      "accuracy": 1.0,
      "grad_norm": 0.09598427265882492
    },
    {
      "step": 1537,
      "loss": 0.020024139434099197,
      "accuracy": 0.9375,
      "grad_norm": 1.1034396886825562
    },
    {
      "step": 1538,
      "loss": 0.01820382848381996,
      "accuracy": 0.9375,
      "grad_norm": 0.4778207838535309
    },
    {
      "step": 1539,
      "loss": 0.10268930345773697,
      "accuracy": 0.875,
      "grad_norm": 0.8286048173904419
    },
    {
      "step": 1540,
      "loss": 0.010123483836650848,
      "accuracy": 1.0,
      "grad_norm": 0.2722710371017456
    },
    {
      "step": 1541,
      "loss": 0.013976579532027245,
      "accuracy": 1.0,
      "grad_norm": 0.48540616035461426
    },
    {
      "step": 1542,
      "loss": 0.019656529650092125,
      "accuracy": 1.0,
      "grad_norm": 0.32929372787475586
    },
    {
      "step": 1543,
      "loss": 0.01428233366459608,
      "accuracy": 1.0,
      "grad_norm": 0.5312370657920837
    },
    {
      "step": 1544,
      "loss": 0.010171128436923027,
      "accuracy": 1.0,
      "grad_norm": 0.2832236588001251
    },
    {
      "step": 1545,
      "loss": 0.010471364483237267,
      "accuracy": 1.0,
      "grad_norm": 0.9297665953636169
    },
    {
      "step": 1546,
      "loss": 0.007734786253422499,
      "accuracy": 1.0,
      "grad_norm": 0.27898114919662476
    },
    {
      "step": 1547,
      "loss": 0.007373895961791277,
      "accuracy": 1.0,
      "grad_norm": 0.19787117838859558
    },
    {
      "step": 1548,
      "loss": 0.006030681077390909,
      "accuracy": 1.0,
      "grad_norm": 0.27253004908561707
    },
    {
      "step": 1549,
      "loss": 0.011850858107209206,
      "accuracy": 1.0,
      "grad_norm": 0.4124237596988678
    },
    {
      "step": 1550,
      "loss": 0.013347015716135502,
      "accuracy": 1.0,
      "grad_norm": 0.6361464858055115
    },
    {
      "step": 1551,
      "loss": 0.007035557646304369,
      "accuracy": 1.0,
      "grad_norm": 0.3471754491329193
    },
    {
      "step": 1552,
      "loss": 0.07931672781705856,
      "accuracy": 0.875,
      "grad_norm": 1.0146375894546509
    },
    {
      "step": 1553,
      "loss": 0.004702594131231308,
      "accuracy": 1.0,
      "grad_norm": 0.17477059364318848
    },
    {
      "step": 1554,
      "loss": 0.0024790470488369465,
      "accuracy": 1.0,
      "grad_norm": 0.13512839376926422
    },
    {
      "step": 1555,
      "loss": 0.005314880982041359,
      "accuracy": 1.0,
      "grad_norm": 0.2091958224773407
    },
    {
      "step": 1556,
      "loss": 0.002993654925376177,
      "accuracy": 1.0,
      "grad_norm": 0.1704549938440323
    },
    {
      "step": 1557,
      "loss": 0.026167692616581917,
      "accuracy": 0.9375,
      "grad_norm": 1.073716640472412
    },
    {
      "step": 1558,
      "loss": 0.0017785552190616727,
      "accuracy": 1.0,
      "grad_norm": 0.033333901315927505
    },
    {
      "step": 1559,
      "loss": 0.007925041019916534,
      "accuracy": 1.0,
      "grad_norm": 0.5410903096199036
    },
    {
      "step": 1560,
      "loss": 0.0015279403887689114,
      "accuracy": 1.0,
      "grad_norm": 0.06123729795217514
    },
    {
      "step": 1561,
      "loss": 0.02903139591217041,
      "accuracy": 0.9375,
      "grad_norm": 0.7124976515769958
    },
    {
      "step": 1562,
      "loss": 0.10537412762641907,
      "accuracy": 0.8125,
      "grad_norm": 2.390500783920288
    },
    {
      "step": 1563,
      "loss": 0.0013658718671649694,
      "accuracy": 1.0,
      "grad_norm": 0.058534663170576096
    },
    {
      "step": 1564,
      "loss": 0.004913625307381153,
      "accuracy": 1.0,
      "grad_norm": 0.47028040885925293
    },
    {
      "step": 1565,
      "loss": 0.08281750977039337,
      "accuracy": 0.875,
      "grad_norm": 2.4311718940734863
    },
    {
      "step": 1566,
      "loss": 0.00046610116260126233,
      "accuracy": 1.0,
      "grad_norm": 0.00666319252923131
    },
    {
      "step": 1567,
      "loss": 0.07011570781469345,
      "accuracy": 0.9375,
      "grad_norm": 0.5523592829704285
    },
    {
      "step": 1568,
      "loss": 0.05441827327013016,
      "accuracy": 0.9375,
      "grad_norm": 1.9829928874969482
    },
    {
      "step": 1569,
      "loss": 0.03959907591342926,
      "accuracy": 0.9375,
      "grad_norm": 1.5958962440490723
    },
    {
      "step": 1570,
      "loss": 0.02629685401916504,
      "accuracy": 0.9375,
      "grad_norm": 1.811203956604004
    },
    {
      "step": 1571,
      "loss": 0.00967742595821619,
      "accuracy": 1.0,
      "grad_norm": 1.0769081115722656
    },
    {
      "step": 1572,
      "loss": 0.004865733440965414,
      "accuracy": 1.0,
      "grad_norm": 0.27239227294921875
    },
    {
      "step": 1573,
      "loss": 0.055114682763814926,
      "accuracy": 0.875,
      "grad_norm": 2.4314701557159424
    },
    {
      "step": 1574,
      "loss": 0.12800543010234833,
      "accuracy": 0.875,
      "grad_norm": 3.6506166458129883
    },
    {
      "step": 1575,
      "loss": 0.03319864720106125,
      "accuracy": 0.9375,
      "grad_norm": 2.656120777130127
    },
    {
      "step": 1576,
      "loss": 0.005072933156043291,
      "accuracy": 1.0,
      "grad_norm": 0.540649950504303
    },
    {
      "step": 1577,
      "loss": 0.005949494894593954,
      "accuracy": 1.0,
      "grad_norm": 0.3225483298301697
    },
    {
      "step": 1578,
      "loss": 0.015235967934131622,
      "accuracy": 1.0,
      "grad_norm": 0.687425971031189
    },
    {
      "step": 1579,
      "loss": 0.007806387729942799,
      "accuracy": 1.0,
      "grad_norm": 0.6220014691352844
    },
    {
      "step": 1580,
      "loss": 0.002676270669326186,
      "accuracy": 1.0,
      "grad_norm": 0.10803921520709991
    },
    {
      "step": 1581,
      "loss": 0.03982623666524887,
      "accuracy": 0.9375,
      "grad_norm": 0.7062700390815735
    },
    {
      "step": 1582,
      "loss": 0.007578014861792326,
      "accuracy": 1.0,
      "grad_norm": 0.35055676102638245
    },
    {
      "step": 1583,
      "loss": 0.05224963277578354,
      "accuracy": 0.9375,
      "grad_norm": 0.3953379988670349
    },
    {
      "step": 1584,
      "loss": 0.005478230305016041,
      "accuracy": 1.0,
      "grad_norm": 0.13752871751785278
    },
    {
      "step": 1585,
      "loss": 0.028219956904649734,
      "accuracy": 0.9375,
      "grad_norm": 1.1376286745071411
    },
    {
      "step": 1586,
      "loss": 0.014592509716749191,
      "accuracy": 1.0,
      "grad_norm": 0.8486138582229614
    },
    {
      "step": 1587,
      "loss": 0.014888797886669636,
      "accuracy": 1.0,
      "grad_norm": 0.5579863786697388
    },
    {
      "step": 1588,
      "loss": 0.09929319471120834,
      "accuracy": 0.9375,
      "grad_norm": 0.9675561189651489
    },
    {
      "step": 1589,
      "loss": 0.05108661949634552,
      "accuracy": 0.9375,
      "grad_norm": 1.00974702835083
    },
    {
      "step": 1590,
      "loss": 0.013952038250863552,
      "accuracy": 1.0,
      "grad_norm": 0.3890208601951599
    },
    {
      "step": 1591,
      "loss": 0.0184473916888237,
      "accuracy": 1.0,
      "grad_norm": 0.18884968757629395
    },
    {
      "step": 1592,
      "loss": 0.0061932699754834175,
      "accuracy": 1.0,
      "grad_norm": 0.2713398039340973
    },
    {
      "step": 1593,
      "loss": 0.030342664569616318,
      "accuracy": 0.9375,
      "grad_norm": 1.0007574558258057
    },
    {
      "step": 1594,
      "loss": 0.01226782612502575,
      "accuracy": 1.0,
      "grad_norm": 0.5750361084938049
    },
    {
      "step": 1595,
      "loss": 0.012412123382091522,
      "accuracy": 1.0,
      "grad_norm": 0.33810243010520935
    },
    {
      "step": 1596,
      "loss": 0.008139008656144142,
      "accuracy": 1.0,
      "grad_norm": 0.45975300669670105
    },
    {
      "step": 1597,
      "loss": 0.0029360821936279535,
      "accuracy": 1.0,
      "grad_norm": 0.06054985150694847
    },
    {
      "step": 1598,
      "loss": 0.024278543889522552,
      "accuracy": 0.9375,
      "grad_norm": 0.5285423398017883
    },
    {
      "step": 1599,
      "loss": 0.0517948679625988,
      "accuracy": 0.875,
      "grad_norm": 0.874802827835083
    },
    {
      "step": 1600,
      "loss": 0.06943855434656143,
      "accuracy": 0.9375,
      "grad_norm": 0.47340747714042664
    },
    {
      "step": 1601,
      "loss": 0.09785023331642151,
      "accuracy": 0.875,
      "grad_norm": 1.9873875379562378
    },
    {
      "step": 1602,
      "loss": 0.017916731536388397,
      "accuracy": 1.0,
      "grad_norm": 0.3571889400482178
    },
    {
      "step": 1603,
      "loss": 0.05073221027851105,
      "accuracy": 0.875,
      "grad_norm": 2.189321517944336
    },
    {
      "step": 1604,
      "loss": 0.02436850219964981,
      "accuracy": 0.9375,
      "grad_norm": 0.47230157256126404
    },
    {
      "step": 1605,
      "loss": 0.012291647493839264,
      "accuracy": 1.0,
      "grad_norm": 0.627887487411499
    },
    {
      "step": 1606,
      "loss": 0.01573447324335575,
      "accuracy": 1.0,
      "grad_norm": 0.6498206257820129
    },
    {
      "step": 1607,
      "loss": 0.03914767503738403,
      "accuracy": 0.9375,
      "grad_norm": 0.7078340649604797
    },
    {
      "step": 1608,
      "loss": 0.004411672241985798,
      "accuracy": 1.0,
      "grad_norm": 0.18688003718852997
    },
    {
      "step": 1609,
      "loss": 0.06124509498476982,
      "accuracy": 0.9375,
      "grad_norm": 0.6309860944747925
    },
    {
      "step": 1610,
      "loss": 0.05012235417962074,
      "accuracy": 0.875,
      "grad_norm": 1.3879237174987793
    },
    {
      "step": 1611,
      "loss": 0.0022672214545309544,
      "accuracy": 1.0,
      "grad_norm": 0.05383124575018883
    },
    {
      "step": 1612,
      "loss": 0.04046110063791275,
      "accuracy": 0.875,
      "grad_norm": 1.2137091159820557
    },
    {
      "step": 1613,
      "loss": 0.040780890733003616,
      "accuracy": 0.875,
      "grad_norm": 0.7531253099441528
    },
    {
      "step": 1614,
      "loss": 0.011078103445470333,
      "accuracy": 1.0,
      "grad_norm": 0.3908803462982178
    },
    {
      "step": 1615,
      "loss": 0.04697683826088905,
      "accuracy": 0.9375,
      "grad_norm": 2.03753399848938
    },
    {
      "step": 1616,
      "loss": 0.051551416516304016,
      "accuracy": 0.9375,
      "grad_norm": 1.2848728895187378
    },
    {
      "step": 1617,
      "loss": 0.014839937910437584,
      "accuracy": 1.0,
      "grad_norm": 0.4493553340435028
    },
    {
      "step": 1618,
      "loss": 0.018579721450805664,
      "accuracy": 1.0,
      "grad_norm": 0.8430556654930115
    },
    {
      "step": 1619,
      "loss": 0.0028410563245415688,
      "accuracy": 1.0,
      "grad_norm": 0.07657649368047714
    },
    {
      "step": 1620,
      "loss": 0.01842268370091915,
      "accuracy": 1.0,
      "grad_norm": 0.22039546072483063
    },
    {
      "step": 1621,
      "loss": 0.018627412617206573,
      "accuracy": 1.0,
      "grad_norm": 0.7533289790153503
    },
    {
      "step": 1622,
      "loss": 0.021168213337659836,
      "accuracy": 0.9375,
      "grad_norm": 0.7347514629364014
    },
    {
      "step": 1623,
      "loss": 0.022080345079302788,
      "accuracy": 0.9375,
      "grad_norm": 0.870864748954773
    },
    {
      "step": 1624,
      "loss": 0.014314815402030945,
      "accuracy": 1.0,
      "grad_norm": 0.46617406606674194
    },
    {
      "step": 1625,
      "loss": 0.024404190480709076,
      "accuracy": 0.9375,
      "grad_norm": 1.0556329488754272
    },
    {
      "step": 1626,
      "loss": 0.06834038347005844,
      "accuracy": 0.9375,
      "grad_norm": 0.4510151743888855
    },
    {
      "step": 1627,
      "loss": 0.04825366288423538,
      "accuracy": 0.9375,
      "grad_norm": 1.7105399370193481
    },
    {
      "step": 1628,
      "loss": 0.011823077686131,
      "accuracy": 1.0,
      "grad_norm": 0.9045006036758423
    },
    {
      "step": 1629,
      "loss": 0.002856051316484809,
      "accuracy": 1.0,
      "grad_norm": 0.09725446254014969
    },
    {
      "step": 1630,
      "loss": 0.002194094704464078,
      "accuracy": 1.0,
      "grad_norm": 0.050831034779548645
    },
    {
      "step": 1631,
      "loss": 0.019541427493095398,
      "accuracy": 0.9375,
      "grad_norm": 0.8501823544502258
    },
    {
      "step": 1632,
      "loss": 0.04833144694566727,
      "accuracy": 0.9375,
      "grad_norm": 1.7570704221725464
    },
    {
      "step": 1633,
      "loss": 0.0015167725505307317,
      "accuracy": 1.0,
      "grad_norm": 0.032251883298158646
    },
    {
      "step": 1634,
      "loss": 0.043783657252788544,
      "accuracy": 0.9375,
      "grad_norm": 0.4440297484397888
    },
    {
      "step": 1635,
      "loss": 0.05230531468987465,
      "accuracy": 0.9375,
      "grad_norm": 2.1370887756347656
    },
    {
      "step": 1636,
      "loss": 0.05997345969080925,
      "accuracy": 0.9375,
      "grad_norm": 2.1270394325256348
    },
    {
      "step": 1637,
      "loss": 0.111993707716465,
      "accuracy": 0.8125,
      "grad_norm": 3.6638505458831787
    },
    {
      "step": 1638,
      "loss": 0.06523145735263824,
      "accuracy": 0.875,
      "grad_norm": 0.9713294506072998
    },
    {
      "step": 1639,
      "loss": 0.0030552796088159084,
      "accuracy": 1.0,
      "grad_norm": 0.09965116530656815
    },
    {
      "step": 1640,
      "loss": 0.0060724071227014065,
      "accuracy": 1.0,
      "grad_norm": 0.35647428035736084
    },
    {
      "step": 1641,
      "loss": 0.004495438653975725,
      "accuracy": 1.0,
      "grad_norm": 0.17605017125606537
    },
    {
      "step": 1642,
      "loss": 0.015565155074000359,
      "accuracy": 0.9375,
      "grad_norm": 0.7472873330116272
    },
    {
      "step": 1643,
      "loss": 0.07347700744867325,
      "accuracy": 0.9375,
      "grad_norm": 3.364332675933838
    },
    {
      "step": 1644,
      "loss": 0.0036949114874005318,
      "accuracy": 1.0,
      "grad_norm": 0.1159270778298378
    },
    {
      "step": 1645,
      "loss": 0.004308369476348162,
      "accuracy": 1.0,
      "grad_norm": 0.17101192474365234
    },
    {
      "step": 1646,
      "loss": 0.08389023691415787,
      "accuracy": 0.875,
      "grad_norm": 2.6737327575683594
    },
    {
      "step": 1647,
      "loss": 0.04057982563972473,
      "accuracy": 0.9375,
      "grad_norm": 1.2973664999008179
    },
    {
      "step": 1648,
      "loss": 0.08021429181098938,
      "accuracy": 0.875,
      "grad_norm": 1.3526220321655273
    },
    {
      "step": 1649,
      "loss": 0.08121846616268158,
      "accuracy": 0.875,
      "grad_norm": 1.858270525932312
    },
    {
      "step": 1650,
      "loss": 0.0071137757040560246,
      "accuracy": 1.0,
      "grad_norm": 0.1911797821521759
    },
    {
      "step": 1651,
      "loss": 0.011226440779864788,
      "accuracy": 1.0,
      "grad_norm": 0.4606032371520996
    },
    {
      "step": 1652,
      "loss": 0.012237097136676311,
      "accuracy": 1.0,
      "grad_norm": 0.6029931306838989
    },
    {
      "step": 1653,
      "loss": 0.043508730828762054,
      "accuracy": 0.9375,
      "grad_norm": 1.2176263332366943
    },
    {
      "step": 1654,
      "loss": 0.03542521595954895,
      "accuracy": 0.9375,
      "grad_norm": 1.2771239280700684
    },
    {
      "step": 1655,
      "loss": 0.08241552859544754,
      "accuracy": 0.875,
      "grad_norm": 2.940307140350342
    },
    {
      "step": 1656,
      "loss": 0.059626657515764236,
      "accuracy": 0.9375,
      "grad_norm": 1.2415380477905273
    },
    {
      "step": 1657,
      "loss": 0.00534600717946887,
      "accuracy": 1.0,
      "grad_norm": 0.11663047969341278
    },
    {
      "step": 1658,
      "loss": 0.007888124324381351,
      "accuracy": 1.0,
      "grad_norm": 0.24532493948936462
    },
    {
      "step": 1659,
      "loss": 0.04089904576539993,
      "accuracy": 0.9375,
      "grad_norm": 1.0620681047439575
    },
    {
      "step": 1660,
      "loss": 0.014371722005307674,
      "accuracy": 1.0,
      "grad_norm": 0.4491729736328125
    },
    {
      "step": 1661,
      "loss": 0.027782272547483444,
      "accuracy": 0.9375,
      "grad_norm": 0.9224496483802795
    },
    {
      "step": 1662,
      "loss": 0.0017740969778969884,
      "accuracy": 1.0,
      "grad_norm": 0.0296060498803854
    },
    {
      "step": 1663,
      "loss": 0.14540135860443115,
      "accuracy": 0.8125,
      "grad_norm": 1.9380210638046265
    },
    {
      "step": 1664,
      "loss": 0.05691034719347954,
      "accuracy": 0.9375,
      "grad_norm": 0.993445634841919
    },
    {
      "step": 1665,
      "loss": 0.015530196018517017,
      "accuracy": 1.0,
      "grad_norm": 0.34069663286209106
    },
    {
      "step": 1666,
      "loss": 0.02290700376033783,
      "accuracy": 1.0,
      "grad_norm": 0.3955283463001251
    },
    {
      "step": 1667,
      "loss": 0.014309060759842396,
      "accuracy": 1.0,
      "grad_norm": 0.5879088044166565
    },
    {
      "step": 1668,
      "loss": 0.059123262763023376,
      "accuracy": 0.8125,
      "grad_norm": 2.288771629333496
    },
    {
      "step": 1669,
      "loss": 0.05043794587254524,
      "accuracy": 0.875,
      "grad_norm": 1.6869473457336426
    },
    {
      "step": 1670,
      "loss": 0.04211931675672531,
      "accuracy": 0.875,
      "grad_norm": 0.9224786162376404
    },
    {
      "step": 1671,
      "loss": 0.05673139914870262,
      "accuracy": 0.875,
      "grad_norm": 1.691063404083252
    },
    {
      "step": 1672,
      "loss": 0.021262574940919876,
      "accuracy": 1.0,
      "grad_norm": 1.1922149658203125
    },
    {
      "step": 1673,
      "loss": 0.04140576720237732,
      "accuracy": 0.9375,
      "grad_norm": 0.45456621050834656
    },
    {
      "step": 1674,
      "loss": 0.0010623862035572529,
      "accuracy": 1.0,
      "grad_norm": 0.024850821122527122
    },
    {
      "step": 1675,
      "loss": 0.02487659454345703,
      "accuracy": 0.9375,
      "grad_norm": 1.0006338357925415
    },
    {
      "step": 1676,
      "loss": 0.0032045694533735514,
      "accuracy": 1.0,
      "grad_norm": 0.10546373575925827
    },
    {
      "step": 1677,
      "loss": 0.002436380134895444,
      "accuracy": 1.0,
      "grad_norm": 0.15166005492210388
    },
    {
      "step": 1678,
      "loss": 0.041519515216350555,
      "accuracy": 0.875,
      "grad_norm": 1.2064628601074219
    },
    {
      "step": 1679,
      "loss": 0.003235776210203767,
      "accuracy": 1.0,
      "grad_norm": 0.18202708661556244
    },
    {
      "step": 1680,
      "loss": 0.1005539819598198,
      "accuracy": 0.875,
      "grad_norm": 1.1157690286636353
    },
    {
      "step": 1681,
      "loss": 0.004407993983477354,
      "accuracy": 1.0,
      "grad_norm": 0.11747782677412033
    },
    {
      "step": 1682,
      "loss": 0.033642131835222244,
      "accuracy": 0.9375,
      "grad_norm": 1.132079839706421
    },
    {
      "step": 1683,
      "loss": 0.013693797402083874,
      "accuracy": 1.0,
      "grad_norm": 0.3607279658317566
    },
    {
      "step": 1684,
      "loss": 0.0019642780534923077,
      "accuracy": 1.0,
      "grad_norm": 0.051317356526851654
    },
    {
      "step": 1685,
      "loss": 0.00872223824262619,
      "accuracy": 1.0,
      "grad_norm": 0.19457757472991943
    },
    {
      "step": 1686,
      "loss": 0.002484759083017707,
      "accuracy": 1.0,
      "grad_norm": 0.04700818657875061
    },
    {
      "step": 1687,
      "loss": 0.018330322578549385,
      "accuracy": 0.9375,
      "grad_norm": 0.35167571902275085
    },
    {
      "step": 1688,
      "loss": 0.04629966616630554,
      "accuracy": 0.9375,
      "grad_norm": 1.0402313470840454
    },
    {
      "step": 1689,
      "loss": 0.07117332518100739,
      "accuracy": 0.9375,
      "grad_norm": 1.9080930948257446
    },
    {
      "step": 1690,
      "loss": 0.04063190892338753,
      "accuracy": 0.9375,
      "grad_norm": 0.9720690846443176
    },
    {
      "step": 1691,
      "loss": 0.06541112065315247,
      "accuracy": 0.875,
      "grad_norm": 0.9593457579612732
    },
    {
      "step": 1692,
      "loss": 0.010822724550962448,
      "accuracy": 1.0,
      "grad_norm": 0.5379394888877869
    },
    {
      "step": 1693,
      "loss": 0.03184720501303673,
      "accuracy": 0.9375,
      "grad_norm": 0.8354731202125549
    },
    {
      "step": 1694,
      "loss": 0.01090253610163927,
      "accuracy": 1.0,
      "grad_norm": 0.15915626287460327
    },
    {
      "step": 1695,
      "loss": 0.005653996951878071,
      "accuracy": 1.0,
      "grad_norm": 0.09629727154970169
    },
    {
      "step": 1696,
      "loss": 0.013054851442575455,
      "accuracy": 1.0,
      "grad_norm": 0.37650033831596375
    },
    {
      "step": 1697,
      "loss": 0.056090347468853,
      "accuracy": 0.9375,
      "grad_norm": 0.7726138830184937
    },
    {
      "step": 1698,
      "loss": 0.008899160660803318,
      "accuracy": 1.0,
      "grad_norm": 0.3522946238517761
    },
    {
      "step": 1699,
      "loss": 0.07479766756296158,
      "accuracy": 0.875,
      "grad_norm": 1.7135659456253052
    },
    {
      "step": 1700,
      "loss": 0.008515017107129097,
      "accuracy": 1.0,
      "grad_norm": 0.3765897750854492
    },
    {
      "step": 1701,
      "loss": 0.016270725056529045,
      "accuracy": 1.0,
      "grad_norm": 0.6251869201660156
    },
    {
      "step": 1702,
      "loss": 0.0047127618454396725,
      "accuracy": 1.0,
      "grad_norm": 0.2103157937526703
    },
    {
      "step": 1703,
      "loss": 0.0021836813539266586,
      "accuracy": 1.0,
      "grad_norm": 0.05343199148774147
    },
    {
      "step": 1704,
      "loss": 0.06596074253320694,
      "accuracy": 0.9375,
      "grad_norm": 0.6501519680023193
    },
    {
      "step": 1705,
      "loss": 0.003883778816089034,
      "accuracy": 1.0,
      "grad_norm": 0.09701509773731232
    },
    {
      "step": 1706,
      "loss": 0.052533458918333054,
      "accuracy": 0.875,
      "grad_norm": 1.7796415090560913
    },
    {
      "step": 1707,
      "loss": 0.03153172507882118,
      "accuracy": 0.9375,
      "grad_norm": 2.0163891315460205
    },
    {
      "step": 1708,
      "loss": 0.028430858626961708,
      "accuracy": 0.9375,
      "grad_norm": 1.3507201671600342
    },
    {
      "step": 1709,
      "loss": 0.014512625522911549,
      "accuracy": 1.0,
      "grad_norm": 0.8147322535514832
    },
    {
      "step": 1710,
      "loss": 0.006436377298086882,
      "accuracy": 1.0,
      "grad_norm": 0.12854637205600739
    },
    {
      "step": 1711,
      "loss": 0.002754954854026437,
      "accuracy": 1.0,
      "grad_norm": 0.09917981177568436
    },
    {
      "step": 1712,
      "loss": 0.031691499054431915,
      "accuracy": 0.9375,
      "grad_norm": 0.5433905124664307
    },
    {
      "step": 1713,
      "loss": 0.002806121250614524,
      "accuracy": 1.0,
      "grad_norm": 0.08969784528017044
    },
    {
      "step": 1714,
      "loss": 0.08574263751506805,
      "accuracy": 0.875,
      "grad_norm": 1.4181309938430786
    },
    {
      "step": 1715,
      "loss": 0.024584610015153885,
      "accuracy": 0.9375,
      "grad_norm": 1.1780803203582764
    },
    {
      "step": 1716,
      "loss": 0.024575773626565933,
      "accuracy": 0.9375,
      "grad_norm": 1.1840941905975342
    },
    {
      "step": 1717,
      "loss": 0.003042125841602683,
      "accuracy": 1.0,
      "grad_norm": 0.12792734801769257
    },
    {
      "step": 1718,
      "loss": 0.0023349840193986893,
      "accuracy": 1.0,
      "grad_norm": 0.0733230784535408
    },
    {
      "step": 1719,
      "loss": 0.005543097387999296,
      "accuracy": 1.0,
      "grad_norm": 0.3758717179298401
    },
    {
      "step": 1720,
      "loss": 0.005488076712936163,
      "accuracy": 1.0,
      "grad_norm": 0.31999751925468445
    },
    {
      "step": 1721,
      "loss": 0.0015448995400220156,
      "accuracy": 1.0,
      "grad_norm": 0.03606262430548668
    },
    {
      "step": 1722,
      "loss": 0.001141892047598958,
      "accuracy": 1.0,
      "grad_norm": 0.031761206686496735
    },
    {
      "step": 1723,
      "loss": 0.002285149646922946,
      "accuracy": 1.0,
      "grad_norm": 0.04543178156018257
    },
    {
      "step": 1724,
      "loss": 0.01554388552904129,
      "accuracy": 1.0,
      "grad_norm": 0.40157046914100647
    },
    {
      "step": 1725,
      "loss": 0.05188750475645065,
      "accuracy": 0.9375,
      "grad_norm": 0.6471145749092102
    },
    {
      "step": 1726,
      "loss": 0.011736857704818249,
      "accuracy": 1.0,
      "grad_norm": 0.6834601759910583
    },
    {
      "step": 1727,
      "loss": 0.0055772834457457066,
      "accuracy": 1.0,
      "grad_norm": 0.42475512623786926
    },
    {
      "step": 1728,
      "loss": 0.02136957086622715,
      "accuracy": 0.9375,
      "grad_norm": 1.688635230064392
    },
    {
      "step": 1729,
      "loss": 0.0034569716081023216,
      "accuracy": 1.0,
      "grad_norm": 0.28399065136909485
    },
    {
      "step": 1730,
      "loss": 0.011989769525825977,
      "accuracy": 1.0,
      "grad_norm": 1.0402796268463135
    },
    {
      "step": 1731,
      "loss": 0.00950649008154869,
      "accuracy": 1.0,
      "grad_norm": 0.8164234161376953
    },
    {
      "step": 1732,
      "loss": 0.07585439085960388,
      "accuracy": 0.875,
      "grad_norm": 1.5785064697265625
    },
    {
      "step": 1733,
      "loss": 0.007020486053079367,
      "accuracy": 1.0,
      "grad_norm": 0.30579498410224915
    },
    {
      "step": 1734,
      "loss": 0.0030108678620308638,
      "accuracy": 1.0,
      "grad_norm": 0.09928271919488907
    },
    {
      "step": 1735,
      "loss": 0.03234182670712471,
      "accuracy": 0.9375,
      "grad_norm": 0.47414863109588623
    },
    {
      "step": 1736,
      "loss": 0.08025505393743515,
      "accuracy": 0.875,
      "grad_norm": 1.7380040884017944
    },
    {
      "step": 1737,
      "loss": 0.05150262266397476,
      "accuracy": 0.9375,
      "grad_norm": 1.62154221534729
    },
    {
      "step": 1738,
      "loss": 0.04270055890083313,
      "accuracy": 0.9375,
      "grad_norm": 0.5403741002082825
    },
    {
      "step": 1739,
      "loss": 0.0037614803295582533,
      "accuracy": 1.0,
      "grad_norm": 0.15712395310401917
    },
    {
      "step": 1740,
      "loss": 0.003027784638106823,
      "accuracy": 1.0,
      "grad_norm": 0.0764203816652298
    },
    {
      "step": 1741,
      "loss": 0.0065644909627735615,
      "accuracy": 1.0,
      "grad_norm": 0.17235016822814941
    },
    {
      "step": 1742,
      "loss": 0.016454918310046196,
      "accuracy": 0.9375,
      "grad_norm": 1.0551625490188599
    },
    {
      "step": 1743,
      "loss": 0.0036855130456387997,
      "accuracy": 1.0,
      "grad_norm": 0.1445937156677246
    },
    {
      "step": 1744,
      "loss": 0.007564664352685213,
      "accuracy": 1.0,
      "grad_norm": 0.2250148355960846
    },
    {
      "step": 1745,
      "loss": 0.02349907159805298,
      "accuracy": 0.9375,
      "grad_norm": 0.6922226548194885
    },
    {
      "step": 1746,
      "loss": 0.0017319181933999062,
      "accuracy": 1.0,
      "grad_norm": 0.05418204143643379
    },
    {
      "step": 1747,
      "loss": 0.027546338737010956,
      "accuracy": 0.9375,
      "grad_norm": 1.7276793718338013
    },
    {
      "step": 1748,
      "loss": 0.08293043076992035,
      "accuracy": 0.9375,
      "grad_norm": 1.5890225172042847
    },
    {
      "step": 1749,
      "loss": 0.0029617941472679377,
      "accuracy": 1.0,
      "grad_norm": 0.11441045254468918
    },
    {
      "step": 1750,
      "loss": 0.0027156283613294363,
      "accuracy": 1.0,
      "grad_norm": 0.08085467666387558
    },
    {
      "step": 1751,
      "loss": 0.08145110309123993,
      "accuracy": 0.875,
      "grad_norm": 1.488671064376831
    },
    {
      "step": 1752,
      "loss": 0.0032474412582814693,
      "accuracy": 1.0,
      "grad_norm": 0.08555496484041214
    },
    {
      "step": 1753,
      "loss": 0.0019439288880676031,
      "accuracy": 1.0,
      "grad_norm": 0.059710875153541565
    },
    {
      "step": 1754,
      "loss": 0.06011711061000824,
      "accuracy": 0.875,
      "grad_norm": 2.94271183013916
    },
    {
      "step": 1755,
      "loss": 0.03388550505042076,
      "accuracy": 0.9375,
      "grad_norm": 1.5549105405807495
    },
    {
      "step": 1756,
      "loss": 0.03907470032572746,
      "accuracy": 0.875,
      "grad_norm": 1.015499234199524
    },
    {
      "step": 1757,
      "loss": 0.04317468777298927,
      "accuracy": 0.9375,
      "grad_norm": 0.8176621794700623
    },
    {
      "step": 1758,
      "loss": 0.03191971406340599,
      "accuracy": 0.9375,
      "grad_norm": 1.5148677825927734
    },
    {
      "step": 1759,
      "loss": 0.03076694905757904,
      "accuracy": 0.9375,
      "grad_norm": 1.322134017944336
    },
    {
      "step": 1760,
      "loss": 0.01676352694630623,
      "accuracy": 1.0,
      "grad_norm": 1.1602959632873535
    },
    {
      "step": 1761,
      "loss": 0.023467089980840683,
      "accuracy": 0.9375,
      "grad_norm": 0.7295600175857544
    },
    {
      "step": 1762,
      "loss": 0.16730472445487976,
      "accuracy": 0.8125,
      "grad_norm": 2.946178913116455
    },
    {
      "step": 1763,
      "loss": 0.006866208277642727,
      "accuracy": 1.0,
      "grad_norm": 0.4243139326572418
    },
    {
      "step": 1764,
      "loss": 0.02006382681429386,
      "accuracy": 1.0,
      "grad_norm": 1.2457530498504639
    },
    {
      "step": 1765,
      "loss": 0.0044413115829229355,
      "accuracy": 1.0,
      "grad_norm": 0.28438785672187805
    },
    {
      "step": 1766,
      "loss": 0.021569417789578438,
      "accuracy": 0.9375,
      "grad_norm": 0.6333553791046143
    },
    {
      "step": 1767,
      "loss": 0.007821219973266125,
      "accuracy": 1.0,
      "grad_norm": 0.4658817648887634
    },
    {
      "step": 1768,
      "loss": 0.10835517197847366,
      "accuracy": 0.875,
      "grad_norm": 4.0088958740234375
    },
    {
      "step": 1769,
      "loss": 0.0037236108910292387,
      "accuracy": 1.0,
      "grad_norm": 0.5391069054603577
    },
    {
      "step": 1770,
      "loss": 0.09129219502210617,
      "accuracy": 0.875,
      "grad_norm": 2.562957525253296
    },
    {
      "step": 1771,
      "loss": 0.11199304461479187,
      "accuracy": 0.875,
      "grad_norm": 3.855999708175659
    },
    {
      "step": 1772,
      "loss": 0.0027431356720626354,
      "accuracy": 1.0,
      "grad_norm": 0.10337378829717636
    },
    {
      "step": 1773,
      "loss": 0.03309272602200508,
      "accuracy": 0.9375,
      "grad_norm": 1.3852710723876953
    },
    {
      "step": 1774,
      "loss": 0.009219517931342125,
      "accuracy": 1.0,
      "grad_norm": 0.37833037972450256
    },
    {
      "step": 1775,
      "loss": 0.004853720776736736,
      "accuracy": 1.0,
      "grad_norm": 0.14832556247711182
    },
    {
      "step": 1776,
      "loss": 0.0030519922729581594,
      "accuracy": 1.0,
      "grad_norm": 0.09531790763139725
    },
    {
      "step": 1777,
      "loss": 0.008901352994143963,
      "accuracy": 1.0,
      "grad_norm": 0.44507884979248047
    },
    {
      "step": 1778,
      "loss": 0.009019299410283566,
      "accuracy": 1.0,
      "grad_norm": 0.26947474479675293
    },
    {
      "step": 1779,
      "loss": 0.025212643668055534,
      "accuracy": 0.9375,
      "grad_norm": 0.8088269233703613
    },
    {
      "step": 1780,
      "loss": 0.07215696573257446,
      "accuracy": 0.9375,
      "grad_norm": 0.6290994882583618
    },
    {
      "step": 1781,
      "loss": 0.02969641610980034,
      "accuracy": 0.9375,
      "grad_norm": 0.9175090789794922
    },
    {
      "step": 1782,
      "loss": 0.0034647230058908463,
      "accuracy": 1.0,
      "grad_norm": 0.23638960719108582
    },
    {
      "step": 1783,
      "loss": 0.012073331512510777,
      "accuracy": 1.0,
      "grad_norm": 0.5077054500579834
    },
    {
      "step": 1784,
      "loss": 0.07080502063035965,
      "accuracy": 0.8125,
      "grad_norm": 1.7909826040267944
    },
    {
      "step": 1785,
      "loss": 0.037992771714925766,
      "accuracy": 0.9375,
      "grad_norm": 1.2734794616699219
    },
    {
      "step": 1786,
      "loss": 0.05194176733493805,
      "accuracy": 0.9375,
      "grad_norm": 0.8237239718437195
    },
    {
      "step": 1787,
      "loss": 0.0346430167555809,
      "accuracy": 0.9375,
      "grad_norm": 1.226269006729126
    },
    {
      "step": 1788,
      "loss": 0.006101920269429684,
      "accuracy": 1.0,
      "grad_norm": 0.14427103102207184
    },
    {
      "step": 1789,
      "loss": 0.03701898455619812,
      "accuracy": 0.9375,
      "grad_norm": 0.7197358012199402
    },
    {
      "step": 1790,
      "loss": 0.03930848091840744,
      "accuracy": 0.9375,
      "grad_norm": 0.8140038847923279
    },
    {
      "step": 1791,
      "loss": 0.004944287706166506,
      "accuracy": 1.0,
      "grad_norm": 0.1798669695854187
    },
    {
      "step": 1792,
      "loss": 0.03461407497525215,
      "accuracy": 0.9375,
      "grad_norm": 1.2160354852676392
    },
    {
      "step": 1793,
      "loss": 0.006825732532888651,
      "accuracy": 1.0,
      "grad_norm": 0.2625018358230591
    },
    {
      "step": 1794,
      "loss": 0.09823877364397049,
      "accuracy": 0.8125,
      "grad_norm": 2.105628728866577
    },
    {
      "step": 1795,
      "loss": 0.021541589871048927,
      "accuracy": 0.9375,
      "grad_norm": 0.5839439630508423
    },
    {
      "step": 1796,
      "loss": 0.006395814009010792,
      "accuracy": 1.0,
      "grad_norm": 0.24448226392269135
    },
    {
      "step": 1797,
      "loss": 0.008738244883716106,
      "accuracy": 1.0,
      "grad_norm": 0.2965759038925171
    },
    {
      "step": 1798,
      "loss": 0.009460893459618092,
      "accuracy": 1.0,
      "grad_norm": 0.2942253053188324
    },
    {
      "step": 1799,
      "loss": 0.013601955026388168,
      "accuracy": 1.0,
      "grad_norm": 0.5918922424316406
    },
    {
      "step": 1800,
      "loss": 0.04746762290596962,
      "accuracy": 0.9375,
      "grad_norm": 0.978684663772583
    },
    {
      "step": 1801,
      "loss": 0.006536733824759722,
      "accuracy": 1.0,
      "grad_norm": 0.12304029613733292
    },
    {
      "step": 1802,
      "loss": 0.0022577305790036917,
      "accuracy": 1.0,
      "grad_norm": 0.08730307221412659
    },
    {
      "step": 1803,
      "loss": 0.008844244293868542,
      "accuracy": 1.0,
      "grad_norm": 0.5997568964958191
    },
    {
      "step": 1804,
      "loss": 0.003334101988002658,
      "accuracy": 1.0,
      "grad_norm": 0.07197493314743042
    },
    {
      "step": 1805,
      "loss": 0.026164667680859566,
      "accuracy": 0.9375,
      "grad_norm": 0.7946974039077759
    },
    {
      "step": 1806,
      "loss": 0.012897009029984474,
      "accuracy": 1.0,
      "grad_norm": 0.8227556347846985
    },
    {
      "step": 1807,
      "loss": 0.009592205286026001,
      "accuracy": 1.0,
      "grad_norm": 0.21177396178245544
    },
    {
      "step": 1808,
      "loss": 0.06980572640895844,
      "accuracy": 0.9375,
      "grad_norm": 0.8238402009010315
    },
    {
      "step": 1809,
      "loss": 0.0014474228955805302,
      "accuracy": 1.0,
      "grad_norm": 0.06439998745918274
    },
    {
      "step": 1810,
      "loss": 0.004732170607894659,
      "accuracy": 1.0,
      "grad_norm": 0.2728152275085449
    },
    {
      "step": 1811,
      "loss": 0.023490197956562042,
      "accuracy": 0.9375,
      "grad_norm": 0.7032713890075684
    },
    {
      "step": 1812,
      "loss": 0.008306527510285378,
      "accuracy": 1.0,
      "grad_norm": 0.23105046153068542
    },
    {
      "step": 1813,
      "loss": 0.03950263187289238,
      "accuracy": 0.875,
      "grad_norm": 0.7481155395507812
    },
    {
      "step": 1814,
      "loss": 0.030194759368896484,
      "accuracy": 0.9375,
      "grad_norm": 1.3185538053512573
    },
    {
      "step": 1815,
      "loss": 0.018496206030249596,
      "accuracy": 1.0,
      "grad_norm": 0.9611412286758423
    },
    {
      "step": 1816,
      "loss": 0.024432256817817688,
      "accuracy": 0.9375,
      "grad_norm": 1.411228895187378
    },
    {
      "step": 1817,
      "loss": 0.009783444926142693,
      "accuracy": 1.0,
      "grad_norm": 0.30573156476020813
    },
    {
      "step": 1818,
      "loss": 0.0025191616732627153,
      "accuracy": 1.0,
      "grad_norm": 0.11142920702695847
    },
    {
      "step": 1819,
      "loss": 0.0007124820840544999,
      "accuracy": 1.0,
      "grad_norm": 0.019362982362508774
    },
    {
      "step": 1820,
      "loss": 0.002882877364754677,
      "accuracy": 1.0,
      "grad_norm": 0.11552325636148453
    },
    {
      "step": 1821,
      "loss": 0.06356501579284668,
      "accuracy": 0.9375,
      "grad_norm": 1.4709421396255493
    },
    {
      "step": 1822,
      "loss": 0.04242752492427826,
      "accuracy": 0.875,
      "grad_norm": 1.3093640804290771
    },
    {
      "step": 1823,
      "loss": 0.003200405277311802,
      "accuracy": 1.0,
      "grad_norm": 0.15308156609535217
    },
    {
      "step": 1824,
      "loss": 0.013598489575088024,
      "accuracy": 0.9375,
      "grad_norm": 0.889827311038971
    },
    {
      "step": 1825,
      "loss": 0.0174745824187994,
      "accuracy": 0.9375,
      "grad_norm": 0.8672096729278564
    },
    {
      "step": 1826,
      "loss": 0.038958411663770676,
      "accuracy": 0.9375,
      "grad_norm": 0.5066596269607544
    },
    {
      "step": 1827,
      "loss": 0.006256119813770056,
      "accuracy": 1.0,
      "grad_norm": 0.47384706139564514
    },
    {
      "step": 1828,
      "loss": 0.08025501668453217,
      "accuracy": 0.875,
      "grad_norm": 3.095081329345703
    },
    {
      "step": 1829,
      "loss": 0.019445709884166718,
      "accuracy": 1.0,
      "grad_norm": 1.792872428894043
    },
    {
      "step": 1830,
      "loss": 0.012853016145527363,
      "accuracy": 1.0,
      "grad_norm": 0.9686895608901978
    },
    {
      "step": 1831,
      "loss": 0.0026961255352944136,
      "accuracy": 1.0,
      "grad_norm": 0.204766184091568
    },
    {
      "step": 1832,
      "loss": 0.0274201612919569,
      "accuracy": 0.9375,
      "grad_norm": 1.8390483856201172
    },
    {
      "step": 1833,
      "loss": 0.0019386601634323597,
      "accuracy": 1.0,
      "grad_norm": 0.07332660257816315
    },
    {
      "step": 1834,
      "loss": 0.012104686349630356,
      "accuracy": 1.0,
      "grad_norm": 0.5530170798301697
    },
    {
      "step": 1835,
      "loss": 0.001381321344524622,
      "accuracy": 1.0,
      "grad_norm": 0.08740130066871643
    },
    {
      "step": 1836,
      "loss": 0.008002616465091705,
      "accuracy": 1.0,
      "grad_norm": 0.6933392882347107
    },
    {
      "step": 1837,
      "loss": 0.09919267892837524,
      "accuracy": 0.9375,
      "grad_norm": 3.316676378250122
    },
    {
      "step": 1838,
      "loss": 0.06944163143634796,
      "accuracy": 0.875,
      "grad_norm": 3.441955089569092
    },
    {
      "step": 1839,
      "loss": 0.010250886902213097,
      "accuracy": 1.0,
      "grad_norm": 1.7220033407211304
    },
    {
      "step": 1840,
      "loss": 0.010563967749476433,
      "accuracy": 1.0,
      "grad_norm": 0.8213655948638916
    },
    {
      "step": 1841,
      "loss": 0.001222088118083775,
      "accuracy": 1.0,
      "grad_norm": 0.05540229752659798
    },
    {
      "step": 1842,
      "loss": 0.00853150524199009,
      "accuracy": 1.0,
      "grad_norm": 0.7338162660598755
    },
    {
      "step": 1843,
      "loss": 0.023310715332627296,
      "accuracy": 0.9375,
      "grad_norm": 0.509109377861023
    },
    {
      "step": 1844,
      "loss": 0.0025462170597165823,
      "accuracy": 1.0,
      "grad_norm": 0.16238334774971008
    },
    {
      "step": 1845,
      "loss": 0.0009033769019879401,
      "accuracy": 1.0,
      "grad_norm": 0.024875381961464882
    },
    {
      "step": 1846,
      "loss": 0.036009807139635086,
      "accuracy": 0.9375,
      "grad_norm": 1.9937856197357178
    },
    {
      "step": 1847,
      "loss": 0.07085539400577545,
      "accuracy": 0.875,
      "grad_norm": 1.4681158065795898
    },
    {
      "step": 1848,
      "loss": 0.14252352714538574,
      "accuracy": 0.75,
      "grad_norm": 4.199601650238037
    },
    {
      "step": 1849,
      "loss": 0.05395059287548065,
      "accuracy": 0.875,
      "grad_norm": 3.0286037921905518
    },
    {
      "step": 1850,
      "loss": 0.0642414465546608,
      "accuracy": 0.9375,
      "grad_norm": 3.162757158279419
    },
    {
      "step": 1851,
      "loss": 0.1150786504149437,
      "accuracy": 0.875,
      "grad_norm": 1.8158738613128662
    },
    {
      "step": 1852,
      "loss": 0.0047354064881801605,
      "accuracy": 1.0,
      "grad_norm": 0.22356459498405457
    },
    {
      "step": 1853,
      "loss": 0.002763717668130994,
      "accuracy": 1.0,
      "grad_norm": 0.07876526564359665
    },
    {
      "step": 1854,
      "loss": 0.007495848461985588,
      "accuracy": 1.0,
      "grad_norm": 0.2190755009651184
    },
    {
      "step": 1855,
      "loss": 0.04190100356936455,
      "accuracy": 0.9375,
      "grad_norm": 1.4772727489471436
    },
    {
      "step": 1856,
      "loss": 0.0025181244127452374,
      "accuracy": 1.0,
      "grad_norm": 0.13792765140533447
    },
    {
      "step": 1857,
      "loss": 0.043795693665742874,
      "accuracy": 0.9375,
      "grad_norm": 2.8811609745025635
    },
    {
      "step": 1858,
      "loss": 0.001195790828205645,
      "accuracy": 1.0,
      "grad_norm": 0.0417226143181324
    },
    {
      "step": 1859,
      "loss": 0.05834635719656944,
      "accuracy": 0.9375,
      "grad_norm": 1.0091285705566406
    },
    {
      "step": 1860,
      "loss": 0.016547933220863342,
      "accuracy": 0.9375,
      "grad_norm": 0.8382055759429932
    },
    {
      "step": 1861,
      "loss": 0.02070941962301731,
      "accuracy": 1.0,
      "grad_norm": 0.5542498826980591
    },
    {
      "step": 1862,
      "loss": 0.010240715928375721,
      "accuracy": 1.0,
      "grad_norm": 0.21152947843074799
    },
    {
      "step": 1863,
      "loss": 0.00886707566678524,
      "accuracy": 1.0,
      "grad_norm": 0.5189306139945984
    },
    {
      "step": 1864,
      "loss": 0.003799417521804571,
      "accuracy": 1.0,
      "grad_norm": 0.169669970870018
    },
    {
      "step": 1865,
      "loss": 0.008124656043946743,
      "accuracy": 1.0,
      "grad_norm": 0.5785318613052368
    },
    {
      "step": 1866,
      "loss": 0.03148369491100311,
      "accuracy": 0.9375,
      "grad_norm": 1.7349944114685059
    },
    {
      "step": 1867,
      "loss": 0.029200809076428413,
      "accuracy": 0.9375,
      "grad_norm": 1.5046913623809814
    },
    {
      "step": 1868,
      "loss": 0.008314053528010845,
      "accuracy": 1.0,
      "grad_norm": 0.37564438581466675
    },
    {
      "step": 1869,
      "loss": 0.00942873302847147,
      "accuracy": 1.0,
      "grad_norm": 0.6968651413917542
    },
    {
      "step": 1870,
      "loss": 0.0319502018392086,
      "accuracy": 0.9375,
      "grad_norm": 1.7412725687026978
    },
    {
      "step": 1871,
      "loss": 0.0023162777069956064,
      "accuracy": 1.0,
      "grad_norm": 0.10647615045309067
    },
    {
      "step": 1872,
      "loss": 0.0012394979130476713,
      "accuracy": 1.0,
      "grad_norm": 0.053843434900045395
    },
    {
      "step": 1873,
      "loss": 0.015107879415154457,
      "accuracy": 1.0,
      "grad_norm": 0.6445655822753906
    },
    {
      "step": 1874,
      "loss": 0.0020549434702843428,
      "accuracy": 1.0,
      "grad_norm": 0.11650027334690094
    },
    {
      "step": 1875,
      "loss": 0.1643405556678772,
      "accuracy": 0.875,
      "grad_norm": 1.8595479726791382
    },
    {
      "step": 1876,
      "loss": 0.012963440269231796,
      "accuracy": 1.0,
      "grad_norm": 1.2612971067428589
    },
    {
      "step": 1877,
      "loss": 0.008623926900327206,
      "accuracy": 1.0,
      "grad_norm": 0.4763093888759613
    },
    {
      "step": 1878,
      "loss": 0.024996820837259293,
      "accuracy": 0.9375,
      "grad_norm": 1.133690595626831
    },
    {
      "step": 1879,
      "loss": 0.00869674514979124,
      "accuracy": 1.0,
      "grad_norm": 0.768954873085022
    },
    {
      "step": 1880,
      "loss": 0.06756269931793213,
      "accuracy": 0.9375,
      "grad_norm": 0.9419417977333069
    },
    {
      "step": 1881,
      "loss": 0.007410023827105761,
      "accuracy": 1.0,
      "grad_norm": 0.8228520750999451
    },
    {
      "step": 1882,
      "loss": 0.07545649260282516,
      "accuracy": 0.9375,
      "grad_norm": 0.823663592338562
    },
    {
      "step": 1883,
      "loss": 0.03859976679086685,
      "accuracy": 0.9375,
      "grad_norm": 1.8848189115524292
    },
    {
      "step": 1884,
      "loss": 0.002673584269359708,
      "accuracy": 1.0,
      "grad_norm": 0.09712082147598267
    },
    {
      "step": 1885,
      "loss": 0.0269636157900095,
      "accuracy": 0.9375,
      "grad_norm": 1.0635719299316406
    },
    {
      "step": 1886,
      "loss": 0.004137949552386999,
      "accuracy": 1.0,
      "grad_norm": 0.3292033076286316
    },
    {
      "step": 1887,
      "loss": 0.06040915474295616,
      "accuracy": 0.9375,
      "grad_norm": 0.5833176374435425
    },
    {
      "step": 1888,
      "loss": 0.004453470464795828,
      "accuracy": 1.0,
      "grad_norm": 0.3063124418258667
    },
    {
      "step": 1889,
      "loss": 0.030055146664381027,
      "accuracy": 0.9375,
      "grad_norm": 1.3211946487426758
    },
    {
      "step": 1890,
      "loss": 0.00903051532804966,
      "accuracy": 1.0,
      "grad_norm": 0.5314486026763916
    },
    {
      "step": 1891,
      "loss": 0.08529173582792282,
      "accuracy": 0.875,
      "grad_norm": 0.7612876892089844
    },
    {
      "step": 1892,
      "loss": 0.009737646207213402,
      "accuracy": 1.0,
      "grad_norm": 0.6630026698112488
    },
    {
      "step": 1893,
      "loss": 0.0025943638756871223,
      "accuracy": 1.0,
      "grad_norm": 0.10422663390636444
    },
    {
      "step": 1894,
      "loss": 0.003222472732886672,
      "accuracy": 1.0,
      "grad_norm": 0.10641861706972122
    },
    {
      "step": 1895,
      "loss": 0.00833851471543312,
      "accuracy": 1.0,
      "grad_norm": 0.5002628564834595
    },
    {
      "step": 1896,
      "loss": 0.1360122114419937,
      "accuracy": 0.8125,
      "grad_norm": 1.8865635395050049
    },
    {
      "step": 1897,
      "loss": 0.011859923601150513,
      "accuracy": 0.9375,
      "grad_norm": 0.7640953660011292
    },
    {
      "step": 1898,
      "loss": 0.15286795794963837,
      "accuracy": 0.8125,
      "grad_norm": 3.0305325984954834
    },
    {
      "step": 1899,
      "loss": 0.001411945791915059,
      "accuracy": 1.0,
      "grad_norm": 0.042261816561222076
    },
    {
      "step": 1900,
      "loss": 0.008646883070468903,
      "accuracy": 1.0,
      "grad_norm": 0.3827574849128723
    },
    {
      "step": 1901,
      "loss": 0.0092550627887249,
      "accuracy": 1.0,
      "grad_norm": 0.23827733099460602
    },
    {
      "step": 1902,
      "loss": 0.019887663424015045,
      "accuracy": 0.9375,
      "grad_norm": 0.7684294581413269
    },
    {
      "step": 1903,
      "loss": 0.07346487045288086,
      "accuracy": 0.9375,
      "grad_norm": 1.1668822765350342
    },
    {
      "step": 1904,
      "loss": 0.006465210113674402,
      "accuracy": 1.0,
      "grad_norm": 0.37303224205970764
    },
    {
      "step": 1905,
      "loss": 0.06220647692680359,
      "accuracy": 0.8125,
      "grad_norm": 0.5301875472068787
    },
    {
      "step": 1906,
      "loss": 0.01405898854136467,
      "accuracy": 1.0,
      "grad_norm": 0.838396430015564
    },
    {
      "step": 1907,
      "loss": 0.0054647307842969894,
      "accuracy": 1.0,
      "grad_norm": 0.1362171769142151
    },
    {
      "step": 1908,
      "loss": 0.003411067882552743,
      "accuracy": 1.0,
      "grad_norm": 0.12856349349021912
    },
    {
      "step": 1909,
      "loss": 0.02300519309937954,
      "accuracy": 0.9375,
      "grad_norm": 0.6150944828987122
    },
    {
      "step": 1910,
      "loss": 0.05478088930249214,
      "accuracy": 0.9375,
      "grad_norm": 0.9403464198112488
    },
    {
      "step": 1911,
      "loss": 0.028730742633342743,
      "accuracy": 1.0,
      "grad_norm": 1.5257471799850464
    },
    {
      "step": 1912,
      "loss": 0.015148153528571129,
      "accuracy": 1.0,
      "grad_norm": 0.7294158935546875
    },
    {
      "step": 1913,
      "loss": 0.02589859999716282,
      "accuracy": 0.9375,
      "grad_norm": 0.46868956089019775
    },
    {
      "step": 1914,
      "loss": 0.008318859152495861,
      "accuracy": 1.0,
      "grad_norm": 0.38750016689300537
    },
    {
      "step": 1915,
      "loss": 0.0033989122603088617,
      "accuracy": 1.0,
      "grad_norm": 0.1613977551460266
    },
    {
      "step": 1916,
      "loss": 0.002119221491739154,
      "accuracy": 1.0,
      "grad_norm": 0.07513760775327682
    },
    {
      "step": 1917,
      "loss": 0.005137274041771889,
      "accuracy": 1.0,
      "grad_norm": 0.2863214612007141
    },
    {
      "step": 1918,
      "loss": 0.05069766938686371,
      "accuracy": 0.9375,
      "grad_norm": 0.6758653521537781
    },
    {
      "step": 1919,
      "loss": 0.007110073696821928,
      "accuracy": 1.0,
      "grad_norm": 0.16751813888549805
    },
    {
      "step": 1920,
      "loss": 0.024441640824079514,
      "accuracy": 0.9375,
      "grad_norm": 1.1810139417648315
    },
    {
      "step": 1921,
      "loss": 0.0022264670114964247,
      "accuracy": 1.0,
      "grad_norm": 0.10861126333475113
    },
    {
      "step": 1922,
      "loss": 0.003012564731761813,
      "accuracy": 1.0,
      "grad_norm": 0.13550250232219696
    },
    {
      "step": 1923,
      "loss": 0.004500770475715399,
      "accuracy": 1.0,
      "grad_norm": 0.1061626449227333
    },
    {
      "step": 1924,
      "loss": 0.004257005639374256,
      "accuracy": 1.0,
      "grad_norm": 0.2835170328617096
    },
    {
      "step": 1925,
      "loss": 0.0012756092473864555,
      "accuracy": 1.0,
      "grad_norm": 0.04931728169322014
    },
    {
      "step": 1926,
      "loss": 0.0012514556292444468,
      "accuracy": 1.0,
      "grad_norm": 0.046747513115406036
    },
    {
      "step": 1927,
      "loss": 0.008103590458631516,
      "accuracy": 1.0,
      "grad_norm": 0.40340760350227356
    },
    {
      "step": 1928,
      "loss": 0.024676116183400154,
      "accuracy": 1.0,
      "grad_norm": 0.7795092463493347
    },
    {
      "step": 1929,
      "loss": 0.010363908484578133,
      "accuracy": 1.0,
      "grad_norm": 0.8965807557106018
    },
    {
      "step": 1930,
      "loss": 0.0006868312484584749,
      "accuracy": 1.0,
      "grad_norm": 0.015031441114842892
    },
    {
      "step": 1931,
      "loss": 0.0024631558917462826,
      "accuracy": 1.0,
      "grad_norm": 0.07496973127126694
    },
    {
      "step": 1932,
      "loss": 0.0024015153758227825,
      "accuracy": 1.0,
      "grad_norm": 0.18567785620689392
    },
    {
      "step": 1933,
      "loss": 0.07215339690446854,
      "accuracy": 0.875,
      "grad_norm": 1.6308274269104004
    },
    {
      "step": 1934,
      "loss": 0.022488368675112724,
      "accuracy": 1.0,
      "grad_norm": 2.424406051635742
    },
    {
      "step": 1935,
      "loss": 0.0012218173360452056,
      "accuracy": 1.0,
      "grad_norm": 0.0630437582731247
    },
    {
      "step": 1936,
      "loss": 0.053448569029569626,
      "accuracy": 0.9375,
      "grad_norm": 0.667699933052063
    },
    {
      "step": 1937,
      "loss": 0.020009184256196022,
      "accuracy": 1.0,
      "grad_norm": 2.0975117683410645
    },
    {
      "step": 1938,
      "loss": 0.06523146480321884,
      "accuracy": 0.875,
      "grad_norm": 3.107605457305908
    },
    {
      "step": 1939,
      "loss": 0.09350262582302094,
      "accuracy": 0.875,
      "grad_norm": 1.625670313835144
    },
    {
      "step": 1940,
      "loss": 0.0009542462066747248,
      "accuracy": 1.0,
      "grad_norm": 0.029541896656155586
    },
    {
      "step": 1941,
      "loss": 0.05216362699866295,
      "accuracy": 0.9375,
      "grad_norm": 1.3423149585723877
    },
    {
      "step": 1942,
      "loss": 0.005874082911759615,
      "accuracy": 1.0,
      "grad_norm": 0.2886880934238434
    },
    {
      "step": 1943,
      "loss": 0.008298679254949093,
      "accuracy": 1.0,
      "grad_norm": 0.33825597167015076
    },
    {
      "step": 1944,
      "loss": 0.003003513440489769,
      "accuracy": 1.0,
      "grad_norm": 0.13310490548610687
    },
    {
      "step": 1945,
      "loss": 0.0009991060942411423,
      "accuracy": 1.0,
      "grad_norm": 0.019561605527997017
    },
    {
      "step": 1946,
      "loss": 0.005220101680606604,
      "accuracy": 1.0,
      "grad_norm": 0.14383578300476074
    },
    {
      "step": 1947,
      "loss": 0.005260884761810303,
      "accuracy": 1.0,
      "grad_norm": 0.24393486976623535
    },
    {
      "step": 1948,
      "loss": 0.07230165600776672,
      "accuracy": 0.9375,
      "grad_norm": 2.2344188690185547
    },
    {
      "step": 1949,
      "loss": 0.05579032003879547,
      "accuracy": 0.9375,
      "grad_norm": 0.655459463596344
    },
    {
      "step": 1950,
      "loss": 0.036766089498996735,
      "accuracy": 0.875,
      "grad_norm": 3.3618972301483154
    },
    {
      "step": 1951,
      "loss": 0.00538150779902935,
      "accuracy": 1.0,
      "grad_norm": 0.3444238603115082
    },
    {
      "step": 1952,
      "loss": 0.009226247668266296,
      "accuracy": 1.0,
      "grad_norm": 0.4714410603046417
    },
    {
      "step": 1953,
      "loss": 0.0032240378204733133,
      "accuracy": 1.0,
      "grad_norm": 0.08487909287214279
    },
    {
      "step": 1954,
      "loss": 0.0013052759459242225,
      "accuracy": 1.0,
      "grad_norm": 0.04491402953863144
    },
    {
      "step": 1955,
      "loss": 0.002769005950540304,
      "accuracy": 1.0,
      "grad_norm": 0.13569781184196472
    },
    {
      "step": 1956,
      "loss": 0.004448537714779377,
      "accuracy": 1.0,
      "grad_norm": 0.2217395305633545
    },
    {
      "step": 1957,
      "loss": 0.0016778860008344054,
      "accuracy": 1.0,
      "grad_norm": 0.03994065523147583
    },
    {
      "step": 1958,
      "loss": 0.11425383388996124,
      "accuracy": 0.875,
      "grad_norm": 1.6071510314941406
    },
    {
      "step": 1959,
      "loss": 0.035903528332710266,
      "accuracy": 0.9375,
      "grad_norm": 1.1843082904815674
    },
    {
      "step": 1960,
      "loss": 0.05709107592701912,
      "accuracy": 0.8125,
      "grad_norm": 1.6669600009918213
    },
    {
      "step": 1961,
      "loss": 0.015027343295514584,
      "accuracy": 1.0,
      "grad_norm": 0.7122039794921875
    },
    {
      "step": 1962,
      "loss": 0.005791427101939917,
      "accuracy": 1.0,
      "grad_norm": 0.14883433282375336
    },
    {
      "step": 1963,
      "loss": 0.026173939928412437,
      "accuracy": 0.9375,
      "grad_norm": 0.6782646775245667
    },
    {
      "step": 1964,
      "loss": 0.028910262510180473,
      "accuracy": 0.9375,
      "grad_norm": 1.5911630392074585
    },
    {
      "step": 1965,
      "loss": 0.0011619662400335073,
      "accuracy": 1.0,
      "grad_norm": 0.049591872841119766
    },
    {
      "step": 1966,
      "loss": 0.023824291303753853,
      "accuracy": 0.9375,
      "grad_norm": 1.441320776939392
    },
    {
      "step": 1967,
      "loss": 0.005410574376583099,
      "accuracy": 1.0,
      "grad_norm": 0.4699007272720337
    },
    {
      "step": 1968,
      "loss": 0.003219186794012785,
      "accuracy": 1.0,
      "grad_norm": 0.3129322826862335
    },
    {
      "step": 1969,
      "loss": 0.004048854112625122,
      "accuracy": 1.0,
      "grad_norm": 0.2689407467842102
    },
    {
      "step": 1970,
      "loss": 0.06608100235462189,
      "accuracy": 0.9375,
      "grad_norm": 0.6495201587677002
    },
    {
      "step": 1971,
      "loss": 0.010514719411730766,
      "accuracy": 1.0,
      "grad_norm": 0.8960075378417969
    },
    {
      "step": 1972,
      "loss": 0.0006712574395351112,
      "accuracy": 1.0,
      "grad_norm": 0.022176774218678474
    },
    {
      "step": 1973,
      "loss": 0.001042461022734642,
      "accuracy": 1.0,
      "grad_norm": 0.024138031527400017
    },
    {
      "step": 1974,
      "loss": 0.014209016226232052,
      "accuracy": 1.0,
      "grad_norm": 1.4455455541610718
    },
    {
      "step": 1975,
      "loss": 0.006738524883985519,
      "accuracy": 1.0,
      "grad_norm": 0.8153577446937561
    },
    {
      "step": 1976,
      "loss": 0.05927303433418274,
      "accuracy": 0.9375,
      "grad_norm": 2.1946027278900146
    },
    {
      "step": 1977,
      "loss": 0.0005666807410307229,
      "accuracy": 1.0,
      "grad_norm": 0.012238780036568642
    },
    {
      "step": 1978,
      "loss": 0.023306749761104584,
      "accuracy": 0.9375,
      "grad_norm": 1.4432328939437866
    },
    {
      "step": 1979,
      "loss": 0.0019368313951417804,
      "accuracy": 1.0,
      "grad_norm": 0.08748262375593185
    },
    {
      "step": 1980,
      "loss": 0.046531107276678085,
      "accuracy": 0.9375,
      "grad_norm": 2.3810176849365234
    },
    {
      "step": 1981,
      "loss": 0.06334760785102844,
      "accuracy": 0.9375,
      "grad_norm": 1.111161708831787
    },
    {
      "step": 1982,
      "loss": 0.004056472331285477,
      "accuracy": 1.0,
      "grad_norm": 0.3134955167770386
    },
    {
      "step": 1983,
      "loss": 0.000660179415717721,
      "accuracy": 1.0,
      "grad_norm": 0.012742042541503906
    },
    {
      "step": 1984,
      "loss": 0.0268237367272377,
      "accuracy": 0.9375,
      "grad_norm": 1.1609723567962646
    },
    {
      "step": 1985,
      "loss": 0.04517660290002823,
      "accuracy": 0.875,
      "grad_norm": 1.9670456647872925
    },
    {
      "step": 1986,
      "loss": 0.005799683276563883,
      "accuracy": 1.0,
      "grad_norm": 0.32084164023399353
    },
    {
      "step": 1987,
      "loss": 0.002338788704946637,
      "accuracy": 1.0,
      "grad_norm": 0.07219257205724716
    },
    {
      "step": 1988,
      "loss": 0.015162230469286442,
      "accuracy": 1.0,
      "grad_norm": 0.8629380464553833
    },
    {
      "step": 1989,
      "loss": 0.01011872012168169,
      "accuracy": 1.0,
      "grad_norm": 1.318076729774475
    },
    {
      "step": 1990,
      "loss": 0.021283792331814766,
      "accuracy": 0.9375,
      "grad_norm": 1.1445033550262451
    },
    {
      "step": 1991,
      "loss": 0.027171216905117035,
      "accuracy": 0.9375,
      "grad_norm": 1.6808735132217407
    },
    {
      "step": 1992,
      "loss": 0.004868186078965664,
      "accuracy": 1.0,
      "grad_norm": 0.2833365499973297
    },
    {
      "step": 1993,
      "loss": 0.023586150258779526,
      "accuracy": 0.9375,
      "grad_norm": 1.4701000452041626
    },
    {
      "step": 1994,
      "loss": 0.0037537424359470606,
      "accuracy": 1.0,
      "grad_norm": 0.18518821895122528
    },
    {
      "step": 1995,
      "loss": 0.0037929797545075417,
      "accuracy": 1.0,
      "grad_norm": 0.09948896616697311
    },
    {
      "step": 1996,
      "loss": 0.015049622394144535,
      "accuracy": 1.0,
      "grad_norm": 1.0883169174194336
    },
    {
      "step": 1997,
      "loss": 0.003013158682733774,
      "accuracy": 1.0,
      "grad_norm": 0.09482697397470474
    },
    {
      "step": 1998,
      "loss": 0.06903935968875885,
      "accuracy": 0.9375,
      "grad_norm": 1.559051275253296
    },
    {
      "step": 1999,
      "loss": 0.006527026183903217,
      "accuracy": 1.0,
      "grad_norm": 0.3828844130039215
    },
    {
      "step": 2000,
      "loss": 0.03762368485331535,
      "accuracy": 0.9375,
      "grad_norm": 0.6725384593009949
    },
    {
      "step": 2001,
      "loss": 0.019811630249023438,
      "accuracy": 0.9375,
      "grad_norm": 1.5920170545578003
    },
    {
      "step": 2002,
      "loss": 0.05235271528363228,
      "accuracy": 0.9375,
      "grad_norm": 1.993205189704895
    },
    {
      "step": 2003,
      "loss": 0.06656461954116821,
      "accuracy": 0.875,
      "grad_norm": 1.4909460544586182
    },
    {
      "step": 2004,
      "loss": 0.005636881105601788,
      "accuracy": 1.0,
      "grad_norm": 0.331464558839798
    },
    {
      "step": 2005,
      "loss": 0.029803752899169922,
      "accuracy": 0.9375,
      "grad_norm": 1.999390721321106
    },
    {
      "step": 2006,
      "loss": 0.00881496537476778,
      "accuracy": 1.0,
      "grad_norm": 0.757128894329071
    },
    {
      "step": 2007,
      "loss": 0.004779706243425608,
      "accuracy": 1.0,
      "grad_norm": 0.565970778465271
    },
    {
      "step": 2008,
      "loss": 0.00113370839972049,
      "accuracy": 1.0,
      "grad_norm": 0.04659055545926094
    },
    {
      "step": 2009,
      "loss": 0.07790117710828781,
      "accuracy": 0.875,
      "grad_norm": 6.54518461227417
    },
    {
      "step": 2010,
      "loss": 0.05548090860247612,
      "accuracy": 0.8125,
      "grad_norm": 5.2678751945495605
    },
    {
      "step": 2011,
      "loss": 0.007201822474598885,
      "accuracy": 1.0,
      "grad_norm": 1.3696495294570923
    },
    {
      "step": 2012,
      "loss": 0.010731348767876625,
      "accuracy": 1.0,
      "grad_norm": 0.6603057384490967
    },
    {
      "step": 2013,
      "loss": 0.006353478413075209,
      "accuracy": 1.0,
      "grad_norm": 0.4361300766468048
    },
    {
      "step": 2014,
      "loss": 0.047420941293239594,
      "accuracy": 0.9375,
      "grad_norm": 1.5714967250823975
    },
    {
      "step": 2015,
      "loss": 0.0015913278330117464,
      "accuracy": 1.0,
      "grad_norm": 0.045545510947704315
    },
    {
      "step": 2016,
      "loss": 0.06534960120916367,
      "accuracy": 0.9375,
      "grad_norm": 0.8014993071556091
    },
    {
      "step": 2017,
      "loss": 0.00455197598785162,
      "accuracy": 1.0,
      "grad_norm": 0.1343366950750351
    },
    {
      "step": 2018,
      "loss": 0.0607881173491478,
      "accuracy": 0.9375,
      "grad_norm": 2.4906082153320312
    },
    {
      "step": 2019,
      "loss": 0.00253373128362,
      "accuracy": 1.0,
      "grad_norm": 0.08355563133955002
    },
    {
      "step": 2020,
      "loss": 0.01034530159085989,
      "accuracy": 1.0,
      "grad_norm": 0.585054337978363
    },
    {
      "step": 2021,
      "loss": 0.0028530885465443134,
      "accuracy": 1.0,
      "grad_norm": 0.09243408590555191
    },
    {
      "step": 2022,
      "loss": 0.08572312444448471,
      "accuracy": 0.875,
      "grad_norm": 1.0763317346572876
    },
    {
      "step": 2023,
      "loss": 0.03581681847572327,
      "accuracy": 0.9375,
      "grad_norm": 0.7361528873443604
    },
    {
      "step": 2024,
      "loss": 0.01550906803458929,
      "accuracy": 1.0,
      "grad_norm": 0.9454011917114258
    },
    {
      "step": 2025,
      "loss": 0.009912063367664814,
      "accuracy": 1.0,
      "grad_norm": 0.36215940117836
    },
    {
      "step": 2026,
      "loss": 0.024640513584017754,
      "accuracy": 0.9375,
      "grad_norm": 1.25261390209198
    },
    {
      "step": 2027,
      "loss": 0.014087998308241367,
      "accuracy": 1.0,
      "grad_norm": 0.8168565630912781
    },
    {
      "step": 2028,
      "loss": 0.0033836946822702885,
      "accuracy": 1.0,
      "grad_norm": 0.11183325201272964
    },
    {
      "step": 2029,
      "loss": 0.005053239408880472,
      "accuracy": 1.0,
      "grad_norm": 0.15263743698596954
    },
    {
      "step": 2030,
      "loss": 0.002071669790893793,
      "accuracy": 1.0,
      "grad_norm": 0.06268294155597687
    },
    {
      "step": 2031,
      "loss": 0.06937246769666672,
      "accuracy": 0.875,
      "grad_norm": 0.7408367991447449
    },
    {
      "step": 2032,
      "loss": 0.0384703166782856,
      "accuracy": 0.875,
      "grad_norm": 2.2171502113342285
    },
    {
      "step": 2033,
      "loss": 0.01847471296787262,
      "accuracy": 0.9375,
      "grad_norm": 1.300453543663025
    },
    {
      "step": 2034,
      "loss": 0.0018132079858332872,
      "accuracy": 1.0,
      "grad_norm": 0.05162180960178375
    },
    {
      "step": 2035,
      "loss": 0.00225629610940814,
      "accuracy": 1.0,
      "grad_norm": 0.07862543314695358
    },
    {
      "step": 2036,
      "loss": 0.15421821177005768,
      "accuracy": 0.8125,
      "grad_norm": 3.548741340637207
    },
    {
      "step": 2037,
      "loss": 0.0014642066089436412,
      "accuracy": 1.0,
      "grad_norm": 0.045712534338235855
    },
    {
      "step": 2038,
      "loss": 0.043011587113142014,
      "accuracy": 0.875,
      "grad_norm": 0.9431843757629395
    },
    {
      "step": 2039,
      "loss": 0.026525020599365234,
      "accuracy": 0.9375,
      "grad_norm": 0.7047377824783325
    },
    {
      "step": 2040,
      "loss": 0.0024633125867694616,
      "accuracy": 1.0,
      "grad_norm": 0.060924869030714035
    },
    {
      "step": 2041,
      "loss": 0.0066283512860536575,
      "accuracy": 1.0,
      "grad_norm": 0.1436096578836441
    },
    {
      "step": 2042,
      "loss": 0.006454065907746553,
      "accuracy": 1.0,
      "grad_norm": 0.4394102394580841
    },
    {
      "step": 2043,
      "loss": 0.0027617188170552254,
      "accuracy": 1.0,
      "grad_norm": 0.09741727262735367
    },
    {
      "step": 2044,
      "loss": 0.002505525015294552,
      "accuracy": 1.0,
      "grad_norm": 0.17871111631393433
    },
    {
      "step": 2045,
      "loss": 0.02245478518307209,
      "accuracy": 0.9375,
      "grad_norm": 1.6621266603469849
    },
    {
      "step": 2046,
      "loss": 0.0012396969832479954,
      "accuracy": 1.0,
      "grad_norm": 0.05778428539633751
    },
    {
      "step": 2047,
      "loss": 0.008830849081277847,
      "accuracy": 1.0,
      "grad_norm": 0.31894057989120483
    },
    {
      "step": 2048,
      "loss": 0.0009025403996929526,
      "accuracy": 1.0,
      "grad_norm": 0.03418872505426407
    },
    {
      "step": 2049,
      "loss": 0.0036138577852398157,
      "accuracy": 1.0,
      "grad_norm": 0.2198629379272461
    },
    {
      "step": 2050,
      "loss": 0.0037839235737919807,
      "accuracy": 1.0,
      "grad_norm": 0.26731351017951965
    },
    {
      "step": 2051,
      "loss": 0.000849545409437269,
      "accuracy": 1.0,
      "grad_norm": 0.023018963634967804
    },
    {
      "step": 2052,
      "loss": 0.0014543094439432025,
      "accuracy": 1.0,
      "grad_norm": 0.0539306104183197
    },
    {
      "step": 2053,
      "loss": 0.09824000298976898,
      "accuracy": 0.875,
      "grad_norm": 1.58452570438385
    },
    {
      "step": 2054,
      "loss": 0.01182564441114664,
      "accuracy": 0.9375,
      "grad_norm": 1.1674374341964722
    },
    {
      "step": 2055,
      "loss": 0.007269831374287605,
      "accuracy": 1.0,
      "grad_norm": 0.6699597835540771
    },
    {
      "step": 2056,
      "loss": 0.022245312109589577,
      "accuracy": 0.9375,
      "grad_norm": 1.7366411685943604
    },
    {
      "step": 2057,
      "loss": 0.0018981273751705885,
      "accuracy": 1.0,
      "grad_norm": 0.11026730388402939
    },
    {
      "step": 2058,
      "loss": 0.013343269936740398,
      "accuracy": 1.0,
      "grad_norm": 0.8008063435554504
    },
    {
      "step": 2059,
      "loss": 0.07579785585403442,
      "accuracy": 0.9375,
      "grad_norm": 1.4311563968658447
    },
    {
      "step": 2060,
      "loss": 0.0015504509210586548,
      "accuracy": 1.0,
      "grad_norm": 0.09494780004024506
    },
    {
      "step": 2061,
      "loss": 0.0002710937988013029,
      "accuracy": 1.0,
      "grad_norm": 0.004218903370201588
    },
    {
      "step": 2062,
      "loss": 0.07051312923431396,
      "accuracy": 0.9375,
      "grad_norm": 1.214563250541687
    },
    {
      "step": 2063,
      "loss": 0.005025696009397507,
      "accuracy": 1.0,
      "grad_norm": 0.3477461338043213
    },
    {
      "step": 2064,
      "loss": 0.0017591522773727775,
      "accuracy": 1.0,
      "grad_norm": 0.13822698593139648
    },
    {
      "step": 2065,
      "loss": 0.0012009050697088242,
      "accuracy": 1.0,
      "grad_norm": 0.06903804838657379
    },
    {
      "step": 2066,
      "loss": 0.042522598057985306,
      "accuracy": 0.9375,
      "grad_norm": 0.8676080107688904
    },
    {
      "step": 2067,
      "loss": 0.013052024878561497,
      "accuracy": 1.0,
      "grad_norm": 1.0655535459518433
    },
    {
      "step": 2068,
      "loss": 0.02286922000348568,
      "accuracy": 0.9375,
      "grad_norm": 1.3710774183273315
    },
    {
      "step": 2069,
      "loss": 0.003997498657554388,
      "accuracy": 1.0,
      "grad_norm": 0.49095943570137024
    },
    {
      "step": 2070,
      "loss": 0.06524009257555008,
      "accuracy": 0.9375,
      "grad_norm": 0.8189042806625366
    },
    {
      "step": 2071,
      "loss": 0.0021886706817895174,
      "accuracy": 1.0,
      "grad_norm": 0.051187582314014435
    },
    {
      "step": 2072,
      "loss": 0.004777471534907818,
      "accuracy": 1.0,
      "grad_norm": 0.18974842131137848
    },
    {
      "step": 2073,
      "loss": 0.003019134048372507,
      "accuracy": 1.0,
      "grad_norm": 0.15012116730213165
    },
    {
      "step": 2074,
      "loss": 0.006183363497257233,
      "accuracy": 1.0,
      "grad_norm": 0.3477288782596588
    },
    {
      "step": 2075,
      "loss": 0.012415982782840729,
      "accuracy": 1.0,
      "grad_norm": 0.9711014628410339
    },
    {
      "step": 2076,
      "loss": 0.007111800834536552,
      "accuracy": 1.0,
      "grad_norm": 0.3631134033203125
    },
    {
      "step": 2077,
      "loss": 0.021061476320028305,
      "accuracy": 0.9375,
      "grad_norm": 1.5359457731246948
    },
    {
      "step": 2078,
      "loss": 0.0033286598045378923,
      "accuracy": 1.0,
      "grad_norm": 0.13542482256889343
    },
    {
      "step": 2079,
      "loss": 0.003931953106075525,
      "accuracy": 1.0,
      "grad_norm": 0.23247507214546204
    },
    {
      "step": 2080,
      "loss": 0.02951420284807682,
      "accuracy": 0.9375,
      "grad_norm": 0.980438768863678
    },
    {
      "step": 2081,
      "loss": 0.001210101880133152,
      "accuracy": 1.0,
      "grad_norm": 0.05297530069947243
    },
    {
      "step": 2082,
      "loss": 0.005711304023861885,
      "accuracy": 1.0,
      "grad_norm": 0.26829034090042114
    },
    {
      "step": 2083,
      "loss": 0.024661945179104805,
      "accuracy": 0.9375,
      "grad_norm": 1.8950985670089722
    },
    {
      "step": 2084,
      "loss": 0.012536182068288326,
      "accuracy": 0.9375,
      "grad_norm": 0.9191687703132629
    },
    {
      "step": 2085,
      "loss": 0.000626016000751406,
      "accuracy": 1.0,
      "grad_norm": 0.03054416924715042
    },
    {
      "step": 2086,
      "loss": 0.0010078424820676446,
      "accuracy": 1.0,
      "grad_norm": 0.02321273274719715
    },
    {
      "step": 2087,
      "loss": 0.002437793416902423,
      "accuracy": 1.0,
      "grad_norm": 0.20513929426670074
    },
    {
      "step": 2088,
      "loss": 0.01051600556820631,
      "accuracy": 1.0,
      "grad_norm": 0.9916269779205322
    },
    {
      "step": 2089,
      "loss": 0.0012156619923189282,
      "accuracy": 1.0,
      "grad_norm": 0.1107846349477768
    },
    {
      "step": 2090,
      "loss": 0.0006746859871782362,
      "accuracy": 1.0,
      "grad_norm": 0.02504163607954979
    },
    {
      "step": 2091,
      "loss": 0.06845615804195404,
      "accuracy": 0.9375,
      "grad_norm": 2.480328321456909
    },
    {
      "step": 2092,
      "loss": 0.006555141881108284,
      "accuracy": 1.0,
      "grad_norm": 0.5157253742218018
    },
    {
      "step": 2093,
      "loss": 0.0008271128172054887,
      "accuracy": 1.0,
      "grad_norm": 0.05803650617599487
    },
    {
      "step": 2094,
      "loss": 0.0012275396147742867,
      "accuracy": 1.0,
      "grad_norm": 0.06788404285907745
    },
    {
      "step": 2095,
      "loss": 0.07226665318012238,
      "accuracy": 0.875,
      "grad_norm": 2.250105142593384
    },
    {
      "step": 2096,
      "loss": 0.0012532213004305959,
      "accuracy": 1.0,
      "grad_norm": 0.07512420415878296
    },
    {
      "step": 2097,
      "loss": 0.0010753916576504707,
      "accuracy": 1.0,
      "grad_norm": 0.0475345179438591
    },
    {
      "step": 2098,
      "loss": 0.08118220418691635,
      "accuracy": 0.9375,
      "grad_norm": 0.5861974954605103
    },
    {
      "step": 2099,
      "loss": 0.04934430122375488,
      "accuracy": 0.9375,
      "grad_norm": 0.8737838864326477
    },
    {
      "step": 2100,
      "loss": 0.031878259032964706,
      "accuracy": 0.9375,
      "grad_norm": 0.7400504350662231
    },
    {
      "step": 2101,
      "loss": 0.0022188120055943727,
      "accuracy": 1.0,
      "grad_norm": 0.14347554743289948
    },
    {
      "step": 2102,
      "loss": 0.029797684401273727,
      "accuracy": 0.9375,
      "grad_norm": 2.1379973888397217
    },
    {
      "step": 2103,
      "loss": 0.012948647141456604,
      "accuracy": 1.0,
      "grad_norm": 0.3782505989074707
    },
    {
      "step": 2104,
      "loss": 0.032945871353149414,
      "accuracy": 0.9375,
      "grad_norm": 2.8213133811950684
    },
    {
      "step": 2105,
      "loss": 0.0046336716040968895,
      "accuracy": 1.0,
      "grad_norm": 0.15589389204978943
    },
    {
      "step": 2106,
      "loss": 0.0014550418127328157,
      "accuracy": 1.0,
      "grad_norm": 0.08668933063745499
    },
    {
      "step": 2107,
      "loss": 0.005516372621059418,
      "accuracy": 1.0,
      "grad_norm": 0.3280991017818451
    },
    {
      "step": 2108,
      "loss": 0.022421743720769882,
      "accuracy": 0.9375,
      "grad_norm": 1.7059355974197388
    },
    {
      "step": 2109,
      "loss": 0.006635172292590141,
      "accuracy": 1.0,
      "grad_norm": 0.32844972610473633
    },
    {
      "step": 2110,
      "loss": 0.0016624764539301395,
      "accuracy": 1.0,
      "grad_norm": 0.06434755027294159
    },
    {
      "step": 2111,
      "loss": 0.03235868737101555,
      "accuracy": 0.9375,
      "grad_norm": 1.3794670104980469
    },
    {
      "step": 2112,
      "loss": 0.00173036172054708,
      "accuracy": 1.0,
      "grad_norm": 0.08004418760538101
    },
    {
      "step": 2113,
      "loss": 0.09633499383926392,
      "accuracy": 0.9375,
      "grad_norm": 1.3168272972106934
    },
    {
      "step": 2114,
      "loss": 0.04126596078276634,
      "accuracy": 0.875,
      "grad_norm": 1.7592687606811523
    },
    {
      "step": 2115,
      "loss": 0.0024038690607994795,
      "accuracy": 1.0,
      "grad_norm": 0.10863145440816879
    },
    {
      "step": 2116,
      "loss": 0.0030383600387722254,
      "accuracy": 1.0,
      "grad_norm": 0.1063103899359703
    },
    {
      "step": 2117,
      "loss": 0.001344231073744595,
      "accuracy": 1.0,
      "grad_norm": 0.053215958178043365
    },
    {
      "step": 2118,
      "loss": 0.0015986552461981773,
      "accuracy": 1.0,
      "grad_norm": 0.05138879641890526
    },
    {
      "step": 2119,
      "loss": 0.005874557886272669,
      "accuracy": 1.0,
      "grad_norm": 0.4622792899608612
    },
    {
      "step": 2120,
      "loss": 0.0009006128530018032,
      "accuracy": 1.0,
      "grad_norm": 0.027846816927194595
    },
    {
      "step": 2121,
      "loss": 0.000987596926279366,
      "accuracy": 1.0,
      "grad_norm": 0.04425131902098656
    },
    {
      "step": 2122,
      "loss": 0.003550911322236061,
      "accuracy": 1.0,
      "grad_norm": 0.1960349678993225
    },
    {
      "step": 2123,
      "loss": 0.010045776143670082,
      "accuracy": 1.0,
      "grad_norm": 0.9632598757743835
    },
    {
      "step": 2124,
      "loss": 0.03630110248923302,
      "accuracy": 0.9375,
      "grad_norm": 0.956707775592804
    },
    {
      "step": 2125,
      "loss": 0.004707551561295986,
      "accuracy": 1.0,
      "grad_norm": 0.4828767776489258
    },
    {
      "step": 2126,
      "loss": 0.0026150033809244633,
      "accuracy": 1.0,
      "grad_norm": 0.23492839932441711
    },
    {
      "step": 2127,
      "loss": 0.006712157279253006,
      "accuracy": 1.0,
      "grad_norm": 0.32839691638946533
    },
    {
      "step": 2128,
      "loss": 0.002962173195555806,
      "accuracy": 1.0,
      "grad_norm": 0.1685553789138794
    },
    {
      "step": 2129,
      "loss": 0.0027278270572423935,
      "accuracy": 1.0,
      "grad_norm": 0.31808435916900635
    },
    {
      "step": 2130,
      "loss": 0.017159994691610336,
      "accuracy": 0.9375,
      "grad_norm": 1.144492268562317
    },
    {
      "step": 2131,
      "loss": 0.03028845228254795,
      "accuracy": 0.9375,
      "grad_norm": 0.791244626045227
    },
    {
      "step": 2132,
      "loss": 0.07826262712478638,
      "accuracy": 0.9375,
      "grad_norm": 0.6394298672676086
    },
    {
      "step": 2133,
      "loss": 0.0050698877312242985,
      "accuracy": 1.0,
      "grad_norm": 0.26784905791282654
    },
    {
      "step": 2134,
      "loss": 0.07591092586517334,
      "accuracy": 0.9375,
      "grad_norm": 1.956437587738037
    },
    {
      "step": 2135,
      "loss": 0.053871702402830124,
      "accuracy": 0.9375,
      "grad_norm": 1.007955551147461
    },
    {
      "step": 2136,
      "loss": 0.12366338819265366,
      "accuracy": 0.875,
      "grad_norm": 2.0424156188964844
    },
    {
      "step": 2137,
      "loss": 0.012266960926353931,
      "accuracy": 0.9375,
      "grad_norm": 1.2597579956054688
    },
    {
      "step": 2138,
      "loss": 0.001368281664326787,
      "accuracy": 1.0,
      "grad_norm": 0.055042292922735214
    },
    {
      "step": 2139,
      "loss": 0.0020814980380237103,
      "accuracy": 1.0,
      "grad_norm": 0.07327712327241898
    },
    {
      "step": 2140,
      "loss": 0.005718161817640066,
      "accuracy": 1.0,
      "grad_norm": 0.17056699097156525
    },
    {
      "step": 2141,
      "loss": 0.0005105863674543798,
      "accuracy": 1.0,
      "grad_norm": 0.012670472264289856
    },
    {
      "step": 2142,
      "loss": 0.0008401917293667793,
      "accuracy": 1.0,
      "grad_norm": 0.04296550154685974
    },
    {
      "step": 2143,
      "loss": 0.03584398701786995,
      "accuracy": 0.875,
      "grad_norm": 2.8752686977386475
    },
    {
      "step": 2144,
      "loss": 0.0456438884139061,
      "accuracy": 0.9375,
      "grad_norm": 2.296485662460327
    },
    {
      "step": 2145,
      "loss": 0.0010679780971258879,
      "accuracy": 1.0,
      "grad_norm": 0.01956942491233349
    },
    {
      "step": 2146,
      "loss": 0.017392868176102638,
      "accuracy": 0.9375,
      "grad_norm": 1.4756096601486206
    },
    {
      "step": 2147,
      "loss": 0.04023711755871773,
      "accuracy": 0.9375,
      "grad_norm": 2.5568294525146484
    },
    {
      "step": 2148,
      "loss": 0.038409966975450516,
      "accuracy": 0.9375,
      "grad_norm": 1.884901523590088
    },
    {
      "step": 2149,
      "loss": 0.06866451352834702,
      "accuracy": 0.9375,
      "grad_norm": 1.2572133541107178
    },
    {
      "step": 2150,
      "loss": 0.005376962944865227,
      "accuracy": 1.0,
      "grad_norm": 0.5578039288520813
    },
    {
      "step": 2151,
      "loss": 0.002051766961812973,
      "accuracy": 1.0,
      "grad_norm": 0.146785169839859
    },
    {
      "step": 2152,
      "loss": 0.018990537151694298,
      "accuracy": 0.9375,
      "grad_norm": 0.822992742061615
    },
    {
      "step": 2153,
      "loss": 0.016625547781586647,
      "accuracy": 1.0,
      "grad_norm": 0.4073157012462616
    },
    {
      "step": 2154,
      "loss": 0.010127832181751728,
      "accuracy": 1.0,
      "grad_norm": 0.6938403844833374
    },
    {
      "step": 2155,
      "loss": 0.010635996237397194,
      "accuracy": 1.0,
      "grad_norm": 0.8914194703102112
    },
    {
      "step": 2156,
      "loss": 0.030801067128777504,
      "accuracy": 0.9375,
      "grad_norm": 0.9588907957077026
    },
    {
      "step": 2157,
      "loss": 0.0033441747073084116,
      "accuracy": 1.0,
      "grad_norm": 0.22231674194335938
    },
    {
      "step": 2158,
      "loss": 0.05698668956756592,
      "accuracy": 0.9375,
      "grad_norm": 0.6848701238632202
    },
    {
      "step": 2159,
      "loss": 0.038506750017404556,
      "accuracy": 0.9375,
      "grad_norm": 1.8782275915145874
    },
    {
      "step": 2160,
      "loss": 0.09232465922832489,
      "accuracy": 0.8125,
      "grad_norm": 3.2918541431427
    },
    {
      "step": 2161,
      "loss": 0.001959382789209485,
      "accuracy": 1.0,
      "grad_norm": 0.10339731723070145
    },
    {
      "step": 2162,
      "loss": 0.034160953015089035,
      "accuracy": 0.9375,
      "grad_norm": 2.0123233795166016
    },
    {
      "step": 2163,
      "loss": 0.011041280813515186,
      "accuracy": 1.0,
      "grad_norm": 0.30667489767074585
    },
    {
      "step": 2164,
      "loss": 0.007512998767197132,
      "accuracy": 1.0,
      "grad_norm": 0.6304613351821899
    },
    {
      "step": 2165,
      "loss": 0.004951354581862688,
      "accuracy": 1.0,
      "grad_norm": 0.27789875864982605
    },
    {
      "step": 2166,
      "loss": 0.06756971776485443,
      "accuracy": 0.9375,
      "grad_norm": 0.549631655216217
    },
    {
      "step": 2167,
      "loss": 0.05405358597636223,
      "accuracy": 0.9375,
      "grad_norm": 1.6548309326171875
    },
    {
      "step": 2168,
      "loss": 0.06903234124183655,
      "accuracy": 0.9375,
      "grad_norm": 1.6219751834869385
    },
    {
      "step": 2169,
      "loss": 0.0017702217446640134,
      "accuracy": 1.0,
      "grad_norm": 0.04354077950119972
    },
    {
      "step": 2170,
      "loss": 0.015572966076433659,
      "accuracy": 0.9375,
      "grad_norm": 0.619412362575531
    },
    {
      "step": 2171,
      "loss": 0.002564791589975357,
      "accuracy": 1.0,
      "grad_norm": 0.13712596893310547
    },
    {
      "step": 2172,
      "loss": 0.002603967674076557,
      "accuracy": 1.0,
      "grad_norm": 0.06278310716152191
    },
    {
      "step": 2173,
      "loss": 0.03137911856174469,
      "accuracy": 0.9375,
      "grad_norm": 1.4610211849212646
    },
    {
      "step": 2174,
      "loss": 0.05652400851249695,
      "accuracy": 0.875,
      "grad_norm": 1.6782763004302979
    },
    {
      "step": 2175,
      "loss": 0.002566714771091938,
      "accuracy": 1.0,
      "grad_norm": 0.08800333738327026
    },
    {
      "step": 2176,
      "loss": 0.004335223697125912,
      "accuracy": 1.0,
      "grad_norm": 0.2020106017589569
    },
    {
      "step": 2177,
      "loss": 0.0032918185461312532,
      "accuracy": 1.0,
      "grad_norm": 0.2571636438369751
    },
    {
      "step": 2178,
      "loss": 0.01805044524371624,
      "accuracy": 0.9375,
      "grad_norm": 1.213176965713501
    },
    {
      "step": 2179,
      "loss": 0.009065182879567146,
      "accuracy": 1.0,
      "grad_norm": 0.45556944608688354
    },
    {
      "step": 2180,
      "loss": 0.00740781519562006,
      "accuracy": 1.0,
      "grad_norm": 0.36466243863105774
    },
    {
      "step": 2181,
      "loss": 0.011527837254106998,
      "accuracy": 1.0,
      "grad_norm": 0.33902907371520996
    },
    {
      "step": 2182,
      "loss": 0.023952579125761986,
      "accuracy": 0.9375,
      "grad_norm": 1.3831135034561157
    },
    {
      "step": 2183,
      "loss": 0.043606046587228775,
      "accuracy": 0.9375,
      "grad_norm": 0.8310048580169678
    },
    {
      "step": 2184,
      "loss": 0.01188728678971529,
      "accuracy": 1.0,
      "grad_norm": 0.8237065076828003
    },
    {
      "step": 2185,
      "loss": 0.03339343145489693,
      "accuracy": 0.9375,
      "grad_norm": 0.8244642615318298
    },
    {
      "step": 2186,
      "loss": 0.004918120335787535,
      "accuracy": 1.0,
      "grad_norm": 0.31718575954437256
    },
    {
      "step": 2187,
      "loss": 0.0033844776917248964,
      "accuracy": 1.0,
      "grad_norm": 0.1319342702627182
    },
    {
      "step": 2188,
      "loss": 0.002659677527844906,
      "accuracy": 1.0,
      "grad_norm": 0.10481354594230652
    },
    {
      "step": 2189,
      "loss": 0.010313860140740871,
      "accuracy": 1.0,
      "grad_norm": 0.5350043177604675
    },
    {
      "step": 2190,
      "loss": 0.007763660047203302,
      "accuracy": 1.0,
      "grad_norm": 0.43169257044792175
    },
    {
      "step": 2191,
      "loss": 0.002945352578535676,
      "accuracy": 1.0,
      "grad_norm": 0.15139417350292206
    },
    {
      "step": 2192,
      "loss": 0.005907674320042133,
      "accuracy": 1.0,
      "grad_norm": 0.3828606605529785
    },
    {
      "step": 2193,
      "loss": 0.008846527896821499,
      "accuracy": 1.0,
      "grad_norm": 0.6955737471580505
    },
    {
      "step": 2194,
      "loss": 0.03799983114004135,
      "accuracy": 0.9375,
      "grad_norm": 1.0489670038223267
    },
    {
      "step": 2195,
      "loss": 0.012507639825344086,
      "accuracy": 0.9375,
      "grad_norm": 1.211464524269104
    },
    {
      "step": 2196,
      "loss": 0.012600306421518326,
      "accuracy": 1.0,
      "grad_norm": 1.3219749927520752
    },
    {
      "step": 2197,
      "loss": 0.04680778831243515,
      "accuracy": 0.9375,
      "grad_norm": 0.7738623023033142
    },
    {
      "step": 2198,
      "loss": 0.019164616242051125,
      "accuracy": 0.9375,
      "grad_norm": 1.2711420059204102
    },
    {
      "step": 2199,
      "loss": 0.0015400672564283013,
      "accuracy": 1.0,
      "grad_norm": 0.07614349573850632
    },
    {
      "step": 2200,
      "loss": 0.0070985713973641396,
      "accuracy": 1.0,
      "grad_norm": 0.26240891218185425
    },
    {
      "step": 2201,
      "loss": 0.0023573872167617083,
      "accuracy": 1.0,
      "grad_norm": 0.1094876155257225
    },
    {
      "step": 2202,
      "loss": 0.011185025796294212,
      "accuracy": 1.0,
      "grad_norm": 1.0874288082122803
    },
    {
      "step": 2203,
      "loss": 0.0027760204393416643,
      "accuracy": 1.0,
      "grad_norm": 0.1483728587627411
    },
    {
      "step": 2204,
      "loss": 0.0005284362123347819,
      "accuracy": 1.0,
      "grad_norm": 0.015646032989025116
    },
    {
      "step": 2205,
      "loss": 0.07741900533437729,
      "accuracy": 0.9375,
      "grad_norm": 0.9981505870819092
    },
    {
      "step": 2206,
      "loss": 0.07398303598165512,
      "accuracy": 0.875,
      "grad_norm": 2.3405137062072754
    },
    {
      "step": 2207,
      "loss": 0.025787105783820152,
      "accuracy": 0.9375,
      "grad_norm": 0.5851367712020874
    },
    {
      "step": 2208,
      "loss": 0.001845718128606677,
      "accuracy": 1.0,
      "grad_norm": 0.04469014331698418
    },
    {
      "step": 2209,
      "loss": 0.009286351501941681,
      "accuracy": 1.0,
      "grad_norm": 0.36285749077796936
    },
    {
      "step": 2210,
      "loss": 0.09878838062286377,
      "accuracy": 0.9375,
      "grad_norm": 0.6556382775306702
    },
    {
      "step": 2211,
      "loss": 0.004765939898788929,
      "accuracy": 1.0,
      "grad_norm": 0.34815680980682373
    },
    {
      "step": 2212,
      "loss": 0.016289277002215385,
      "accuracy": 0.9375,
      "grad_norm": 0.5182704329490662
    },
    {
      "step": 2213,
      "loss": 0.026877207681536674,
      "accuracy": 0.9375,
      "grad_norm": 1.0661696195602417
    },
    {
      "step": 2214,
      "loss": 0.012707514688372612,
      "accuracy": 1.0,
      "grad_norm": 0.3342272639274597
    },
    {
      "step": 2215,
      "loss": 0.012962782755494118,
      "accuracy": 1.0,
      "grad_norm": 0.7423451542854309
    },
    {
      "step": 2216,
      "loss": 0.005059696268290281,
      "accuracy": 1.0,
      "grad_norm": 0.31011003255844116
    },
    {
      "step": 2217,
      "loss": 0.02095133066177368,
      "accuracy": 0.9375,
      "grad_norm": 0.9115163683891296
    },
    {
      "step": 2218,
      "loss": 0.005125344730913639,
      "accuracy": 1.0,
      "grad_norm": 0.3204118609428406
    },
    {
      "step": 2219,
      "loss": 0.008597945794463158,
      "accuracy": 1.0,
      "grad_norm": 0.5444474220275879
    },
    {
      "step": 2220,
      "loss": 0.058258891105651855,
      "accuracy": 0.9375,
      "grad_norm": 1.3025691509246826
    },
    {
      "step": 2221,
      "loss": 0.006071873474866152,
      "accuracy": 1.0,
      "grad_norm": 0.2126113921403885
    },
    {
      "step": 2222,
      "loss": 0.010438242927193642,
      "accuracy": 1.0,
      "grad_norm": 0.47983235120773315
    },
    {
      "step": 2223,
      "loss": 0.051733776926994324,
      "accuracy": 0.9375,
      "grad_norm": 1.0822253227233887
    },
    {
      "step": 2224,
      "loss": 0.008667348884046078,
      "accuracy": 1.0,
      "grad_norm": 0.27054616808891296
    },
    {
      "step": 2225,
      "loss": 0.030678287148475647,
      "accuracy": 0.9375,
      "grad_norm": 1.9833245277404785
    },
    {
      "step": 2226,
      "loss": 0.042741239070892334,
      "accuracy": 0.9375,
      "grad_norm": 1.1799139976501465
    },
    {
      "step": 2227,
      "loss": 0.006356140598654747,
      "accuracy": 1.0,
      "grad_norm": 0.4955059289932251
    },
    {
      "step": 2228,
      "loss": 0.009941049851477146,
      "accuracy": 1.0,
      "grad_norm": 0.5074800252914429
    },
    {
      "step": 2229,
      "loss": 0.049307506531476974,
      "accuracy": 0.9375,
      "grad_norm": 0.4833010733127594
    },
    {
      "step": 2230,
      "loss": 0.022075040265917778,
      "accuracy": 0.9375,
      "grad_norm": 2.245358467102051
    },
    {
      "step": 2231,
      "loss": 0.0016485664527863264,
      "accuracy": 1.0,
      "grad_norm": 0.05216403305530548
    },
    {
      "step": 2232,
      "loss": 0.005283007863909006,
      "accuracy": 1.0,
      "grad_norm": 0.20480036735534668
    },
    {
      "step": 2233,
      "loss": 0.003247215412557125,
      "accuracy": 1.0,
      "grad_norm": 0.10326613485813141
    },
    {
      "step": 2234,
      "loss": 0.004323506262153387,
      "accuracy": 1.0,
      "grad_norm": 0.17246267199516296
    },
    {
      "step": 2235,
      "loss": 0.02415292337536812,
      "accuracy": 0.9375,
      "grad_norm": 0.8765020966529846
    },
    {
      "step": 2236,
      "loss": 0.0029050209559500217,
      "accuracy": 1.0,
      "grad_norm": 0.07596015930175781
    },
    {
      "step": 2237,
      "loss": 0.041436389088630676,
      "accuracy": 0.9375,
      "grad_norm": 2.670499324798584
    },
    {
      "step": 2238,
      "loss": 0.005716841202229261,
      "accuracy": 1.0,
      "grad_norm": 0.30834129452705383
    },
    {
      "step": 2239,
      "loss": 0.012148702517151833,
      "accuracy": 1.0,
      "grad_norm": 0.9931378960609436
    },
    {
      "step": 2240,
      "loss": 0.009877985343337059,
      "accuracy": 1.0,
      "grad_norm": 0.9178074598312378
    },
    {
      "step": 2241,
      "loss": 0.003628829261288047,
      "accuracy": 1.0,
      "grad_norm": 0.17355240881443024
    },
    {
      "step": 2242,
      "loss": 0.0026937569491565228,
      "accuracy": 1.0,
      "grad_norm": 0.1688130497932434
    },
    {
      "step": 2243,
      "loss": 0.022505510598421097,
      "accuracy": 0.9375,
      "grad_norm": 1.2911889553070068
    },
    {
      "step": 2244,
      "loss": 0.001616300898604095,
      "accuracy": 1.0,
      "grad_norm": 0.06102340668439865
    },
    {
      "step": 2245,
      "loss": 0.0007161191897466779,
      "accuracy": 1.0,
      "grad_norm": 0.020546231418848038
    },
    {
      "step": 2246,
      "loss": 0.004435257986187935,
      "accuracy": 1.0,
      "grad_norm": 0.22045086324214935
    },
    {
      "step": 2247,
      "loss": 0.006221006624400616,
      "accuracy": 1.0,
      "grad_norm": 0.4751335084438324
    },
    {
      "step": 2248,
      "loss": 0.002666573505848646,
      "accuracy": 1.0,
      "grad_norm": 0.09529776126146317
    },
    {
      "step": 2249,
      "loss": 0.0014385785907506943,
      "accuracy": 1.0,
      "grad_norm": 0.051036857068538666
    },
    {
      "step": 2250,
      "loss": 0.0007953072781674564,
      "accuracy": 1.0,
      "grad_norm": 0.03463847562670708
    },
    {
      "step": 2251,
      "loss": 0.009252838790416718,
      "accuracy": 1.0,
      "grad_norm": 0.5568487644195557
    },
    {
      "step": 2252,
      "loss": 0.0012683103559538722,
      "accuracy": 1.0,
      "grad_norm": 0.03299393877387047
    },
    {
      "step": 2253,
      "loss": 0.009326310828328133,
      "accuracy": 1.0,
      "grad_norm": 1.4584648609161377
    },
    {
      "step": 2254,
      "loss": 0.0010465704835951328,
      "accuracy": 1.0,
      "grad_norm": 0.04336768388748169
    },
    {
      "step": 2255,
      "loss": 0.0031440204475075006,
      "accuracy": 1.0,
      "grad_norm": 0.1588679552078247
    },
    {
      "step": 2256,
      "loss": 0.0013187750009819865,
      "accuracy": 1.0,
      "grad_norm": 0.13984540104866028
    },
    {
      "step": 2257,
      "loss": 0.00036476130480878055,
      "accuracy": 1.0,
      "grad_norm": 0.005143656395375729
    },
    {
      "step": 2258,
      "loss": 0.05327983573079109,
      "accuracy": 0.9375,
      "grad_norm": 2.618488073348999
    },
    {
      "step": 2259,
      "loss": 0.0015280661173164845,
      "accuracy": 1.0,
      "grad_norm": 0.06923644989728928
    },
    {
      "step": 2260,
      "loss": 0.01441271137446165,
      "accuracy": 0.9375,
      "grad_norm": 2.1540257930755615
    },
    {
      "step": 2261,
      "loss": 0.0005563799059018493,
      "accuracy": 1.0,
      "grad_norm": 0.016022460535168648
    },
    {
      "step": 2262,
      "loss": 0.0012335453648120165,
      "accuracy": 1.0,
      "grad_norm": 0.07070527970790863
    },
    {
      "step": 2263,
      "loss": 0.0004060505307279527,
      "accuracy": 1.0,
      "grad_norm": 0.006405541207641363
    },
    {
      "step": 2264,
      "loss": 0.08703052252531052,
      "accuracy": 0.875,
      "grad_norm": 2.5062882900238037
    },
    {
      "step": 2265,
      "loss": 0.0013730940409004688,
      "accuracy": 1.0,
      "grad_norm": 0.08741798251867294
    },
    {
      "step": 2266,
      "loss": 0.003530567977577448,
      "accuracy": 1.0,
      "grad_norm": 0.35202327370643616
    },
    {
      "step": 2267,
      "loss": 0.008808755315840244,
      "accuracy": 1.0,
      "grad_norm": 0.8626989126205444
    },
    {
      "step": 2268,
      "loss": 0.004346921108663082,
      "accuracy": 1.0,
      "grad_norm": 0.5594269037246704
    },
    {
      "step": 2269,
      "loss": 0.0006562648923136294,
      "accuracy": 1.0,
      "grad_norm": 0.04093658924102783
    },
    {
      "step": 2270,
      "loss": 0.001493790652602911,
      "accuracy": 1.0,
      "grad_norm": 0.1322919875383377
    },
    {
      "step": 2271,
      "loss": 0.0006483981851488352,
      "accuracy": 1.0,
      "grad_norm": 0.017483090981841087
    },
    {
      "step": 2272,
      "loss": 0.001023931778036058,
      "accuracy": 1.0,
      "grad_norm": 0.10099619626998901
    },
    {
      "step": 2273,
      "loss": 0.0072097089141607285,
      "accuracy": 1.0,
      "grad_norm": 1.2875994443893433
    },
    {
      "step": 2274,
      "loss": 0.0009923336328938603,
      "accuracy": 1.0,
      "grad_norm": 0.048205044120550156
    },
    {
      "step": 2275,
      "loss": 0.11111997067928314,
      "accuracy": 0.875,
      "grad_norm": 2.588536262512207
    },
    {
      "step": 2276,
      "loss": 0.0005617011920548975,
      "accuracy": 1.0,
      "grad_norm": 0.034200772643089294
    },
    {
      "step": 2277,
      "loss": 0.050534576177597046,
      "accuracy": 0.9375,
      "grad_norm": 1.6186628341674805
    },
    {
      "step": 2278,
      "loss": 0.010277300141751766,
      "accuracy": 1.0,
      "grad_norm": 1.489530086517334
    },
    {
      "step": 2279,
      "loss": 0.02517768181860447,
      "accuracy": 0.875,
      "grad_norm": 2.5759336948394775
    },
    {
      "step": 2280,
      "loss": 0.001578578376211226,
      "accuracy": 1.0,
      "grad_norm": 0.1287730634212494
    },
    {
      "step": 2281,
      "loss": 0.0007274812087416649,
      "accuracy": 1.0,
      "grad_norm": 0.026730414479970932
    },
    {
      "step": 2282,
      "loss": 0.05361796170473099,
      "accuracy": 0.9375,
      "grad_norm": 1.8625102043151855
    },
    {
      "step": 2283,
      "loss": 0.09037609398365021,
      "accuracy": 0.9375,
      "grad_norm": 1.917249321937561
    },
    {
      "step": 2284,
      "loss": 0.031019775196909904,
      "accuracy": 0.9375,
      "grad_norm": 2.4555206298828125
    },
    {
      "step": 2285,
      "loss": 0.0029329725075513124,
      "accuracy": 1.0,
      "grad_norm": 0.11424270272254944
    },
    {
      "step": 2286,
      "loss": 0.0006833662046119571,
      "accuracy": 1.0,
      "grad_norm": 0.01615585945546627
    },
    {
      "step": 2287,
      "loss": 0.0012407093308866024,
      "accuracy": 1.0,
      "grad_norm": 0.09393831342458725
    },
    {
      "step": 2288,
      "loss": 0.005526730790734291,
      "accuracy": 1.0,
      "grad_norm": 0.3649667799472809
    },
    {
      "step": 2289,
      "loss": 0.003367687575519085,
      "accuracy": 1.0,
      "grad_norm": 0.3615838289260864
    },
    {
      "step": 2290,
      "loss": 0.0009488147916272283,
      "accuracy": 1.0,
      "grad_norm": 0.041064660996198654
    },
    {
      "step": 2291,
      "loss": 0.02709546685218811,
      "accuracy": 0.9375,
      "grad_norm": 3.358828067779541
    },
    {
      "step": 2292,
      "loss": 0.04674910381436348,
      "accuracy": 0.9375,
      "grad_norm": 0.9870946407318115
    },
    {
      "step": 2293,
      "loss": 0.043089985847473145,
      "accuracy": 0.9375,
      "grad_norm": 3.8194518089294434
    },
    {
      "step": 2294,
      "loss": 0.00038505677366629243,
      "accuracy": 1.0,
      "grad_norm": 0.01939012110233307
    },
    {
      "step": 2295,
      "loss": 0.02490926906466484,
      "accuracy": 0.9375,
      "grad_norm": 1.005516529083252
    },
    {
      "step": 2296,
      "loss": 0.019835785031318665,
      "accuracy": 0.9375,
      "grad_norm": 0.7408355474472046
    },
    {
      "step": 2297,
      "loss": 0.0009469555225223303,
      "accuracy": 1.0,
      "grad_norm": 0.08783373981714249
    },
    {
      "step": 2298,
      "loss": 0.00288890628144145,
      "accuracy": 1.0,
      "grad_norm": 0.34431222081184387
    },
    {
      "step": 2299,
      "loss": 0.0030833324417471886,
      "accuracy": 1.0,
      "grad_norm": 0.1919705718755722
    },
    {
      "step": 2300,
      "loss": 0.005026467144489288,
      "accuracy": 1.0,
      "grad_norm": 0.31502091884613037
    },
    {
      "step": 2301,
      "loss": 0.00327158416621387,
      "accuracy": 1.0,
      "grad_norm": 0.11393558979034424
    },
    {
      "step": 2302,
      "loss": 0.0019708015024662018,
      "accuracy": 1.0,
      "grad_norm": 0.059261105954647064
    },
    {
      "step": 2303,
      "loss": 0.0009512763936072588,
      "accuracy": 1.0,
      "grad_norm": 0.025036310777068138
    },
    {
      "step": 2304,
      "loss": 0.03405114635825157,
      "accuracy": 0.875,
      "grad_norm": 2.3963847160339355
    },
    {
      "step": 2305,
      "loss": 0.0014629547949880362,
      "accuracy": 1.0,
      "grad_norm": 0.05264734476804733
    },
    {
      "step": 2306,
      "loss": 0.001958910608664155,
      "accuracy": 1.0,
      "grad_norm": 0.15488411486148834
    },
    {
      "step": 2307,
      "loss": 0.0012713458854705095,
      "accuracy": 1.0,
      "grad_norm": 0.09113957732915878
    },
    {
      "step": 2308,
      "loss": 0.003349182428792119,
      "accuracy": 1.0,
      "grad_norm": 0.16782450675964355
    },
    {
      "step": 2309,
      "loss": 0.0064486307092010975,
      "accuracy": 1.0,
      "grad_norm": 0.446257084608078
    },
    {
      "step": 2310,
      "loss": 0.0025661790277808905,
      "accuracy": 1.0,
      "grad_norm": 0.15245556831359863
    },
    {
      "step": 2311,
      "loss": 0.018871350213885307,
      "accuracy": 1.0,
      "grad_norm": 0.6782659888267517
    },
    {
      "step": 2312,
      "loss": 0.061176348477602005,
      "accuracy": 0.9375,
      "grad_norm": 2.3937933444976807
    },
    {
      "step": 2313,
      "loss": 0.01590815745294094,
      "accuracy": 0.9375,
      "grad_norm": 1.8730727434158325
    },
    {
      "step": 2314,
      "loss": 0.0011141272261738777,
      "accuracy": 1.0,
      "grad_norm": 0.04580776020884514
    },
    {
      "step": 2315,
      "loss": 0.0016984510002657771,
      "accuracy": 1.0,
      "grad_norm": 0.14050622284412384
    },
    {
      "step": 2316,
      "loss": 0.010420404374599457,
      "accuracy": 1.0,
      "grad_norm": 0.5067546367645264
    },
    {
      "step": 2317,
      "loss": 0.0005576488329097629,
      "accuracy": 1.0,
      "grad_norm": 0.017845356836915016
    },
    {
      "step": 2318,
      "loss": 0.1442529857158661,
      "accuracy": 0.875,
      "grad_norm": 2.2688910961151123
    },
    {
      "step": 2319,
      "loss": 0.0013556882040575147,
      "accuracy": 1.0,
      "grad_norm": 0.06460423767566681
    },
    {
      "step": 2320,
      "loss": 0.003818176221102476,
      "accuracy": 1.0,
      "grad_norm": 0.1785588562488556
    },
    {
      "step": 2321,
      "loss": 0.004490816034376621,
      "accuracy": 1.0,
      "grad_norm": 0.4186379313468933
    },
    {
      "step": 2322,
      "loss": 0.0012781283585354686,
      "accuracy": 1.0,
      "grad_norm": 0.059019267559051514
    },
    {
      "step": 2323,
      "loss": 0.0015504597686231136,
      "accuracy": 1.0,
      "grad_norm": 0.049693576991558075
    },
    {
      "step": 2324,
      "loss": 0.010180918499827385,
      "accuracy": 1.0,
      "grad_norm": 1.7775541543960571
    },
    {
      "step": 2325,
      "loss": 0.022038297727704048,
      "accuracy": 0.9375,
      "grad_norm": 1.449203372001648
    },
    {
      "step": 2326,
      "loss": 0.001039477763697505,
      "accuracy": 1.0,
      "grad_norm": 0.051763441413640976
    },
    {
      "step": 2327,
      "loss": 0.002114915056154132,
      "accuracy": 1.0,
      "grad_norm": 0.11968406289815903
    },
    {
      "step": 2328,
      "loss": 0.005204740911722183,
      "accuracy": 1.0,
      "grad_norm": 0.8760929107666016
    },
    {
      "step": 2329,
      "loss": 0.0014173182426020503,
      "accuracy": 1.0,
      "grad_norm": 0.18489322066307068
    },
    {
      "step": 2330,
      "loss": 0.009255990386009216,
      "accuracy": 1.0,
      "grad_norm": 1.6238700151443481
    },
    {
      "step": 2331,
      "loss": 0.0021779965609312057,
      "accuracy": 1.0,
      "grad_norm": 0.4334433376789093
    },
    {
      "step": 2332,
      "loss": 0.10391861945390701,
      "accuracy": 0.875,
      "grad_norm": 4.812789440155029
    },
    {
      "step": 2333,
      "loss": 0.007750792428851128,
      "accuracy": 1.0,
      "grad_norm": 1.1190989017486572
    },
    {
      "step": 2334,
      "loss": 0.001047931145876646,
      "accuracy": 1.0,
      "grad_norm": 0.09537184238433838
    },
    {
      "step": 2335,
      "loss": 0.03586145490407944,
      "accuracy": 0.9375,
      "grad_norm": 1.040012240409851
    },
    {
      "step": 2336,
      "loss": 0.0010027644457295537,
      "accuracy": 1.0,
      "grad_norm": 0.09426026046276093
    },
    {
      "step": 2337,
      "loss": 0.011715726926922798,
      "accuracy": 0.9375,
      "grad_norm": 0.9398778676986694
    },
    {
      "step": 2338,
      "loss": 0.003356099594384432,
      "accuracy": 1.0,
      "grad_norm": 0.36547404527664185
    },
    {
      "step": 2339,
      "loss": 0.007970871403813362,
      "accuracy": 1.0,
      "grad_norm": 0.6622194051742554
    },
    {
      "step": 2340,
      "loss": 0.03500358387827873,
      "accuracy": 0.9375,
      "grad_norm": 3.2786083221435547
    },
    {
      "step": 2341,
      "loss": 0.003946402575820684,
      "accuracy": 1.0,
      "grad_norm": 0.3087335526943207
    },
    {
      "step": 2342,
      "loss": 0.0004404320497997105,
      "accuracy": 1.0,
      "grad_norm": 0.010040055960416794
    },
    {
      "step": 2343,
      "loss": 0.018536211922764778,
      "accuracy": 0.9375,
      "grad_norm": 0.938758134841919
    },
    {
      "step": 2344,
      "loss": 0.0013262422289699316,
      "accuracy": 1.0,
      "grad_norm": 0.15489836037158966
    },
    {
      "step": 2345,
      "loss": 0.03891988843679428,
      "accuracy": 0.9375,
      "grad_norm": 1.7049428224563599
    },
    {
      "step": 2346,
      "loss": 0.012230451218783855,
      "accuracy": 1.0,
      "grad_norm": 1.663022518157959
    },
    {
      "step": 2347,
      "loss": 0.0009033633396029472,
      "accuracy": 1.0,
      "grad_norm": 0.021564435213804245
    },
    {
      "step": 2348,
      "loss": 0.0028919640462845564,
      "accuracy": 1.0,
      "grad_norm": 0.20991618931293488
    },
    {
      "step": 2349,
      "loss": 0.0011146520264446735,
      "accuracy": 1.0,
      "grad_norm": 0.05945250019431114
    },
    {
      "step": 2350,
      "loss": 0.003002135083079338,
      "accuracy": 1.0,
      "grad_norm": 0.4327971935272217
    },
    {
      "step": 2351,
      "loss": 0.03941787779331207,
      "accuracy": 0.9375,
      "grad_norm": 1.4393364191055298
    },
    {
      "step": 2352,
      "loss": 0.008084605447947979,
      "accuracy": 1.0,
      "grad_norm": 0.9139314889907837
    },
    {
      "step": 2353,
      "loss": 0.027336202561855316,
      "accuracy": 0.9375,
      "grad_norm": 0.9521813988685608
    },
    {
      "step": 2354,
      "loss": 0.0013478976907208562,
      "accuracy": 1.0,
      "grad_norm": 0.06992560625076294
    },
    {
      "step": 2355,
      "loss": 0.014615979045629501,
      "accuracy": 1.0,
      "grad_norm": 1.0662435293197632
    },
    {
      "step": 2356,
      "loss": 0.00046139350160956383,
      "accuracy": 1.0,
      "grad_norm": 0.00972138810902834
    },
    {
      "step": 2357,
      "loss": 0.0031099847983568907,
      "accuracy": 1.0,
      "grad_norm": 0.26773250102996826
    },
    {
      "step": 2358,
      "loss": 0.001084612333215773,
      "accuracy": 1.0,
      "grad_norm": 0.05515342205762863
    },
    {
      "step": 2359,
      "loss": 0.00754476897418499,
      "accuracy": 1.0,
      "grad_norm": 1.4655534029006958
    },
    {
      "step": 2360,
      "loss": 0.0020228030625730753,
      "accuracy": 1.0,
      "grad_norm": 0.08275087922811508
    },
    {
      "step": 2361,
      "loss": 0.0011360622011125088,
      "accuracy": 1.0,
      "grad_norm": 0.04795464500784874
    },
    {
      "step": 2362,
      "loss": 0.13776376843452454,
      "accuracy": 0.875,
      "grad_norm": 3.6491150856018066
    },
    {
      "step": 2363,
      "loss": 0.000349257345078513,
      "accuracy": 1.0,
      "grad_norm": 0.009883477352559566
    },
    {
      "step": 2364,
      "loss": 0.008340769447386265,
      "accuracy": 1.0,
      "grad_norm": 0.9337418675422668
    },
    {
      "step": 2365,
      "loss": 0.009104378521442413,
      "accuracy": 1.0,
      "grad_norm": 0.3645249903202057
    },
    {
      "step": 2366,
      "loss": 0.0007769115618430078,
      "accuracy": 1.0,
      "grad_norm": 0.02054406888782978
    },
    {
      "step": 2367,
      "loss": 0.030056023970246315,
      "accuracy": 0.9375,
      "grad_norm": 2.5370776653289795
    },
    {
      "step": 2368,
      "loss": 0.0005984831950627267,
      "accuracy": 1.0,
      "grad_norm": 0.02464553900063038
    },
    {
      "step": 2369,
      "loss": 0.0035685242619365454,
      "accuracy": 1.0,
      "grad_norm": 0.12493816018104553
    },
    {
      "step": 2370,
      "loss": 0.0008247059886343777,
      "accuracy": 1.0,
      "grad_norm": 0.024048296734690666
    },
    {
      "step": 2371,
      "loss": 0.0006582770147360861,
      "accuracy": 1.0,
      "grad_norm": 0.024569116532802582
    },
    {
      "step": 2372,
      "loss": 0.004071804229170084,
      "accuracy": 1.0,
      "grad_norm": 0.2505771815776825
    },
    {
      "step": 2373,
      "loss": 0.0035334452986717224,
      "accuracy": 1.0,
      "grad_norm": 0.3089149594306946
    },
    {
      "step": 2374,
      "loss": 0.007986584678292274,
      "accuracy": 1.0,
      "grad_norm": 1.466266393661499
    },
    {
      "step": 2375,
      "loss": 0.0022950584534555674,
      "accuracy": 1.0,
      "grad_norm": 0.2033511996269226
    },
    {
      "step": 2376,
      "loss": 0.001170613570138812,
      "accuracy": 1.0,
      "grad_norm": 0.09898742288351059
    },
    {
      "step": 2377,
      "loss": 0.05275542661547661,
      "accuracy": 0.9375,
      "grad_norm": 3.278902530670166
    },
    {
      "step": 2378,
      "loss": 0.013865482062101364,
      "accuracy": 0.9375,
      "grad_norm": 0.2570481300354004
    },
    {
      "step": 2379,
      "loss": 0.002055424964055419,
      "accuracy": 1.0,
      "grad_norm": 0.102024607360363
    },
    {
      "step": 2380,
      "loss": 0.001971857389435172,
      "accuracy": 1.0,
      "grad_norm": 0.2157808244228363
    },
    {
      "step": 2381,
      "loss": 0.004018875770270824,
      "accuracy": 1.0,
      "grad_norm": 0.6200722455978394
    },
    {
      "step": 2382,
      "loss": 0.002437000162899494,
      "accuracy": 1.0,
      "grad_norm": 0.10366223007440567
    },
    {
      "step": 2383,
      "loss": 0.0013219586107879877,
      "accuracy": 1.0,
      "grad_norm": 0.04756835103034973
    },
    {
      "step": 2384,
      "loss": 0.06497853994369507,
      "accuracy": 0.9375,
      "grad_norm": 1.8814336061477661
    },
    {
      "step": 2385,
      "loss": 0.002651667222380638,
      "accuracy": 1.0,
      "grad_norm": 0.2783549129962921
    },
    {
      "step": 2386,
      "loss": 0.0006129035609774292,
      "accuracy": 1.0,
      "grad_norm": 0.025186114013195038
    },
    {
      "step": 2387,
      "loss": 0.04116755351424217,
      "accuracy": 0.9375,
      "grad_norm": 3.2071986198425293
    },
    {
      "step": 2388,
      "loss": 0.015464230440557003,
      "accuracy": 1.0,
      "grad_norm": 2.343273401260376
    },
    {
      "step": 2389,
      "loss": 0.012409660033881664,
      "accuracy": 0.9375,
      "grad_norm": 0.3245083689689636
    },
    {
      "step": 2390,
      "loss": 0.0034214213956147432,
      "accuracy": 1.0,
      "grad_norm": 0.24713216722011566
    },
    {
      "step": 2391,
      "loss": 0.0015913557726889849,
      "accuracy": 1.0,
      "grad_norm": 0.10423479229211807
    },
    {
      "step": 2392,
      "loss": 0.002702327910810709,
      "accuracy": 1.0,
      "grad_norm": 0.17266222834587097
    },
    {
      "step": 2393,
      "loss": 0.0007667901809327304,
      "accuracy": 1.0,
      "grad_norm": 0.027149708941578865
    },
    {
      "step": 2394,
      "loss": 0.001238222816027701,
      "accuracy": 1.0,
      "grad_norm": 0.12171803414821625
    },
    {
      "step": 2395,
      "loss": 0.008126373402774334,
      "accuracy": 1.0,
      "grad_norm": 0.7835915684700012
    },
    {
      "step": 2396,
      "loss": 0.0005541321006603539,
      "accuracy": 1.0,
      "grad_norm": 0.022397480905056
    },
    {
      "step": 2397,
      "loss": 0.0008693240815773606,
      "accuracy": 1.0,
      "grad_norm": 0.031457457691431046
    },
    {
      "step": 2398,
      "loss": 0.0006964203785173595,
      "accuracy": 1.0,
      "grad_norm": 0.037563931196928024
    },
    {
      "step": 2399,
      "loss": 0.017221637070178986,
      "accuracy": 0.9375,
      "grad_norm": 2.897984743118286
    },
    {
      "step": 2400,
      "loss": 0.019023273140192032,
      "accuracy": 0.9375,
      "grad_norm": 2.868821144104004
    },
    {
      "step": 2401,
      "loss": 0.0013030924601480365,
      "accuracy": 1.0,
      "grad_norm": 0.052258871495723724
    },
    {
      "step": 2402,
      "loss": 0.018930375576019287,
      "accuracy": 0.9375,
      "grad_norm": 1.1539928913116455
    },
    {
      "step": 2403,
      "loss": 0.008672239258885384,
      "accuracy": 1.0,
      "grad_norm": 0.6191197633743286
    },
    {
      "step": 2404,
      "loss": 0.015336224809288979,
      "accuracy": 0.9375,
      "grad_norm": 0.4717046618461609
    },
    {
      "step": 2405,
      "loss": 0.020371753722429276,
      "accuracy": 0.9375,
      "grad_norm": 3.0511269569396973
    },
    {
      "step": 2406,
      "loss": 0.0007349037914536893,
      "accuracy": 1.0,
      "grad_norm": 0.026786020025610924
    },
    {
      "step": 2407,
      "loss": 0.009794842451810837,
      "accuracy": 1.0,
      "grad_norm": 0.9341618418693542
    },
    {
      "step": 2408,
      "loss": 0.0004500309587456286,
      "accuracy": 1.0,
      "grad_norm": 0.02741176262497902
    },
    {
      "step": 2409,
      "loss": 0.001331616542302072,
      "accuracy": 1.0,
      "grad_norm": 0.0702807754278183
    },
    {
      "step": 2410,
      "loss": 0.07986549288034439,
      "accuracy": 0.875,
      "grad_norm": 3.7829110622406006
    },
    {
      "step": 2411,
      "loss": 0.005169350653886795,
      "accuracy": 1.0,
      "grad_norm": 0.2929401099681854
    },
    {
      "step": 2412,
      "loss": 0.0004487092373892665,
      "accuracy": 1.0,
      "grad_norm": 0.01076473481953144
    },
    {
      "step": 2413,
      "loss": 0.0016309635248035192,
      "accuracy": 1.0,
      "grad_norm": 0.10727888345718384
    },
    {
      "step": 2414,
      "loss": 0.0005049007595516741,
      "accuracy": 1.0,
      "grad_norm": 0.010542265139520168
    },
    {
      "step": 2415,
      "loss": 0.004191041458398104,
      "accuracy": 1.0,
      "grad_norm": 0.24300234019756317
    },
    {
      "step": 2416,
      "loss": 0.00112915167119354,
      "accuracy": 1.0,
      "grad_norm": 0.08508958667516708
    },
    {
      "step": 2417,
      "loss": 0.00031882667099125683,
      "accuracy": 1.0,
      "grad_norm": 0.0048192162066698074
    },
    {
      "step": 2418,
      "loss": 0.0030485617462545633,
      "accuracy": 1.0,
      "grad_norm": 0.6476857662200928
    },
    {
      "step": 2419,
      "loss": 0.0007493398734368384,
      "accuracy": 1.0,
      "grad_norm": 0.02473326213657856
    },
    {
      "step": 2420,
      "loss": 0.10263095051050186,
      "accuracy": 0.9375,
      "grad_norm": 1.3192408084869385
    },
    {
      "step": 2421,
      "loss": 0.00038740530726499856,
      "accuracy": 1.0,
      "grad_norm": 0.010813320986926556
    },
    {
      "step": 2422,
      "loss": 0.0007442283094860613,
      "accuracy": 1.0,
      "grad_norm": 0.03044695407152176
    },
    {
      "step": 2423,
      "loss": 0.0005116016254760325,
      "accuracy": 1.0,
      "grad_norm": 0.018939947709441185
    },
    {
      "step": 2424,
      "loss": 0.0005317050381563604,
      "accuracy": 1.0,
      "grad_norm": 0.017838720232248306
    },
    {
      "step": 2425,
      "loss": 0.0012327124131843448,
      "accuracy": 1.0,
      "grad_norm": 0.07731491327285767
    },
    {
      "step": 2426,
      "loss": 0.004003387875854969,
      "accuracy": 1.0,
      "grad_norm": 0.6698145866394043
    },
    {
      "step": 2427,
      "loss": 0.028427349403500557,
      "accuracy": 0.9375,
      "grad_norm": 1.276255488395691
    },
    {
      "step": 2428,
      "loss": 0.00043693138286471367,
      "accuracy": 1.0,
      "grad_norm": 0.015071619302034378
    },
    {
      "step": 2429,
      "loss": 0.0004259614506736398,
      "accuracy": 1.0,
      "grad_norm": 0.01570669189095497
    },
    {
      "step": 2430,
      "loss": 0.08761371672153473,
      "accuracy": 0.9375,
      "grad_norm": 1.8719607591629028
    },
    {
      "step": 2431,
      "loss": 0.0015925312181934714,
      "accuracy": 1.0,
      "grad_norm": 0.16826993227005005
    },
    {
      "step": 2432,
      "loss": 0.14861547946929932,
      "accuracy": 0.875,
      "grad_norm": 3.465522527694702
    },
    {
      "step": 2433,
      "loss": 0.000699905096553266,
      "accuracy": 1.0,
      "grad_norm": 0.01852896437048912
    },
    {
      "step": 2434,
      "loss": 0.001086738076992333,
      "accuracy": 1.0,
      "grad_norm": 0.051446583122015
    },
    {
      "step": 2435,
      "loss": 0.06215313822031021,
      "accuracy": 0.9375,
      "grad_norm": 1.0387849807739258
    },
    {
      "step": 2436,
      "loss": 0.040386732667684555,
      "accuracy": 0.9375,
      "grad_norm": 1.0856423377990723
    },
    {
      "step": 2437,
      "loss": 0.011393280699849129,
      "accuracy": 0.9375,
      "grad_norm": 1.9558604955673218
    },
    {
      "step": 2438,
      "loss": 0.00572251807898283,
      "accuracy": 1.0,
      "grad_norm": 0.8087037801742554
    },
    {
      "step": 2439,
      "loss": 0.0003626110847108066,
      "accuracy": 1.0,
      "grad_norm": 0.01175124291330576
    },
    {
      "step": 2440,
      "loss": 0.012597616761922836,
      "accuracy": 1.0,
      "grad_norm": 1.0391616821289062
    },
    {
      "step": 2441,
      "loss": 0.005595406051725149,
      "accuracy": 1.0,
      "grad_norm": 0.634740948677063
    },
    {
      "step": 2442,
      "loss": 0.0008813717868179083,
      "accuracy": 1.0,
      "grad_norm": 0.07141454517841339
    },
    {
      "step": 2443,
      "loss": 0.0017700176686048508,
      "accuracy": 1.0,
      "grad_norm": 0.08799318969249725
    },
    {
      "step": 2444,
      "loss": 0.015116679482161999,
      "accuracy": 0.9375,
      "grad_norm": 1.5194731950759888
    },
    {
      "step": 2445,
      "loss": 0.00043552284478209913,
      "accuracy": 1.0,
      "grad_norm": 0.008808138780295849
    },
    {
      "step": 2446,
      "loss": 0.015340348705649376,
      "accuracy": 0.9375,
      "grad_norm": 0.7868056893348694
    },
    {
      "step": 2447,
      "loss": 0.0018408916657790542,
      "accuracy": 1.0,
      "grad_norm": 0.12253589183092117
    },
    {
      "step": 2448,
      "loss": 0.0013091384898871183,
      "accuracy": 1.0,
      "grad_norm": 0.04987984523177147
    },
    {
      "step": 2449,
      "loss": 0.011552746407687664,
      "accuracy": 1.0,
      "grad_norm": 0.4794519543647766
    },
    {
      "step": 2450,
      "loss": 0.002723191399127245,
      "accuracy": 1.0,
      "grad_norm": 0.18773998320102692
    },
    {
      "step": 2451,
      "loss": 0.0016904155490919948,
      "accuracy": 1.0,
      "grad_norm": 0.13790374994277954
    },
    {
      "step": 2452,
      "loss": 0.0011131338542327285,
      "accuracy": 1.0,
      "grad_norm": 0.05397835746407509
    },
    {
      "step": 2453,
      "loss": 0.001997812418267131,
      "accuracy": 1.0,
      "grad_norm": 0.13582195341587067
    },
    {
      "step": 2454,
      "loss": 0.0007003171485848725,
      "accuracy": 1.0,
      "grad_norm": 0.023618284612894058
    },
    {
      "step": 2455,
      "loss": 0.012900898233056068,
      "accuracy": 1.0,
      "grad_norm": 0.7508792877197266
    },
    {
      "step": 2456,
      "loss": 0.01236377377063036,
      "accuracy": 1.0,
      "grad_norm": 0.40897899866104126
    },
    {
      "step": 2457,
      "loss": 0.016863971948623657,
      "accuracy": 0.9375,
      "grad_norm": 0.48919665813446045
    },
    {
      "step": 2458,
      "loss": 0.0009230397990904748,
      "accuracy": 1.0,
      "grad_norm": 0.029273154214024544
    },
    {
      "step": 2459,
      "loss": 0.003272052388638258,
      "accuracy": 1.0,
      "grad_norm": 0.2065955400466919
    },
    {
      "step": 2460,
      "loss": 0.02140985056757927,
      "accuracy": 0.9375,
      "grad_norm": 1.8886709213256836
    },
    {
      "step": 2461,
      "loss": 0.0006337028462439775,
      "accuracy": 1.0,
      "grad_norm": 0.015426925383508205
    },
    {
      "step": 2462,
      "loss": 0.0061323996633291245,
      "accuracy": 1.0,
      "grad_norm": 0.28263455629348755
    },
    {
      "step": 2463,
      "loss": 0.0017664753831923008,
      "accuracy": 1.0,
      "grad_norm": 0.08343936502933502
    },
    {
      "step": 2464,
      "loss": 0.0009614573791623116,
      "accuracy": 1.0,
      "grad_norm": 0.04142303764820099
    },
    {
      "step": 2465,
      "loss": 0.001369074801914394,
      "accuracy": 1.0,
      "grad_norm": 0.08221907168626785
    },
    {
      "step": 2466,
      "loss": 0.0014928460586816072,
      "accuracy": 1.0,
      "grad_norm": 0.1336769014596939
    },
    {
      "step": 2467,
      "loss": 0.00026523449923843145,
      "accuracy": 1.0,
      "grad_norm": 0.0046350969932973385
    },
    {
      "step": 2468,
      "loss": 0.0014696229482069612,
      "accuracy": 1.0,
      "grad_norm": 0.16185849905014038
    },
    {
      "step": 2469,
      "loss": 0.035739440470933914,
      "accuracy": 0.9375,
      "grad_norm": 3.2159628868103027
    },
    {
      "step": 2470,
      "loss": 0.024818213656544685,
      "accuracy": 0.875,
      "grad_norm": 1.4294441938400269
    },
    {
      "step": 2471,
      "loss": 0.0007762074819765985,
      "accuracy": 1.0,
      "grad_norm": 0.038308680057525635
    },
    {
      "step": 2472,
      "loss": 0.0003366252058185637,
      "accuracy": 1.0,
      "grad_norm": 0.008792120963335037
    },
    {
      "step": 2473,
      "loss": 0.0006738243973813951,
      "accuracy": 1.0,
      "grad_norm": 0.03053351119160652
    },
    {
      "step": 2474,
      "loss": 0.0021478887647390366,
      "accuracy": 1.0,
      "grad_norm": 0.2095978707075119
    },
    {
      "step": 2475,
      "loss": 0.0107366181910038,
      "accuracy": 1.0,
      "grad_norm": 0.5977238416671753
    },
    {
      "step": 2476,
      "loss": 0.000916730088647455,
      "accuracy": 1.0,
      "grad_norm": 0.04542890563607216
    },
    {
      "step": 2477,
      "loss": 0.052347876131534576,
      "accuracy": 0.9375,
      "grad_norm": 1.406921625137329
    },
    {
      "step": 2478,
      "loss": 0.0009780992986634374,
      "accuracy": 1.0,
      "grad_norm": 0.1487169712781906
    },
    {
      "step": 2479,
      "loss": 0.005444840062409639,
      "accuracy": 1.0,
      "grad_norm": 1.0817196369171143
    },
    {
      "step": 2480,
      "loss": 0.021407149732112885,
      "accuracy": 0.9375,
      "grad_norm": 3.0513155460357666
    },
    {
      "step": 2481,
      "loss": 0.004957967437803745,
      "accuracy": 1.0,
      "grad_norm": 0.970088541507721
    },
    {
      "step": 2482,
      "loss": 0.00038168716127984226,
      "accuracy": 1.0,
      "grad_norm": 0.011756405234336853
    },
    {
      "step": 2483,
      "loss": 0.0007818982703611255,
      "accuracy": 1.0,
      "grad_norm": 0.03944239020347595
    },
    {
      "step": 2484,
      "loss": 0.007432790473103523,
      "accuracy": 1.0,
      "grad_norm": 1.4651604890823364
    },
    {
      "step": 2485,
      "loss": 0.000648172979708761,
      "accuracy": 1.0,
      "grad_norm": 0.0580327995121479
    },
    {
      "step": 2486,
      "loss": 0.0326746329665184,
      "accuracy": 0.9375,
      "grad_norm": 2.6688425540924072
    },
    {
      "step": 2487,
      "loss": 0.0003025732294190675,
      "accuracy": 1.0,
      "grad_norm": 0.004488336853682995
    },
    {
      "step": 2488,
      "loss": 0.0005172675009816885,
      "accuracy": 1.0,
      "grad_norm": 0.016198251396417618
    },
    {
      "step": 2489,
      "loss": 0.041540101170539856,
      "accuracy": 0.9375,
      "grad_norm": 1.3831932544708252
    },
    {
      "step": 2490,
      "loss": 0.001604213030077517,
      "accuracy": 1.0,
      "grad_norm": 0.216372549533844
    },
    {
      "step": 2491,
      "loss": 0.0004402567574288696,
      "accuracy": 1.0,
      "grad_norm": 0.010596457868814468
    },
    {
      "step": 2492,
      "loss": 0.00042102602310478687,
      "accuracy": 1.0,
      "grad_norm": 0.01975984312593937
    },
    {
      "step": 2493,
      "loss": 0.0003554881550371647,
      "accuracy": 1.0,
      "grad_norm": 0.007364488672465086
    },
    {
      "step": 2494,
      "loss": 0.005770346615463495,
      "accuracy": 1.0,
      "grad_norm": 0.615331768989563
    },
    {
      "step": 2495,
      "loss": 0.001344621297903359,
      "accuracy": 1.0,
      "grad_norm": 0.15611319243907928
    },
    {
      "step": 2496,
      "loss": 0.0008504281286150217,
      "accuracy": 1.0,
      "grad_norm": 0.05317120999097824
    },
    {
      "step": 2497,
      "loss": 0.0228672306984663,
      "accuracy": 0.9375,
      "grad_norm": 0.9852697849273682
    },
    {
      "step": 2498,
      "loss": 0.00045704556396231055,
      "accuracy": 1.0,
      "grad_norm": 0.023414907976984978
    },
    {
      "step": 2499,
      "loss": 0.0021266015246510506,
      "accuracy": 1.0,
      "grad_norm": 0.30541932582855225
    },
    {
      "step": 2500,
      "loss": 0.0003308823797851801,
      "accuracy": 1.0,
      "grad_norm": 0.005548712331801653
    },
    {
      "step": 2501,
      "loss": 0.0013173803454264998,
      "accuracy": 1.0,
      "grad_norm": 0.16272461414337158
    },
    {
      "step": 2502,
      "loss": 0.010223756544291973,
      "accuracy": 1.0,
      "grad_norm": 1.7522251605987549
    },
    {
      "step": 2503,
      "loss": 0.001313644926995039,
      "accuracy": 1.0,
      "grad_norm": 0.09967904537916183
    },
    {
      "step": 2504,
      "loss": 0.007553194649517536,
      "accuracy": 1.0,
      "grad_norm": 0.6874185800552368
    },
    {
      "step": 2505,
      "loss": 0.09380140900611877,
      "accuracy": 0.875,
      "grad_norm": 4.300654411315918
    },
    {
      "step": 2506,
      "loss": 0.0003926168428733945,
      "accuracy": 1.0,
      "grad_norm": 0.00745901744812727
    },
    {
      "step": 2507,
      "loss": 0.07388434559106827,
      "accuracy": 0.875,
      "grad_norm": 4.651076316833496
    },
    {
      "step": 2508,
      "loss": 0.02565370686352253,
      "accuracy": 0.9375,
      "grad_norm": 0.9848259091377258
    },
    {
      "step": 2509,
      "loss": 0.00101083901245147,
      "accuracy": 1.0,
      "grad_norm": 0.12249378114938736
    },
    {
      "step": 2510,
      "loss": 0.0005092761130072176,
      "accuracy": 1.0,
      "grad_norm": 0.010789347812533379
    },
    {
      "step": 2511,
      "loss": 0.007503320928663015,
      "accuracy": 1.0,
      "grad_norm": 0.6776184439659119
    },
    {
      "step": 2512,
      "loss": 0.05345732346177101,
      "accuracy": 0.9375,
      "grad_norm": 1.2320109605789185
    },
    {
      "step": 2513,
      "loss": 0.0012633074074983597,
      "accuracy": 1.0,
      "grad_norm": 0.062007468193769455
    },
    {
      "step": 2514,
      "loss": 0.030196448788046837,
      "accuracy": 0.9375,
      "grad_norm": 1.781948447227478
    },
    {
      "step": 2515,
      "loss": 0.04606494680047035,
      "accuracy": 0.9375,
      "grad_norm": 1.1805839538574219
    },
    {
      "step": 2516,
      "loss": 0.0006335391663014889,
      "accuracy": 1.0,
      "grad_norm": 0.018138576298952103
    },
    {
      "step": 2517,
      "loss": 0.0017019797815009952,
      "accuracy": 1.0,
      "grad_norm": 0.11701393127441406
    },
    {
      "step": 2518,
      "loss": 0.0004665943270083517,
      "accuracy": 1.0,
      "grad_norm": 0.014659223146736622
    },
    {
      "step": 2519,
      "loss": 0.0038456437177956104,
      "accuracy": 1.0,
      "grad_norm": 0.24696899950504303
    },
    {
      "step": 2520,
      "loss": 0.0006755264475941658,
      "accuracy": 1.0,
      "grad_norm": 0.01613790914416313
    },
    {
      "step": 2521,
      "loss": 0.0459601916372776,
      "accuracy": 0.9375,
      "grad_norm": 3.270071268081665
    },
    {
      "step": 2522,
      "loss": 0.0033046237658709288,
      "accuracy": 1.0,
      "grad_norm": 0.44406798481941223
    },
    {
      "step": 2523,
      "loss": 0.0018401279812678695,
      "accuracy": 1.0,
      "grad_norm": 0.22614428400993347
    },
    {
      "step": 2524,
      "loss": 0.10579399764537811,
      "accuracy": 0.9375,
      "grad_norm": 2.439380168914795
    },
    {
      "step": 2525,
      "loss": 0.013020887970924377,
      "accuracy": 1.0,
      "grad_norm": 0.5770447850227356
    },
    {
      "step": 2526,
      "loss": 0.0019506470998749137,
      "accuracy": 1.0,
      "grad_norm": 0.08100774139165878
    },
    {
      "step": 2527,
      "loss": 0.015787769109010696,
      "accuracy": 0.9375,
      "grad_norm": 1.2122138738632202
    },
    {
      "step": 2528,
      "loss": 0.033267684280872345,
      "accuracy": 0.9375,
      "grad_norm": 1.9719736576080322
    },
    {
      "step": 2529,
      "loss": 0.0014793459558859468,
      "accuracy": 1.0,
      "grad_norm": 0.08162735402584076
    },
    {
      "step": 2530,
      "loss": 0.0018034545937553048,
      "accuracy": 1.0,
      "grad_norm": 0.08606000989675522
    },
    {
      "step": 2531,
      "loss": 0.0036779576912522316,
      "accuracy": 1.0,
      "grad_norm": 0.20011721551418304
    },
    {
      "step": 2532,
      "loss": 0.0013512021396309137,
      "accuracy": 1.0,
      "grad_norm": 0.07739265263080597
    },
    {
      "step": 2533,
      "loss": 0.0014681185130029917,
      "accuracy": 1.0,
      "grad_norm": 0.09925676882266998
    },
    {
      "step": 2534,
      "loss": 0.0012183482758700848,
      "accuracy": 1.0,
      "grad_norm": 0.05999371409416199
    },
    {
      "step": 2535,
      "loss": 0.01755981706082821,
      "accuracy": 0.9375,
      "grad_norm": 0.3478209376335144
    },
    {
      "step": 2536,
      "loss": 0.0013362152967602015,
      "accuracy": 1.0,
      "grad_norm": 0.14382995665073395
    },
    {
      "step": 2537,
      "loss": 0.008267012424767017,
      "accuracy": 1.0,
      "grad_norm": 1.2855980396270752
    },
    {
      "step": 2538,
      "loss": 0.0005409908480942249,
      "accuracy": 1.0,
      "grad_norm": 0.015098398551344872
    },
    {
      "step": 2539,
      "loss": 0.0008955167140811682,
      "accuracy": 1.0,
      "grad_norm": 0.043661169707775116
    },
    {
      "step": 2540,
      "loss": 0.0016566184349358082,
      "accuracy": 1.0,
      "grad_norm": 0.09464669972658157
    },
    {
      "step": 2541,
      "loss": 0.07385162264108658,
      "accuracy": 0.9375,
      "grad_norm": 1.0349699258804321
    },
    {
      "step": 2542,
      "loss": 0.00048245216021314263,
      "accuracy": 1.0,
      "grad_norm": 0.012280002236366272
    },
    {
      "step": 2543,
      "loss": 0.007748867850750685,
      "accuracy": 1.0,
      "grad_norm": 1.2911746501922607
    },
    {
      "step": 2544,
      "loss": 0.0004956154152750969,
      "accuracy": 1.0,
      "grad_norm": 0.012407650239765644
    },
    {
      "step": 2545,
      "loss": 0.13189977407455444,
      "accuracy": 0.875,
      "grad_norm": 1.4858213663101196
    },
    {
      "step": 2546,
      "loss": 0.0038176935631781816,
      "accuracy": 1.0,
      "grad_norm": 0.6958574056625366
    },
    {
      "step": 2547,
      "loss": 0.010948790237307549,
      "accuracy": 1.0,
      "grad_norm": 0.9199889898300171
    },
    {
      "step": 2548,
      "loss": 0.010533476248383522,
      "accuracy": 1.0,
      "grad_norm": 0.7860198616981506
    },
    {
      "step": 2549,
      "loss": 0.0006577940075658262,
      "accuracy": 1.0,
      "grad_norm": 0.025990286841988564
    },
    {
      "step": 2550,
      "loss": 0.018234217539429665,
      "accuracy": 1.0,
      "grad_norm": 0.7374241352081299
    },
    {
      "step": 2551,
      "loss": 0.007071889471262693,
      "accuracy": 1.0,
      "grad_norm": 0.551228940486908
    },
    {
      "step": 2552,
      "loss": 0.017832010984420776,
      "accuracy": 0.9375,
      "grad_norm": 2.554363489151001
    },
    {
      "step": 2553,
      "loss": 0.010237693786621094,
      "accuracy": 1.0,
      "grad_norm": 0.5186713933944702
    },
    {
      "step": 2554,
      "loss": 0.004774070810526609,
      "accuracy": 1.0,
      "grad_norm": 0.3835916817188263
    },
    {
      "step": 2555,
      "loss": 0.0019243520218878984,
      "accuracy": 1.0,
      "grad_norm": 0.10176204144954681
    },
    {
      "step": 2556,
      "loss": 0.005100622307509184,
      "accuracy": 1.0,
      "grad_norm": 0.43233755230903625
    },
    {
      "step": 2557,
      "loss": 0.002077939687296748,
      "accuracy": 1.0,
      "grad_norm": 0.13410818576812744
    },
    {
      "step": 2558,
      "loss": 0.035554416477680206,
      "accuracy": 0.9375,
      "grad_norm": 1.176961064338684
    },
    {
      "step": 2559,
      "loss": 0.007103492971509695,
      "accuracy": 1.0,
      "grad_norm": 0.3259005844593048
    },
    {
      "step": 2560,
      "loss": 0.010392684489488602,
      "accuracy": 1.0,
      "grad_norm": 0.32407861948013306
    },
    {
      "step": 2561,
      "loss": 0.0035218338016420603,
      "accuracy": 1.0,
      "grad_norm": 0.29761508107185364
    },
    {
      "step": 2562,
      "loss": 0.027395233511924744,
      "accuracy": 0.9375,
      "grad_norm": 3.5083582401275635
    },
    {
      "step": 2563,
      "loss": 0.0018168592359870672,
      "accuracy": 1.0,
      "grad_norm": 0.06629231572151184
    },
    {
      "step": 2564,
      "loss": 0.06002262607216835,
      "accuracy": 0.9375,
      "grad_norm": 5.2001495361328125
    },
    {
      "step": 2565,
      "loss": 0.0011069177417084575,
      "accuracy": 1.0,
      "grad_norm": 0.0607803575694561
    },
    {
      "step": 2566,
      "loss": 0.0190703347325325,
      "accuracy": 0.9375,
      "grad_norm": 3.7608695030212402
    },
    {
      "step": 2567,
      "loss": 0.024324702098965645,
      "accuracy": 0.9375,
      "grad_norm": 2.6847951412200928
    },
    {
      "step": 2568,
      "loss": 0.002938521094620228,
      "accuracy": 1.0,
      "grad_norm": 0.14176461100578308
    },
    {
      "step": 2569,
      "loss": 0.008350919000804424,
      "accuracy": 1.0,
      "grad_norm": 0.7436977028846741
    },
    {
      "step": 2570,
      "loss": 0.0018968090880662203,
      "accuracy": 1.0,
      "grad_norm": 0.08276905119419098
    },
    {
      "step": 2571,
      "loss": 0.00224053836427629,
      "accuracy": 1.0,
      "grad_norm": 0.22043517231941223
    },
    {
      "step": 2572,
      "loss": 0.00028580386424437165,
      "accuracy": 1.0,
      "grad_norm": 0.0052772406488657
    },
    {
      "step": 2573,
      "loss": 0.05601068213582039,
      "accuracy": 0.9375,
      "grad_norm": 0.780430257320404
    },
    {
      "step": 2574,
      "loss": 0.05679440125823021,
      "accuracy": 0.9375,
      "grad_norm": 0.9879835247993469
    },
    {
      "step": 2575,
      "loss": 0.0007822721381671727,
      "accuracy": 1.0,
      "grad_norm": 0.026778947561979294
    },
    {
      "step": 2576,
      "loss": 0.0006141089834272861,
      "accuracy": 1.0,
      "grad_norm": 0.02034694142639637
    },
    {
      "step": 2577,
      "loss": 0.01662198267877102,
      "accuracy": 0.9375,
      "grad_norm": 2.186413049697876
    },
    {
      "step": 2578,
      "loss": 0.002323061926290393,
      "accuracy": 1.0,
      "grad_norm": 0.1276024430990219
    },
    {
      "step": 2579,
      "loss": 0.0010339719010517001,
      "accuracy": 1.0,
      "grad_norm": 0.04049175605177879
    },
    {
      "step": 2580,
      "loss": 0.0006094503914937377,
      "accuracy": 1.0,
      "grad_norm": 0.024587523192167282
    },
    {
      "step": 2581,
      "loss": 0.004198803100734949,
      "accuracy": 1.0,
      "grad_norm": 0.21506118774414062
    },
    {
      "step": 2582,
      "loss": 0.00028291274793446064,
      "accuracy": 1.0,
      "grad_norm": 0.005999009124934673
    },
    {
      "step": 2583,
      "loss": 0.015272742137312889,
      "accuracy": 0.9375,
      "grad_norm": 0.7524429559707642
    },
    {
      "step": 2584,
      "loss": 0.000691402587108314,
      "accuracy": 1.0,
      "grad_norm": 0.01725560426712036
    },
    {
      "step": 2585,
      "loss": 0.00893021933734417,
      "accuracy": 1.0,
      "grad_norm": 0.6133522391319275
    },
    {
      "step": 2586,
      "loss": 0.07963526993989944,
      "accuracy": 0.875,
      "grad_norm": 1.7921193838119507
    },
    {
      "step": 2587,
      "loss": 0.006808215752243996,
      "accuracy": 1.0,
      "grad_norm": 0.35579290986061096
    },
    {
      "step": 2588,
      "loss": 0.0013812710531055927,
      "accuracy": 1.0,
      "grad_norm": 0.051327284425497055
    },
    {
      "step": 2589,
      "loss": 0.017105892300605774,
      "accuracy": 0.9375,
      "grad_norm": 2.503974199295044
    },
    {
      "step": 2590,
      "loss": 0.0011175991967320442,
      "accuracy": 1.0,
      "grad_norm": 0.03669959306716919
    },
    {
      "step": 2591,
      "loss": 0.0005757671897299588,
      "accuracy": 1.0,
      "grad_norm": 0.016857502982020378
    },
    {
      "step": 2592,
      "loss": 0.0009550447575747967,
      "accuracy": 1.0,
      "grad_norm": 0.041441842913627625
    },
    {
      "step": 2593,
      "loss": 0.0010141163365915418,
      "accuracy": 1.0,
      "grad_norm": 0.03500610217452049
    },
    {
      "step": 2594,
      "loss": 0.01915515959262848,
      "accuracy": 0.9375,
      "grad_norm": 0.7465739846229553
    },
    {
      "step": 2595,
      "loss": 0.01465663779526949,
      "accuracy": 0.9375,
      "grad_norm": 0.5643477439880371
    },
    {
      "step": 2596,
      "loss": 0.014299062080681324,
      "accuracy": 0.9375,
      "grad_norm": 0.8128018975257874
    },
    {
      "step": 2597,
      "loss": 0.006500041112303734,
      "accuracy": 1.0,
      "grad_norm": 0.32037168741226196
    },
    {
      "step": 2598,
      "loss": 0.0045880828984081745,
      "accuracy": 1.0,
      "grad_norm": 0.19996412098407745
    },
    {
      "step": 2599,
      "loss": 0.00034798882552422583,
      "accuracy": 1.0,
      "grad_norm": 0.010466729290783405
    },
    {
      "step": 2600,
      "loss": 0.006828518584370613,
      "accuracy": 1.0,
      "grad_norm": 1.0089011192321777
    },
    {
      "step": 2601,
      "loss": 0.0010681897401809692,
      "accuracy": 1.0,
      "grad_norm": 0.07931343466043472
    },
    {
      "step": 2602,
      "loss": 0.0012688427232205868,
      "accuracy": 1.0,
      "grad_norm": 0.11429162323474884
    },
    {
      "step": 2603,
      "loss": 0.0010825834469869733,
      "accuracy": 1.0,
      "grad_norm": 0.13085198402404785
    },
    {
      "step": 2604,
      "loss": 0.0008322332287207246,
      "accuracy": 1.0,
      "grad_norm": 0.049852024763822556
    },
    {
      "step": 2605,
      "loss": 0.0005667769582942128,
      "accuracy": 1.0,
      "grad_norm": 0.015261714346706867
    },
    {
      "step": 2606,
      "loss": 0.004078306723386049,
      "accuracy": 1.0,
      "grad_norm": 0.21632254123687744
    },
    {
      "step": 2607,
      "loss": 0.05916499346494675,
      "accuracy": 0.9375,
      "grad_norm": 0.7689375877380371
    },
    {
      "step": 2608,
      "loss": 0.0028254392091184855,
      "accuracy": 1.0,
      "grad_norm": 0.4963706135749817
    },
    {
      "step": 2609,
      "loss": 0.001909436658024788,
      "accuracy": 1.0,
      "grad_norm": 0.1071104034781456
    },
    {
      "step": 2610,
      "loss": 0.0026358943432569504,
      "accuracy": 1.0,
      "grad_norm": 0.13577964901924133
    },
    {
      "step": 2611,
      "loss": 0.08855172991752625,
      "accuracy": 0.9375,
      "grad_norm": 3.8268141746520996
    },
    {
      "step": 2612,
      "loss": 0.006120398174971342,
      "accuracy": 1.0,
      "grad_norm": 1.165676236152649
    },
    {
      "step": 2613,
      "loss": 0.04095977544784546,
      "accuracy": 0.875,
      "grad_norm": 1.9273545742034912
    },
    {
      "step": 2614,
      "loss": 0.01157123688608408,
      "accuracy": 1.0,
      "grad_norm": 2.140512704849243
    },
    {
      "step": 2615,
      "loss": 0.015120149590075016,
      "accuracy": 0.9375,
      "grad_norm": 1.3783419132232666
    },
    {
      "step": 2616,
      "loss": 0.0006551928236149251,
      "accuracy": 1.0,
      "grad_norm": 0.03361724317073822
    },
    {
      "step": 2617,
      "loss": 0.0020040953531861305,
      "accuracy": 1.0,
      "grad_norm": 0.11452411115169525
    },
    {
      "step": 2618,
      "loss": 0.0013174276100471616,
      "accuracy": 1.0,
      "grad_norm": 0.058139584958553314
    },
    {
      "step": 2619,
      "loss": 0.0011391425505280495,
      "accuracy": 1.0,
      "grad_norm": 0.04548691213130951
    },
    {
      "step": 2620,
      "loss": 0.011675394140183926,
      "accuracy": 1.0,
      "grad_norm": 2.2208354473114014
    },
    {
      "step": 2621,
      "loss": 0.0012844755547121167,
      "accuracy": 1.0,
      "grad_norm": 0.052183713763952255
    },
    {
      "step": 2622,
      "loss": 0.0007578790537081659,
      "accuracy": 1.0,
      "grad_norm": 0.057104580104351044
    },
    {
      "step": 2623,
      "loss": 0.0008327087271027267,
      "accuracy": 1.0,
      "grad_norm": 0.0918625071644783
    },
    {
      "step": 2624,
      "loss": 0.000998345436528325,
      "accuracy": 1.0,
      "grad_norm": 0.04645590856671333
    },
    {
      "step": 2625,
      "loss": 0.0005113455699756742,
      "accuracy": 1.0,
      "grad_norm": 0.021134087815880775
    },
    {
      "step": 2626,
      "loss": 0.0006903663743287325,
      "accuracy": 1.0,
      "grad_norm": 0.015620540827512741
    },
    {
      "step": 2627,
      "loss": 0.00044690031791105866,
      "accuracy": 1.0,
      "grad_norm": 0.009967564605176449
    },
    {
      "step": 2628,
      "loss": 0.05462408810853958,
      "accuracy": 0.9375,
      "grad_norm": 2.2322165966033936
    },
    {
      "step": 2629,
      "loss": 0.0006121370242908597,
      "accuracy": 1.0,
      "grad_norm": 0.01612773723900318
    },
    {
      "step": 2630,
      "loss": 0.0003380373527761549,
      "accuracy": 1.0,
      "grad_norm": 0.007144281640648842
    },
    {
      "step": 2631,
      "loss": 0.00042871315963566303,
      "accuracy": 1.0,
      "grad_norm": 0.011207805015146732
    },
    {
      "step": 2632,
      "loss": 0.05450177937746048,
      "accuracy": 0.9375,
      "grad_norm": 1.0939671993255615
    },
    {
      "step": 2633,
      "loss": 0.016925135627388954,
      "accuracy": 0.9375,
      "grad_norm": 0.6941995620727539
    },
    {
      "step": 2634,
      "loss": 0.0008351202704943717,
      "accuracy": 1.0,
      "grad_norm": 0.09297110140323639
    },
    {
      "step": 2635,
      "loss": 0.000909780734218657,
      "accuracy": 1.0,
      "grad_norm": 0.02866659313440323
    },
    {
      "step": 2636,
      "loss": 0.0015235055470839143,
      "accuracy": 1.0,
      "grad_norm": 0.15123288333415985
    },
    {
      "step": 2637,
      "loss": 0.06021275743842125,
      "accuracy": 0.9375,
      "grad_norm": 1.0963810682296753
    },
    {
      "step": 2638,
      "loss": 0.05134792998433113,
      "accuracy": 0.875,
      "grad_norm": 2.2434375286102295
    },
    {
      "step": 2639,
      "loss": 0.0007181495311670005,
      "accuracy": 1.0,
      "grad_norm": 0.020552068948745728
    },
    {
      "step": 2640,
      "loss": 0.049509502947330475,
      "accuracy": 0.9375,
      "grad_norm": 1.8494471311569214
    },
    {
      "step": 2641,
      "loss": 0.0016679285326972604,
      "accuracy": 1.0,
      "grad_norm": 0.09109514951705933
    },
    {
      "step": 2642,
      "loss": 0.0005590377259068191,
      "accuracy": 1.0,
      "grad_norm": 0.015153727494180202
    },
    {
      "step": 2643,
      "loss": 0.001504449057392776,
      "accuracy": 1.0,
      "grad_norm": 0.05410480871796608
    },
    {
      "step": 2644,
      "loss": 0.0009709312580525875,
      "accuracy": 1.0,
      "grad_norm": 0.04411899298429489
    },
    {
      "step": 2645,
      "loss": 0.0015341866528615355,
      "accuracy": 1.0,
      "grad_norm": 0.06466903537511826
    },
    {
      "step": 2646,
      "loss": 0.056930217891931534,
      "accuracy": 0.9375,
      "grad_norm": 0.9552440643310547
    },
    {
      "step": 2647,
      "loss": 0.0019837741274386644,
      "accuracy": 1.0,
      "grad_norm": 0.19537971913814545
    },
    {
      "step": 2648,
      "loss": 0.002897755242884159,
      "accuracy": 1.0,
      "grad_norm": 0.20789484679698944
    },
    {
      "step": 2649,
      "loss": 0.0019035125151276588,
      "accuracy": 1.0,
      "grad_norm": 0.05492854490876198
    },
    {
      "step": 2650,
      "loss": 0.001924285665154457,
      "accuracy": 1.0,
      "grad_norm": 0.07713881134986877
    },
    {
      "step": 2651,
      "loss": 0.0062049757689237595,
      "accuracy": 1.0,
      "grad_norm": 0.7624965310096741
    },
    {
      "step": 2652,
      "loss": 0.0017980349948629737,
      "accuracy": 1.0,
      "grad_norm": 0.09586045145988464
    },
    {
      "step": 2653,
      "loss": 0.012783423066139221,
      "accuracy": 0.9375,
      "grad_norm": 0.4557524025440216
    },
    {
      "step": 2654,
      "loss": 0.021774226799607277,
      "accuracy": 0.9375,
      "grad_norm": 1.9742451906204224
    },
    {
      "step": 2655,
      "loss": 0.001794320298358798,
      "accuracy": 1.0,
      "grad_norm": 0.11178696155548096
    },
    {
      "step": 2656,
      "loss": 0.02094998024404049,
      "accuracy": 0.9375,
      "grad_norm": 1.3860379457473755
    },
    {
      "step": 2657,
      "loss": 0.006878056097775698,
      "accuracy": 1.0,
      "grad_norm": 0.400837779045105
    },
    {
      "step": 2658,
      "loss": 0.0009506599744781852,
      "accuracy": 1.0,
      "grad_norm": 0.04165389761328697
    },
    {
      "step": 2659,
      "loss": 0.04237182438373566,
      "accuracy": 0.9375,
      "grad_norm": 3.964641571044922
    },
    {
      "step": 2660,
      "loss": 0.01277364231646061,
      "accuracy": 1.0,
      "grad_norm": 0.7176998853683472
    },
    {
      "step": 2661,
      "loss": 0.0010460899211466312,
      "accuracy": 1.0,
      "grad_norm": 0.04441223666071892
    },
    {
      "step": 2662,
      "loss": 0.002838266547769308,
      "accuracy": 1.0,
      "grad_norm": 0.22371341288089752
    },
    {
      "step": 2663,
      "loss": 0.001807748805731535,
      "accuracy": 1.0,
      "grad_norm": 0.14143595099449158
    },
    {
      "step": 2664,
      "loss": 0.009144004434347153,
      "accuracy": 1.0,
      "grad_norm": 0.5371006727218628
    },
    {
      "step": 2665,
      "loss": 0.0004101688100490719,
      "accuracy": 1.0,
      "grad_norm": 0.011873818933963776
    },
    {
      "step": 2666,
      "loss": 0.0011966908350586891,
      "accuracy": 1.0,
      "grad_norm": 0.09794007986783981
    },
    {
      "step": 2667,
      "loss": 0.0013542856322601438,
      "accuracy": 1.0,
      "grad_norm": 0.11369660496711731
    },
    {
      "step": 2668,
      "loss": 0.008435589261353016,
      "accuracy": 1.0,
      "grad_norm": 0.6618824601173401
    },
    {
      "step": 2669,
      "loss": 0.001756721525453031,
      "accuracy": 1.0,
      "grad_norm": 0.09088721871376038
    },
    {
      "step": 2670,
      "loss": 0.029835661873221397,
      "accuracy": 0.9375,
      "grad_norm": 0.8369074463844299
    },
    {
      "step": 2671,
      "loss": 0.000647768029011786,
      "accuracy": 1.0,
      "grad_norm": 0.024365341290831566
    },
    {
      "step": 2672,
      "loss": 0.005635267589241266,
      "accuracy": 1.0,
      "grad_norm": 0.5426382422447205
    },
    {
      "step": 2673,
      "loss": 0.000673141039442271,
      "accuracy": 1.0,
      "grad_norm": 0.02374977059662342
    },
    {
      "step": 2674,
      "loss": 0.0014174720272421837,
      "accuracy": 1.0,
      "grad_norm": 0.06332821398973465
    },
    {
      "step": 2675,
      "loss": 0.002362186089158058,
      "accuracy": 1.0,
      "grad_norm": 0.14482322335243225
    },
    {
      "step": 2676,
      "loss": 0.004311906639486551,
      "accuracy": 1.0,
      "grad_norm": 0.22559835016727448
    },
    {
      "step": 2677,
      "loss": 0.0008854650659486651,
      "accuracy": 1.0,
      "grad_norm": 0.03489666432142258
    },
    {
      "step": 2678,
      "loss": 0.005191788077354431,
      "accuracy": 1.0,
      "grad_norm": 0.7637124061584473
    },
    {
      "step": 2679,
      "loss": 0.002926906570792198,
      "accuracy": 1.0,
      "grad_norm": 0.15985043346881866
    },
    {
      "step": 2680,
      "loss": 0.006562688387930393,
      "accuracy": 1.0,
      "grad_norm": 0.9000205993652344
    },
    {
      "step": 2681,
      "loss": 0.0013330683577805758,
      "accuracy": 1.0,
      "grad_norm": 0.10874132812023163
    },
    {
      "step": 2682,
      "loss": 0.0007925726240500808,
      "accuracy": 1.0,
      "grad_norm": 0.02807621657848358
    },
    {
      "step": 2683,
      "loss": 0.0006400859565474093,
      "accuracy": 1.0,
      "grad_norm": 0.02905360981822014
    },
    {
      "step": 2684,
      "loss": 0.07863720506429672,
      "accuracy": 0.9375,
      "grad_norm": 1.8918660879135132
    },
    {
      "step": 2685,
      "loss": 0.09524062275886536,
      "accuracy": 0.9375,
      "grad_norm": 0.9047767519950867
    },
    {
      "step": 2686,
      "loss": 0.0004775761626660824,
      "accuracy": 1.0,
      "grad_norm": 0.01563931815326214
    },
    {
      "step": 2687,
      "loss": 0.0007371753454208374,
      "accuracy": 1.0,
      "grad_norm": 0.022481488063931465
    },
    {
      "step": 2688,
      "loss": 0.052645012736320496,
      "accuracy": 0.9375,
      "grad_norm": 3.063459634780884
    },
    {
      "step": 2689,
      "loss": 0.017568722367286682,
      "accuracy": 0.9375,
      "grad_norm": 1.3632228374481201
    },
    {
      "step": 2690,
      "loss": 0.0010322945890948176,
      "accuracy": 1.0,
      "grad_norm": 0.03286543861031532
    },
    {
      "step": 2691,
      "loss": 0.031219637021422386,
      "accuracy": 0.9375,
      "grad_norm": 0.8067923188209534
    },
    {
      "step": 2692,
      "loss": 0.003550203749909997,
      "accuracy": 1.0,
      "grad_norm": 0.29479262232780457
    },
    {
      "step": 2693,
      "loss": 0.017720047384500504,
      "accuracy": 0.9375,
      "grad_norm": 3.328157663345337
    },
    {
      "step": 2694,
      "loss": 0.033147286623716354,
      "accuracy": 0.9375,
      "grad_norm": 3.5103468894958496
    },
    {
      "step": 2695,
      "loss": 0.0010484433732926846,
      "accuracy": 1.0,
      "grad_norm": 0.06508352607488632
    },
    {
      "step": 2696,
      "loss": 0.0323609784245491,
      "accuracy": 0.9375,
      "grad_norm": 3.203324317932129
    },
    {
      "step": 2697,
      "loss": 0.007690728642046452,
      "accuracy": 1.0,
      "grad_norm": 0.49927854537963867
    },
    {
      "step": 2698,
      "loss": 0.0012237102491781116,
      "accuracy": 1.0,
      "grad_norm": 0.05047840625047684
    },
    {
      "step": 2699,
      "loss": 0.04290373623371124,
      "accuracy": 0.9375,
      "grad_norm": 1.296183466911316
    },
    {
      "step": 2700,
      "loss": 0.028865408152341843,
      "accuracy": 0.9375,
      "grad_norm": 3.3569259643554688
    },
    {
      "step": 2701,
      "loss": 0.03790334612131119,
      "accuracy": 0.9375,
      "grad_norm": 0.7930864691734314
    },
    {
      "step": 2702,
      "loss": 0.003531314665451646,
      "accuracy": 1.0,
      "grad_norm": 0.19575904309749603
    },
    {
      "step": 2703,
      "loss": 0.01698901690542698,
      "accuracy": 0.9375,
      "grad_norm": 0.7037163972854614
    },
    {
      "step": 2704,
      "loss": 0.05432650074362755,
      "accuracy": 0.9375,
      "grad_norm": 2.2190566062927246
    },
    {
      "step": 2705,
      "loss": 0.0006726742722094059,
      "accuracy": 1.0,
      "grad_norm": 0.020749999210238457
    },
    {
      "step": 2706,
      "loss": 0.0008397457422688603,
      "accuracy": 1.0,
      "grad_norm": 0.03238397836685181
    },
    {
      "step": 2707,
      "loss": 0.05161403492093086,
      "accuracy": 0.9375,
      "grad_norm": 1.2737103700637817
    },
    {
      "step": 2708,
      "loss": 0.0013894933508709073,
      "accuracy": 1.0,
      "grad_norm": 0.12368740141391754
    },
    {
      "step": 2709,
      "loss": 0.0020155985839664936,
      "accuracy": 1.0,
      "grad_norm": 0.08758033812046051
    },
    {
      "step": 2710,
      "loss": 0.005484163295477629,
      "accuracy": 1.0,
      "grad_norm": 0.4289214015007019
    },
    {
      "step": 2711,
      "loss": 0.008140431717038155,
      "accuracy": 1.0,
      "grad_norm": 0.47213733196258545
    },
    {
      "step": 2712,
      "loss": 0.00964433141052723,
      "accuracy": 1.0,
      "grad_norm": 1.2599536180496216
    },
    {
      "step": 2713,
      "loss": 0.0019545021932572126,
      "accuracy": 1.0,
      "grad_norm": 0.08047635108232498
    },
    {
      "step": 2714,
      "loss": 0.008472990244626999,
      "accuracy": 1.0,
      "grad_norm": 0.4161404073238373
    },
    {
      "step": 2715,
      "loss": 0.003162509063258767,
      "accuracy": 1.0,
      "grad_norm": 0.45608943700790405
    },
    {
      "step": 2716,
      "loss": 0.0008698586607351899,
      "accuracy": 1.0,
      "grad_norm": 0.03456518426537514
    },
    {
      "step": 2717,
      "loss": 0.009825501590967178,
      "accuracy": 1.0,
      "grad_norm": 0.6918269991874695
    },
    {
      "step": 2718,
      "loss": 0.024096013978123665,
      "accuracy": 0.875,
      "grad_norm": 1.155676245689392
    },
    {
      "step": 2719,
      "loss": 0.07841910421848297,
      "accuracy": 0.9375,
      "grad_norm": 3.4487154483795166
    },
    {
      "step": 2720,
      "loss": 0.02587837539613247,
      "accuracy": 0.9375,
      "grad_norm": 1.4447987079620361
    },
    {
      "step": 2721,
      "loss": 0.004924740642309189,
      "accuracy": 1.0,
      "grad_norm": 0.22382190823554993
    },
    {
      "step": 2722,
      "loss": 0.020735371857881546,
      "accuracy": 0.9375,
      "grad_norm": 1.8597915172576904
    },
    {
      "step": 2723,
      "loss": 0.0036351431626826525,
      "accuracy": 1.0,
      "grad_norm": 0.29678237438201904
    },
    {
      "step": 2724,
      "loss": 0.007737042382359505,
      "accuracy": 1.0,
      "grad_norm": 0.5099821090698242
    },
    {
      "step": 2725,
      "loss": 0.004575515165925026,
      "accuracy": 1.0,
      "grad_norm": 0.31012222170829773
    },
    {
      "step": 2726,
      "loss": 0.004820739384740591,
      "accuracy": 1.0,
      "grad_norm": 0.32652565836906433
    },
    {
      "step": 2727,
      "loss": 0.0034352969378232956,
      "accuracy": 1.0,
      "grad_norm": 0.2620965838432312
    },
    {
      "step": 2728,
      "loss": 0.002833339851349592,
      "accuracy": 1.0,
      "grad_norm": 0.37471669912338257
    },
    {
      "step": 2729,
      "loss": 0.02333558164536953,
      "accuracy": 0.9375,
      "grad_norm": 0.5551788210868835
    },
    {
      "step": 2730,
      "loss": 0.0011999118141829967,
      "accuracy": 1.0,
      "grad_norm": 0.058985792100429535
    },
    {
      "step": 2731,
      "loss": 0.0066577666439116,
      "accuracy": 1.0,
      "grad_norm": 0.8061906099319458
    },
    {
      "step": 2732,
      "loss": 0.036786071956157684,
      "accuracy": 0.9375,
      "grad_norm": 5.1191840171813965
    },
    {
      "step": 2733,
      "loss": 0.0009002653532661498,
      "accuracy": 1.0,
      "grad_norm": 0.06783564388751984
    },
    {
      "step": 2734,
      "loss": 0.0008631630917079747,
      "accuracy": 1.0,
      "grad_norm": 0.0250870194286108
    },
    {
      "step": 2735,
      "loss": 0.0021138456650078297,
      "accuracy": 1.0,
      "grad_norm": 0.11277582496404648
    },
    {
      "step": 2736,
      "loss": 0.0005678973975591362,
      "accuracy": 1.0,
      "grad_norm": 0.02309105359017849
    },
    {
      "step": 2737,
      "loss": 0.0036466410383582115,
      "accuracy": 1.0,
      "grad_norm": 0.3105865716934204
    },
    {
      "step": 2738,
      "loss": 0.034537795931100845,
      "accuracy": 0.9375,
      "grad_norm": 2.46933650970459
    },
    {
      "step": 2739,
      "loss": 0.004000799730420113,
      "accuracy": 1.0,
      "grad_norm": 0.6656844615936279
    },
    {
      "step": 2740,
      "loss": 0.0014888038858771324,
      "accuracy": 1.0,
      "grad_norm": 0.05653718113899231
    },
    {
      "step": 2741,
      "loss": 0.0026530809700489044,
      "accuracy": 1.0,
      "grad_norm": 0.17765545845031738
    },
    {
      "step": 2742,
      "loss": 0.00043532782001420856,
      "accuracy": 1.0,
      "grad_norm": 0.009859545156359673
    },
    {
      "step": 2743,
      "loss": 0.0018161460757255554,
      "accuracy": 1.0,
      "grad_norm": 0.2907896339893341
    },
    {
      "step": 2744,
      "loss": 0.0029358332976698875,
      "accuracy": 1.0,
      "grad_norm": 0.45962536334991455
    },
    {
      "step": 2745,
      "loss": 0.058490779250860214,
      "accuracy": 0.9375,
      "grad_norm": 1.684818148612976
    },
    {
      "step": 2746,
      "loss": 0.0018419428961351514,
      "accuracy": 1.0,
      "grad_norm": 0.09544453769922256
    },
    {
      "step": 2747,
      "loss": 0.0624503530561924,
      "accuracy": 0.9375,
      "grad_norm": 3.3692054748535156
    },
    {
      "step": 2748,
      "loss": 0.0012393509969115257,
      "accuracy": 1.0,
      "grad_norm": 0.07499312609434128
    },
    {
      "step": 2749,
      "loss": 0.0010788114741444588,
      "accuracy": 1.0,
      "grad_norm": 0.07864876091480255
    },
    {
      "step": 2750,
      "loss": 0.0003171720018144697,
      "accuracy": 1.0,
      "grad_norm": 0.008095030672848225
    },
    {
      "step": 2751,
      "loss": 0.016627730801701546,
      "accuracy": 0.9375,
      "grad_norm": 0.537028968334198
    },
    {
      "step": 2752,
      "loss": 0.00043693778570741415,
      "accuracy": 1.0,
      "grad_norm": 0.011329863220453262
    },
    {
      "step": 2753,
      "loss": 0.0007309812936000526,
      "accuracy": 1.0,
      "grad_norm": 0.057103194296360016
    },
    {
      "step": 2754,
      "loss": 0.00024958618450909853,
      "accuracy": 1.0,
      "grad_norm": 0.00357445958070457
    },
    {
      "step": 2755,
      "loss": 0.0007896237075328827,
      "accuracy": 1.0,
      "grad_norm": 0.0340852327644825
    },
    {
      "step": 2756,
      "loss": 0.0023760967887938023,
      "accuracy": 1.0,
      "grad_norm": 0.5866298079490662
    },
    {
      "step": 2757,
      "loss": 0.0018782461993396282,
      "accuracy": 1.0,
      "grad_norm": 0.12087719887495041
    },
    {
      "step": 2758,
      "loss": 0.0005362943629734218,
      "accuracy": 1.0,
      "grad_norm": 0.030794886872172356
    },
    {
      "step": 2759,
      "loss": 0.0992853045463562,
      "accuracy": 0.9375,
      "grad_norm": 0.7870174646377563
    },
    {
      "step": 2760,
      "loss": 0.0015467472840100527,
      "accuracy": 1.0,
      "grad_norm": 0.21376079320907593
    },
    {
      "step": 2761,
      "loss": 0.00037909988895989954,
      "accuracy": 1.0,
      "grad_norm": 0.009520994499325752
    },
    {
      "step": 2762,
      "loss": 0.0007101756636984646,
      "accuracy": 1.0,
      "grad_norm": 0.03823569416999817
    },
    {
      "step": 2763,
      "loss": 0.08942500501871109,
      "accuracy": 0.875,
      "grad_norm": 2.280717611312866
    },
    {
      "step": 2764,
      "loss": 0.04831847548484802,
      "accuracy": 0.9375,
      "grad_norm": 1.365111231803894
    },
    {
      "step": 2765,
      "loss": 0.00046244385885074735,
      "accuracy": 1.0,
      "grad_norm": 0.016049399971961975
    },
    {
      "step": 2766,
      "loss": 0.01345794927328825,
      "accuracy": 0.9375,
      "grad_norm": 2.2810721397399902
    },
    {
      "step": 2767,
      "loss": 0.0010379560990259051,
      "accuracy": 1.0,
      "grad_norm": 0.1273770034313202
    },
    {
      "step": 2768,
      "loss": 0.000518886256031692,
      "accuracy": 1.0,
      "grad_norm": 0.017970023676753044
    },
    {
      "step": 2769,
      "loss": 0.03230675309896469,
      "accuracy": 0.9375,
      "grad_norm": 3.651867628097534
    },
    {
      "step": 2770,
      "loss": 0.031700048595666885,
      "accuracy": 0.9375,
      "grad_norm": 2.7844576835632324
    },
    {
      "step": 2771,
      "loss": 0.013765187934041023,
      "accuracy": 0.9375,
      "grad_norm": 0.5460050106048584
    },
    {
      "step": 2772,
      "loss": 0.02325553074479103,
      "accuracy": 0.9375,
      "grad_norm": 2.7022883892059326
    },
    {
      "step": 2773,
      "loss": 0.008265209384262562,
      "accuracy": 1.0,
      "grad_norm": 0.8661385774612427
    },
    {
      "step": 2774,
      "loss": 0.0005191506934352219,
      "accuracy": 1.0,
      "grad_norm": 0.013043401762843132
    },
    {
      "step": 2775,
      "loss": 0.004155850503593683,
      "accuracy": 1.0,
      "grad_norm": 0.4301840662956238
    },
    {
      "step": 2776,
      "loss": 0.00045433666673488915,
      "accuracy": 1.0,
      "grad_norm": 0.014520709402859211
    },
    {
      "step": 2777,
      "loss": 0.0010217117378488183,
      "accuracy": 1.0,
      "grad_norm": 0.04101410135626793
    },
    {
      "step": 2778,
      "loss": 0.0006511133979074657,
      "accuracy": 1.0,
      "grad_norm": 0.02433243952691555
    },
    {
      "step": 2779,
      "loss": 0.010348021984100342,
      "accuracy": 1.0,
      "grad_norm": 1.5445643663406372
    },
    {
      "step": 2780,
      "loss": 0.0018790742615237832,
      "accuracy": 1.0,
      "grad_norm": 0.17169344425201416
    },
    {
      "step": 2781,
      "loss": 0.009476056322455406,
      "accuracy": 1.0,
      "grad_norm": 0.5319015979766846
    },
    {
      "step": 2782,
      "loss": 0.00373506685718894,
      "accuracy": 1.0,
      "grad_norm": 0.2663485109806061
    },
    {
      "step": 2783,
      "loss": 0.0018396289087831974,
      "accuracy": 1.0,
      "grad_norm": 0.08027421683073044
    },
    {
      "step": 2784,
      "loss": 0.016838202252984047,
      "accuracy": 0.9375,
      "grad_norm": 0.8586646914482117
    },
    {
      "step": 2785,
      "loss": 0.0007565096020698547,
      "accuracy": 1.0,
      "grad_norm": 0.02474876120686531
    },
    {
      "step": 2786,
      "loss": 0.008348672650754452,
      "accuracy": 1.0,
      "grad_norm": 0.5407665967941284
    },
    {
      "step": 2787,
      "loss": 0.008603242225944996,
      "accuracy": 1.0,
      "grad_norm": 0.6604233980178833
    },
    {
      "step": 2788,
      "loss": 0.12966249883174896,
      "accuracy": 0.875,
      "grad_norm": 3.0817551612854004
    },
    {
      "step": 2789,
      "loss": 0.0010556508786976337,
      "accuracy": 1.0,
      "grad_norm": 0.05199243500828743
    },
    {
      "step": 2790,
      "loss": 0.008422358892858028,
      "accuracy": 1.0,
      "grad_norm": 1.7275547981262207
    },
    {
      "step": 2791,
      "loss": 0.0005071654450148344,
      "accuracy": 1.0,
      "grad_norm": 0.013473584316670895
    },
    {
      "step": 2792,
      "loss": 0.0005313156289048493,
      "accuracy": 1.0,
      "grad_norm": 0.026296760886907578
    },
    {
      "step": 2793,
      "loss": 0.0015777676599100232,
      "accuracy": 1.0,
      "grad_norm": 0.08272840082645416
    },
    {
      "step": 2794,
      "loss": 0.01627284660935402,
      "accuracy": 0.9375,
      "grad_norm": 1.074781894683838
    },
    {
      "step": 2795,
      "loss": 0.0010959913488477468,
      "accuracy": 1.0,
      "grad_norm": 0.08841834962368011
    },
    {
      "step": 2796,
      "loss": 0.004744302947074175,
      "accuracy": 1.0,
      "grad_norm": 0.2273849993944168
    },
    {
      "step": 2797,
      "loss": 0.10702657699584961,
      "accuracy": 0.9375,
      "grad_norm": 0.7177436947822571
    },
    {
      "step": 2798,
      "loss": 0.00415452616289258,
      "accuracy": 1.0,
      "grad_norm": 0.24787546694278717
    },
    {
      "step": 2799,
      "loss": 0.004807309713214636,
      "accuracy": 1.0,
      "grad_norm": 0.19916380941867828
    },
    {
      "step": 2800,
      "loss": 0.012540999799966812,
      "accuracy": 1.0,
      "grad_norm": 1.6212650537490845
    },
    {
      "step": 2801,
      "loss": 0.0013647428713738918,
      "accuracy": 1.0,
      "grad_norm": 0.07602661848068237
    },
    {
      "step": 2802,
      "loss": 0.0005612570093944669,
      "accuracy": 1.0,
      "grad_norm": 0.01958271861076355
    },
    {
      "step": 2803,
      "loss": 0.0008045308641158044,
      "accuracy": 1.0,
      "grad_norm": 0.04122289642691612
    },
    {
      "step": 2804,
      "loss": 0.001899408409371972,
      "accuracy": 1.0,
      "grad_norm": 0.0884525403380394
    },
    {
      "step": 2805,
      "loss": 0.0018471719231456518,
      "accuracy": 1.0,
      "grad_norm": 0.1450635939836502
    },
    {
      "step": 2806,
      "loss": 0.016357844695448875,
      "accuracy": 0.9375,
      "grad_norm": 0.7750281691551208
    },
    {
      "step": 2807,
      "loss": 0.0010577476350590587,
      "accuracy": 1.0,
      "grad_norm": 0.0932597666978836
    },
    {
      "step": 2808,
      "loss": 0.005750150885432959,
      "accuracy": 1.0,
      "grad_norm": 1.06990647315979
    },
    {
      "step": 2809,
      "loss": 0.0006582296337001026,
      "accuracy": 1.0,
      "grad_norm": 0.05024784058332443
    },
    {
      "step": 2810,
      "loss": 0.001213646843098104,
      "accuracy": 1.0,
      "grad_norm": 0.043361764401197433
    },
    {
      "step": 2811,
      "loss": 0.02277326211333275,
      "accuracy": 0.9375,
      "grad_norm": 2.5291244983673096
    },
    {
      "step": 2812,
      "loss": 0.010390006005764008,
      "accuracy": 1.0,
      "grad_norm": 2.231062889099121
    },
    {
      "step": 2813,
      "loss": 0.005381362978368998,
      "accuracy": 1.0,
      "grad_norm": 0.4103666841983795
    },
    {
      "step": 2814,
      "loss": 0.0006285876734182239,
      "accuracy": 1.0,
      "grad_norm": 0.015410811640322208
    },
    {
      "step": 2815,
      "loss": 0.0016510720597580075,
      "accuracy": 1.0,
      "grad_norm": 0.21635234355926514
    },
    {
      "step": 2816,
      "loss": 0.001108017866499722,
      "accuracy": 1.0,
      "grad_norm": 0.04664338007569313
    },
    {
      "step": 2817,
      "loss": 0.004220741800963879,
      "accuracy": 1.0,
      "grad_norm": 0.26527538895606995
    },
    {
      "step": 2818,
      "loss": 0.0030295574106276035,
      "accuracy": 1.0,
      "grad_norm": 0.22790823876857758
    },
    {
      "step": 2819,
      "loss": 0.023841679096221924,
      "accuracy": 0.9375,
      "grad_norm": 2.5883257389068604
    },
    {
      "step": 2820,
      "loss": 0.0032358975149691105,
      "accuracy": 1.0,
      "grad_norm": 0.3673497438430786
    },
    {
      "step": 2821,
      "loss": 0.0006414529052563012,
      "accuracy": 1.0,
      "grad_norm": 0.025221051648259163
    },
    {
      "step": 2822,
      "loss": 0.0005369737627916038,
      "accuracy": 1.0,
      "grad_norm": 0.017169805243611336
    },
    {
      "step": 2823,
      "loss": 0.002753478242084384,
      "accuracy": 1.0,
      "grad_norm": 0.182965487241745
    },
    {
      "step": 2824,
      "loss": 0.0106789106503129,
      "accuracy": 1.0,
      "grad_norm": 1.9901992082595825
    },
    {
      "step": 2825,
      "loss": 0.0006393952062353492,
      "accuracy": 1.0,
      "grad_norm": 0.04411556199193001
    },
    {
      "step": 2826,
      "loss": 0.021367236971855164,
      "accuracy": 0.9375,
      "grad_norm": 3.0413761138916016
    },
    {
      "step": 2827,
      "loss": 0.001082598464563489,
      "accuracy": 1.0,
      "grad_norm": 0.054710209369659424
    },
    {
      "step": 2828,
      "loss": 0.0039777690544724464,
      "accuracy": 1.0,
      "grad_norm": 0.5830022096633911
    },
    {
      "step": 2829,
      "loss": 0.04367672652006149,
      "accuracy": 0.9375,
      "grad_norm": 2.0278570652008057
    },
    {
      "step": 2830,
      "loss": 0.0013554368633776903,
      "accuracy": 1.0,
      "grad_norm": 0.07311535626649857
    },
    {
      "step": 2831,
      "loss": 0.0008604360045865178,
      "accuracy": 1.0,
      "grad_norm": 0.04144929349422455
    },
    {
      "step": 2832,
      "loss": 0.011360475793480873,
      "accuracy": 0.9375,
      "grad_norm": 1.426743745803833
    },
    {
      "step": 2833,
      "loss": 0.00042069744085893035,
      "accuracy": 1.0,
      "grad_norm": 0.011955424211919308
    },
    {
      "step": 2834,
      "loss": 0.001147934002801776,
      "accuracy": 1.0,
      "grad_norm": 0.04687350615859032
    },
    {
      "step": 2835,
      "loss": 0.0021903361193835735,
      "accuracy": 1.0,
      "grad_norm": 0.18083499372005463
    },
    {
      "step": 2836,
      "loss": 0.0005419079679995775,
      "accuracy": 1.0,
      "grad_norm": 0.02230856940150261
    },
    {
      "step": 2837,
      "loss": 0.001955435611307621,
      "accuracy": 1.0,
      "grad_norm": 0.09719125181436539
    },
    {
      "step": 2838,
      "loss": 0.0027826926670968533,
      "accuracy": 1.0,
      "grad_norm": 0.16859811544418335
    },
    {
      "step": 2839,
      "loss": 0.0030117041897028685,
      "accuracy": 1.0,
      "grad_norm": 0.30519649386405945
    },
    {
      "step": 2840,
      "loss": 0.035429585725069046,
      "accuracy": 0.9375,
      "grad_norm": 1.0028369426727295
    },
    {
      "step": 2841,
      "loss": 0.0009586677188053727,
      "accuracy": 1.0,
      "grad_norm": 0.04759646952152252
    },
    {
      "step": 2842,
      "loss": 0.0003421952424105257,
      "accuracy": 1.0,
      "grad_norm": 0.007579313591122627
    },
    {
      "step": 2843,
      "loss": 0.0019176581408828497,
      "accuracy": 1.0,
      "grad_norm": 0.11086946725845337
    },
    {
      "step": 2844,
      "loss": 0.00032248307252302766,
      "accuracy": 1.0,
      "grad_norm": 0.012873168103396893
    },
    {
      "step": 2845,
      "loss": 0.00770949199795723,
      "accuracy": 1.0,
      "grad_norm": 0.7108373045921326
    },
    {
      "step": 2846,
      "loss": 0.0012720332015305758,
      "accuracy": 1.0,
      "grad_norm": 0.06756899505853653
    },
    {
      "step": 2847,
      "loss": 0.000416965049225837,
      "accuracy": 1.0,
      "grad_norm": 0.019248051568865776
    },
    {
      "step": 2848,
      "loss": 0.0005945999873802066,
      "accuracy": 1.0,
      "grad_norm": 0.017512314021587372
    },
    {
      "step": 2849,
      "loss": 0.0008154057431966066,
      "accuracy": 1.0,
      "grad_norm": 0.08367986977100372
    },
    {
      "step": 2850,
      "loss": 0.0006871087243780494,
      "accuracy": 1.0,
      "grad_norm": 0.02087278477847576
    },
    {
      "step": 2851,
      "loss": 0.00033240235643461347,
      "accuracy": 1.0,
      "grad_norm": 0.008391408249735832
    },
    {
      "step": 2852,
      "loss": 0.08866560459136963,
      "accuracy": 0.9375,
      "grad_norm": 0.929157018661499
    },
    {
      "step": 2853,
      "loss": 0.00034958519972860813,
      "accuracy": 1.0,
      "grad_norm": 0.007060241885483265
    },
    {
      "step": 2854,
      "loss": 0.00029673721292056143,
      "accuracy": 1.0,
      "grad_norm": 0.006007397081702948
    },
    {
      "step": 2855,
      "loss": 0.0019795801490545273,
      "accuracy": 1.0,
      "grad_norm": 0.3768397271633148
    },
    {
      "step": 2856,
      "loss": 0.0018557776929810643,
      "accuracy": 1.0,
      "grad_norm": 0.10189060121774673
    },
    {
      "step": 2857,
      "loss": 0.0008210759260691702,
      "accuracy": 1.0,
      "grad_norm": 0.02124032750725746
    },
    {
      "step": 2858,
      "loss": 0.06211423501372337,
      "accuracy": 0.9375,
      "grad_norm": 0.9640840291976929
    },
    {
      "step": 2859,
      "loss": 0.0010622385889291763,
      "accuracy": 1.0,
      "grad_norm": 0.08557481318712234
    },
    {
      "step": 2860,
      "loss": 0.00344757828861475,
      "accuracy": 1.0,
      "grad_norm": 0.31452158093452454
    },
    {
      "step": 2861,
      "loss": 0.0005173275130800903,
      "accuracy": 1.0,
      "grad_norm": 0.019451001659035683
    },
    {
      "step": 2862,
      "loss": 0.0010456909658387303,
      "accuracy": 1.0,
      "grad_norm": 0.03796868026256561
    },
    {
      "step": 2863,
      "loss": 0.00043996903696097434,
      "accuracy": 1.0,
      "grad_norm": 0.017160844057798386
    },
    {
      "step": 2864,
      "loss": 0.01689528301358223,
      "accuracy": 0.9375,
      "grad_norm": 2.0165836811065674
    },
    {
      "step": 2865,
      "loss": 0.00037801082362420857,
      "accuracy": 1.0,
      "grad_norm": 0.012597749009728432
    },
    {
      "step": 2866,
      "loss": 0.014632019214332104,
      "accuracy": 0.9375,
      "grad_norm": 1.0028066635131836
    },
    {
      "step": 2867,
      "loss": 0.0016809598309919238,
      "accuracy": 1.0,
      "grad_norm": 0.0848495215177536
    },
    {
      "step": 2868,
      "loss": 0.0018589729443192482,
      "accuracy": 1.0,
      "grad_norm": 0.12064242362976074
    },
    {
      "step": 2869,
      "loss": 0.006270553916692734,
      "accuracy": 1.0,
      "grad_norm": 0.8236492276191711
    },
    {
      "step": 2870,
      "loss": 0.013652732595801353,
      "accuracy": 1.0,
      "grad_norm": 0.8800819516181946
    },
    {
      "step": 2871,
      "loss": 0.0020888238213956356,
      "accuracy": 1.0,
      "grad_norm": 0.12969239056110382
    },
    {
      "step": 2872,
      "loss": 0.0006470500375144184,
      "accuracy": 1.0,
      "grad_norm": 0.02151811681687832
    },
    {
      "step": 2873,
      "loss": 0.0005816846387460828,
      "accuracy": 1.0,
      "grad_norm": 0.021921774372458458
    },
    {
      "step": 2874,
      "loss": 0.0006060338928364217,
      "accuracy": 1.0,
      "grad_norm": 0.026862069964408875
    },
    {
      "step": 2875,
      "loss": 0.0019693041685968637,
      "accuracy": 1.0,
      "grad_norm": 0.11156239360570908
    },
    {
      "step": 2876,
      "loss": 0.0007156009087339044,
      "accuracy": 1.0,
      "grad_norm": 0.055729709565639496
    },
    {
      "step": 2877,
      "loss": 0.06307365000247955,
      "accuracy": 0.875,
      "grad_norm": 2.397948741912842
    },
    {
      "step": 2878,
      "loss": 0.001783363870345056,
      "accuracy": 1.0,
      "grad_norm": 0.14696547389030457
    },
    {
      "step": 2879,
      "loss": 0.001106656389310956,
      "accuracy": 1.0,
      "grad_norm": 0.19363310933113098
    },
    {
      "step": 2880,
      "loss": 0.0008312177378684282,
      "accuracy": 1.0,
      "grad_norm": 0.057319916784763336
    },
    {
      "step": 2881,
      "loss": 0.0036103571765124798,
      "accuracy": 1.0,
      "grad_norm": 0.30991795659065247
    },
    {
      "step": 2882,
      "loss": 0.007316557690501213,
      "accuracy": 1.0,
      "grad_norm": 1.8840388059616089
    },
    {
      "step": 2883,
      "loss": 0.002883895765990019,
      "accuracy": 1.0,
      "grad_norm": 0.3764117658138275
    },
    {
      "step": 2884,
      "loss": 0.0003216573968529701,
      "accuracy": 1.0,
      "grad_norm": 0.013382629491388798
    },
    {
      "step": 2885,
      "loss": 0.0017918143421411514,
      "accuracy": 1.0,
      "grad_norm": 0.16033580899238586
    },
    {
      "step": 2886,
      "loss": 0.0028250410687178373,
      "accuracy": 1.0,
      "grad_norm": 0.47105586528778076
    },
    {
      "step": 2887,
      "loss": 0.00061748520238325,
      "accuracy": 1.0,
      "grad_norm": 0.032790474593639374
    },
    {
      "step": 2888,
      "loss": 0.0003295796050224453,
      "accuracy": 1.0,
      "grad_norm": 0.008125293999910355
    },
    {
      "step": 2889,
      "loss": 0.004920947831124067,
      "accuracy": 1.0,
      "grad_norm": 0.23626556992530823
    },
    {
      "step": 2890,
      "loss": 0.0007237587124109268,
      "accuracy": 1.0,
      "grad_norm": 0.05274191126227379
    },
    {
      "step": 2891,
      "loss": 0.0010258479742333293,
      "accuracy": 1.0,
      "grad_norm": 0.1325615644454956
    },
    {
      "step": 2892,
      "loss": 0.0006069697556085885,
      "accuracy": 1.0,
      "grad_norm": 0.028589114546775818
    },
    {
      "step": 2893,
      "loss": 0.003188273636624217,
      "accuracy": 1.0,
      "grad_norm": 0.31480035185813904
    },
    {
      "step": 2894,
      "loss": 0.014639615081250668,
      "accuracy": 1.0,
      "grad_norm": 1.1072195768356323
    },
    {
      "step": 2895,
      "loss": 0.0003126508090645075,
      "accuracy": 1.0,
      "grad_norm": 0.0059075867757201195
    },
    {
      "step": 2896,
      "loss": 0.012112301774322987,
      "accuracy": 0.9375,
      "grad_norm": 0.6294125318527222
    },
    {
      "step": 2897,
      "loss": 0.0003822996804956347,
      "accuracy": 1.0,
      "grad_norm": 0.00801028497517109
    },
    {
      "step": 2898,
      "loss": 0.0006386616150848567,
      "accuracy": 1.0,
      "grad_norm": 0.03436421602964401
    },
    {
      "step": 2899,
      "loss": 0.0003114696592092514,
      "accuracy": 1.0,
      "grad_norm": 0.008173033595085144
    },
    {
      "step": 2900,
      "loss": 0.0007257924298755825,
      "accuracy": 1.0,
      "grad_norm": 0.05640394240617752
    },
    {
      "step": 2901,
      "loss": 0.011473827995359898,
      "accuracy": 1.0,
      "grad_norm": 2.031100273132324
    },
    {
      "step": 2902,
      "loss": 0.0022377553395926952,
      "accuracy": 1.0,
      "grad_norm": 0.15545250475406647
    },
    {
      "step": 2903,
      "loss": 0.0012539259623736143,
      "accuracy": 1.0,
      "grad_norm": 0.10935965180397034
    },
    {
      "step": 2904,
      "loss": 0.004816912114620209,
      "accuracy": 1.0,
      "grad_norm": 0.595772922039032
    },
    {
      "step": 2905,
      "loss": 0.0004452195134945214,
      "accuracy": 1.0,
      "grad_norm": 0.013405357487499714
    },
    {
      "step": 2906,
      "loss": 0.03415604680776596,
      "accuracy": 0.9375,
      "grad_norm": 3.2760088443756104
    },
    {
      "step": 2907,
      "loss": 0.0013948127161711454,
      "accuracy": 1.0,
      "grad_norm": 0.12851659953594208
    },
    {
      "step": 2908,
      "loss": 0.00025756287504918873,
      "accuracy": 1.0,
      "grad_norm": 0.009516780264675617
    },
    {
      "step": 2909,
      "loss": 0.00027733840397559106,
      "accuracy": 1.0,
      "grad_norm": 0.005927506368607283
    },
    {
      "step": 2910,
      "loss": 0.08926989138126373,
      "accuracy": 0.9375,
      "grad_norm": 1.593858003616333
    },
    {
      "step": 2911,
      "loss": 0.00025204141275025904,
      "accuracy": 1.0,
      "grad_norm": 0.005773407407104969
    },
    {
      "step": 2912,
      "loss": 0.019589116796851158,
      "accuracy": 0.9375,
      "grad_norm": 1.5717438459396362
    },
    {
      "step": 2913,
      "loss": 0.0003635924949776381,
      "accuracy": 1.0,
      "grad_norm": 0.008326862938702106
    },
    {
      "step": 2914,
      "loss": 0.0007199053652584553,
      "accuracy": 1.0,
      "grad_norm": 0.03281994163990021
    },
    {
      "step": 2915,
      "loss": 0.0004541406815405935,
      "accuracy": 1.0,
      "grad_norm": 0.016528550535440445
    },
    {
      "step": 2916,
      "loss": 0.0034940459299832582,
      "accuracy": 1.0,
      "grad_norm": 0.43826591968536377
    },
    {
      "step": 2917,
      "loss": 0.00029221680597402155,
      "accuracy": 1.0,
      "grad_norm": 0.004014911595731974
    },
    {
      "step": 2918,
      "loss": 0.015160002745687962,
      "accuracy": 0.9375,
      "grad_norm": 2.9646379947662354
    },
    {
      "step": 2919,
      "loss": 0.03027161955833435,
      "accuracy": 0.9375,
      "grad_norm": 4.604167938232422
    },
    {
      "step": 2920,
      "loss": 0.00022696133237332106,
      "accuracy": 1.0,
      "grad_norm": 0.0029161982238292694
    },
    {
      "step": 2921,
      "loss": 0.0020128414034843445,
      "accuracy": 1.0,
      "grad_norm": 0.14644020795822144
    },
    {
      "step": 2922,
      "loss": 0.0009161903872154653,
      "accuracy": 1.0,
      "grad_norm": 0.041069380939006805
    },
    {
      "step": 2923,
      "loss": 0.00015938303840812296,
      "accuracy": 1.0,
      "grad_norm": 0.0019278319086879492
    },
    {
      "step": 2924,
      "loss": 0.006371172610670328,
      "accuracy": 1.0,
      "grad_norm": 1.3351702690124512
    },
    {
      "step": 2925,
      "loss": 0.0003708041622303426,
      "accuracy": 1.0,
      "grad_norm": 0.013714145869016647
    },
    {
      "step": 2926,
      "loss": 0.002122042002156377,
      "accuracy": 1.0,
      "grad_norm": 0.3280930519104004
    },
    {
      "step": 2927,
      "loss": 0.0007110651349648833,
      "accuracy": 1.0,
      "grad_norm": 0.032244712114334106
    },
    {
      "step": 2928,
      "loss": 0.00036276099854148924,
      "accuracy": 1.0,
      "grad_norm": 0.009698743931949139
    },
    {
      "step": 2929,
      "loss": 0.0019081777427345514,
      "accuracy": 1.0,
      "grad_norm": 0.28325337171554565
    },
    {
      "step": 2930,
      "loss": 0.0005752237630076706,
      "accuracy": 1.0,
      "grad_norm": 0.025415625423192978
    },
    {
      "step": 2931,
      "loss": 0.001867994200438261,
      "accuracy": 1.0,
      "grad_norm": 0.36806634068489075
    },
    {
      "step": 2932,
      "loss": 0.0018671615980565548,
      "accuracy": 1.0,
      "grad_norm": 0.41116398572921753
    },
    {
      "step": 2933,
      "loss": 0.0008898940868675709,
      "accuracy": 1.0,
      "grad_norm": 0.040513355284929276
    },
    {
      "step": 2934,
      "loss": 0.0011965128360316157,
      "accuracy": 1.0,
      "grad_norm": 0.14447985589504242
    },
    {
      "step": 2935,
      "loss": 0.008426216430962086,
      "accuracy": 1.0,
      "grad_norm": 0.9571914076805115
    },
    {
      "step": 2936,
      "loss": 0.0005543189472518861,
      "accuracy": 1.0,
      "grad_norm": 0.014744204469025135
    },
    {
      "step": 2937,
      "loss": 0.0014923280104994774,
      "accuracy": 1.0,
      "grad_norm": 0.26311278343200684
    },
    {
      "step": 2938,
      "loss": 0.035561490803956985,
      "accuracy": 0.9375,
      "grad_norm": 1.726213812828064
    },
    {
      "step": 2939,
      "loss": 0.0006796958623453975,
      "accuracy": 1.0,
      "grad_norm": 0.050613172352313995
    },
    {
      "step": 2940,
      "loss": 0.0005429210723377764,
      "accuracy": 1.0,
      "grad_norm": 0.07916927337646484
    },
    {
      "step": 2941,
      "loss": 0.00233411299996078,
      "accuracy": 1.0,
      "grad_norm": 0.33223477005958557
    },
    {
      "step": 2942,
      "loss": 0.00041959359077736735,
      "accuracy": 1.0,
      "grad_norm": 0.014360649511218071
    },
    {
      "step": 2943,
      "loss": 0.000277636107057333,
      "accuracy": 1.0,
      "grad_norm": 0.004703515209257603
    },
    {
      "step": 2944,
      "loss": 0.00028799392748624086,
      "accuracy": 1.0,
      "grad_norm": 0.006733959075063467
    },
    {
      "step": 2945,
      "loss": 0.0013596090720966458,
      "accuracy": 1.0,
      "grad_norm": 0.09611407667398453
    },
    {
      "step": 2946,
      "loss": 0.014874245971441269,
      "accuracy": 0.9375,
      "grad_norm": 3.835381031036377
    },
    {
      "step": 2947,
      "loss": 0.0022276255767792463,
      "accuracy": 1.0,
      "grad_norm": 0.5204953551292419
    },
    {
      "step": 2948,
      "loss": 0.0002705695223994553,
      "accuracy": 1.0,
      "grad_norm": 0.006838150322437286
    },
    {
      "step": 2949,
      "loss": 0.0004380687605589628,
      "accuracy": 1.0,
      "grad_norm": 0.04612936079502106
    },
    {
      "step": 2950,
      "loss": 0.000271217169938609,
      "accuracy": 1.0,
      "grad_norm": 0.006098962388932705
    },
    {
      "step": 2951,
      "loss": 0.0028245735447853804,
      "accuracy": 1.0,
      "grad_norm": 0.17304176092147827
    },
    {
      "step": 2952,
      "loss": 0.0005159263382665813,
      "accuracy": 1.0,
      "grad_norm": 0.017364390194416046
    },
    {
      "step": 2953,
      "loss": 0.04213136434555054,
      "accuracy": 0.9375,
      "grad_norm": 1.2916840314865112
    },
    {
      "step": 2954,
      "loss": 0.0004154634370934218,
      "accuracy": 1.0,
      "grad_norm": 0.011847267858684063
    },
    {
      "step": 2955,
      "loss": 0.11287640780210495,
      "accuracy": 0.875,
      "grad_norm": 3.3371541500091553
    },
    {
      "step": 2956,
      "loss": 0.0028332730289548635,
      "accuracy": 1.0,
      "grad_norm": 0.5229080319404602
    },
    {
      "step": 2957,
      "loss": 0.0003832208749372512,
      "accuracy": 1.0,
      "grad_norm": 0.008780546486377716
    },
    {
      "step": 2958,
      "loss": 0.02915341965854168,
      "accuracy": 0.9375,
      "grad_norm": 2.8904337882995605
    },
    {
      "step": 2959,
      "loss": 0.0022514984011650085,
      "accuracy": 1.0,
      "grad_norm": 0.15817730128765106
    },
    {
      "step": 2960,
      "loss": 0.04188798367977142,
      "accuracy": 0.9375,
      "grad_norm": 4.378400802612305
    },
    {
      "step": 2961,
      "loss": 0.017276804894208908,
      "accuracy": 0.9375,
      "grad_norm": 2.1321210861206055
    },
    {
      "step": 2962,
      "loss": 0.001019190065562725,
      "accuracy": 1.0,
      "grad_norm": 0.0661647766828537
    },
    {
      "step": 2963,
      "loss": 0.0005291170673444867,
      "accuracy": 1.0,
      "grad_norm": 0.03567086160182953
    },
    {
      "step": 2964,
      "loss": 0.0023059698287397623,
      "accuracy": 1.0,
      "grad_norm": 0.31840887665748596
    },
    {
      "step": 2965,
      "loss": 0.0005994237726554275,
      "accuracy": 1.0,
      "grad_norm": 0.025810744613409042
    },
    {
      "step": 2966,
      "loss": 0.0006071837851777673,
      "accuracy": 1.0,
      "grad_norm": 0.023456238210201263
    },
    {
      "step": 2967,
      "loss": 0.001867520622909069,
      "accuracy": 1.0,
      "grad_norm": 0.21884579956531525
    },
    {
      "step": 2968,
      "loss": 0.00027827819576486945,
      "accuracy": 1.0,
      "grad_norm": 0.011738169938325882
    },
    {
      "step": 2969,
      "loss": 0.04176805913448334,
      "accuracy": 0.9375,
      "grad_norm": 1.453320860862732
    },
    {
      "step": 2970,
      "loss": 0.0003569783584680408,
      "accuracy": 1.0,
      "grad_norm": 0.01139484066516161
    },
    {
      "step": 2971,
      "loss": 0.00907190516591072,
      "accuracy": 1.0,
      "grad_norm": 1.1662551164627075
    },
    {
      "step": 2972,
      "loss": 0.0005616447888314724,
      "accuracy": 1.0,
      "grad_norm": 0.020827053114771843
    },
    {
      "step": 2973,
      "loss": 0.000521723588462919,
      "accuracy": 1.0,
      "grad_norm": 0.046768125146627426
    },
    {
      "step": 2974,
      "loss": 0.0003803608997259289,
      "accuracy": 1.0,
      "grad_norm": 0.023559845983982086
    },
    {
      "step": 2975,
      "loss": 0.026285966858267784,
      "accuracy": 0.9375,
      "grad_norm": 1.9984166622161865
    },
    {
      "step": 2976,
      "loss": 0.012723523192107677,
      "accuracy": 0.9375,
      "grad_norm": 1.035240650177002
    },
    {
      "step": 2977,
      "loss": 0.0006571891135536134,
      "accuracy": 1.0,
      "grad_norm": 0.03279288858175278
    },
    {
      "step": 2978,
      "loss": 0.0003102101036347449,
      "accuracy": 1.0,
      "grad_norm": 0.010539749637246132
    },
    {
      "step": 2979,
      "loss": 0.0006500801537185907,
      "accuracy": 1.0,
      "grad_norm": 0.03002016618847847
    },
    {
      "step": 2980,
      "loss": 0.006326488219201565,
      "accuracy": 1.0,
      "grad_norm": 0.7665238976478577
    },
    {
      "step": 2981,
      "loss": 0.0477389357984066,
      "accuracy": 0.9375,
      "grad_norm": 1.0488581657409668
    },
    {
      "step": 2982,
      "loss": 0.009865622967481613,
      "accuracy": 1.0,
      "grad_norm": 0.5771723985671997
    },
    {
      "step": 2983,
      "loss": 0.102750264108181,
      "accuracy": 0.9375,
      "grad_norm": 0.6337938904762268
    },
    {
      "step": 2984,
      "loss": 0.00037973112193867564,
      "accuracy": 1.0,
      "grad_norm": 0.011335793882608414
    },
    {
      "step": 2985,
      "loss": 0.00045414702617563307,
      "accuracy": 1.0,
      "grad_norm": 0.030945006757974625
    },
    {
      "step": 2986,
      "loss": 0.027744267135858536,
      "accuracy": 0.9375,
      "grad_norm": 1.9382404088974
    },
    {
      "step": 2987,
      "loss": 0.011881938204169273,
      "accuracy": 1.0,
      "grad_norm": 0.5940900444984436
    },
    {
      "step": 2988,
      "loss": 0.0012939285952597857,
      "accuracy": 1.0,
      "grad_norm": 0.07320573180913925
    },
    {
      "step": 2989,
      "loss": 0.00027282684459351003,
      "accuracy": 1.0,
      "grad_norm": 0.007246896158903837
    },
    {
      "step": 2990,
      "loss": 0.059224504977464676,
      "accuracy": 0.9375,
      "grad_norm": 0.8737544417381287
    },
    {
      "step": 2991,
      "loss": 0.02939380705356598,
      "accuracy": 0.9375,
      "grad_norm": 1.2116212844848633
    },
    {
      "step": 2992,
      "loss": 0.0008529192418791354,
      "accuracy": 1.0,
      "grad_norm": 0.05409887060523033
    },
    {
      "step": 2993,
      "loss": 0.000561336986720562,
      "accuracy": 1.0,
      "grad_norm": 0.021000877022743225
    },
    {
      "step": 2994,
      "loss": 0.041542716324329376,
      "accuracy": 0.9375,
      "grad_norm": 1.174515962600708
    },
    {
      "step": 2995,
      "loss": 0.0002684126375243068,
      "accuracy": 1.0,
      "grad_norm": 0.005732710473239422
    },
    {
      "step": 2996,
      "loss": 0.004179090261459351,
      "accuracy": 1.0,
      "grad_norm": 0.38841912150382996
    },
    {
      "step": 2997,
      "loss": 0.002048422349616885,
      "accuracy": 1.0,
      "grad_norm": 0.07763408124446869
    },
    {
      "step": 2998,
      "loss": 0.0012781127588823438,
      "accuracy": 1.0,
      "grad_norm": 0.04312390089035034
    },
    {
      "step": 2999,
      "loss": 0.002038203878328204,
      "accuracy": 1.0,
      "grad_norm": 0.2579015791416168
    },
    {
      "step": 3000,
      "loss": 0.000524916045833379,
      "accuracy": 1.0,
      "grad_norm": 0.01773536391556263
    }
  ],
  "validation_metrics": [
    {
      "step": 500,
      "loss": 0.21470078577597937,
      "accuracy": 0.7465277777777778
    },
    {
      "step": 1000,
      "loss": 0.057950806286599904,
      "accuracy": 0.9027777777777778
    },
    {
      "step": 1500,
      "loss": 0.056669786779416934,
      "accuracy": 0.9097222222222222
    },
    {
      "step": 2000,
      "loss": 0.07505068004441758,
      "accuracy": 0.8819444444444444
    },
    {
      "step": 2500,
      "loss": 0.09928519817508964,
      "accuracy": 0.9166666666666666
    },
    {
      "step": 3000,
      "loss": 0.0690507638371653,
      "accuracy": 0.9305555555555556
    }
  ],
  "final_test_accuracy": 0.9305555555555556,
  "final_test_loss": 0.06508495037592689,
  "config": {
    "data": {
      "augmentation_prob": 0.1,
      "datasets": [
        {
          "config": "toxicchat0124",
          "name": "lmsys/toxic-chat"
        }
      ],
      "max_length": 256,
      "test_split": 0.1,
      "text_augmentation": true,
      "tokenizer": "sentence-transformers/all-MiniLM-L6-v2",
      "train_split": 0.8,
      "val_split": 0.1
    },
    "logging": {
      "log_dir": "logs",
      "log_level": "INFO",
      "wandb": {
        "entity": null,
        "project": "constitutional-ai-colab",
        "tags": [
          "stage1",
          "safety",
          "colab",
          "gpu"
        ]
      }
    },
    "model": {
      "dropout_rate": 0.1,
      "embedding_dim": 512,
      "feedforward_dim": 2048,
      "max_sequence_length": 256,
      "name": "safety_transformer",
      "num_classes": 4,
      "num_heads": 8,
      "num_layers": 4,
      "vocab_size": 32000
    },
    "paths": {
      "checkpoint_dir": "checkpoints",
      "data_dir": "data",
      "log_dir": "logs"
    },
    "training": {
      "batch_size": 16,
      "beta1": 0.9,
      "beta2": 0.999,
      "eval_every": 500,
      "gradient_clip_norm": 1.0,
      "learning_rate": 0.0001,
      "max_steps": 3000,
      "min_lr_ratio": 0.1,
      "optimizer": "adamw",
      "save_every": 1000,
      "schedule": "cosine_with_warmup",
      "warmup_steps": 500,
      "weight_decay": 0.01
    }
  },
  "model_info": {
    "total_parameters": 28990468,
    "training_steps": 3000,
    "best_val_accuracy": 0.9305555555555556
  }
}