data:
  augmentation_prob: 0.1
  datasets:
  - config: toxicchat0124
    name: lmsys/toxic-chat
  max_length: 256
  test_split: 0.1
  text_augmentation: true
  tokenizer: sentence-transformers/all-MiniLM-L6-v2
  train_split: 0.8
  val_split: 0.1
logging:
  log_dir: logs
  log_level: INFO
  wandb:
    entity: null
    project: constitutional-ai-colab
    tags:
    - stage1
    - safety
    - colab
    - gpu
model:
  dropout_rate: 0.1
  embedding_dim: 512
  feedforward_dim: 2048
  max_sequence_length: 256
  name: safety_transformer
  num_classes: 4
  num_heads: 8
  num_layers: 4
  vocab_size: 32000
paths:
  checkpoint_dir: checkpoints
  data_dir: data
  log_dir: logs
training:
  batch_size: 16
  beta1: 0.9
  beta2: 0.999
  eval_every: 500
  gradient_clip_norm: 1.0
  learning_rate: 0.0001
  max_steps: 3000
  min_lr_ratio: 0.1
  optimizer: adamw
  save_every: 1000
  schedule: cosine_with_warmup
  warmup_steps: 500
  weight_decay: 0.01
